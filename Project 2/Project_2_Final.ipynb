{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P3f9kkqYWzOi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import pickle\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "dvc = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff42sD6jDZaC"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbJ0F22wY5Bx",
        "outputId": "47715795-b6d5-4124-b903-a9e252a0a8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#Load cifar dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M24HaB_Bky5g"
      },
      "outputs": [],
      "source": [
        "# Reshape and normalize data via maximum pixel values\n",
        "x_train_vector = x_train.reshape((x_train.shape[0],-1)).copy()\n",
        "x_test_vector = x_test.reshape((x_test.shape[0],-1)).copy()\n",
        "x_train_vector = x_train_vector/255.0\n",
        "x_test_vector = x_test_vector / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWg1GsXBNwLv"
      },
      "outputs": [],
      "source": [
        "# Use 10% of training data as validation set\n",
        "x_train_vector, x_val_vector, y_train, y_val = train_test_split(x_train_vector, y_train,\n",
        "                                                             stratify=y_train, test_size=0.1, random_state=110)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZdcivAa8tzo"
      },
      "outputs": [],
      "source": [
        "#Create unnormalized x vector\n",
        "x_train_vector_unnorm = x_train_vector * 255.0\n",
        "x_val_vector_unnorm = x_val_vector * 255.0\n",
        "x_test_vector_unnorm = x_test_vector * 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txL4h2Z-PA_P",
        "outputId": "bd7a0aaa-cf9c-4a4a-bad5-d1b31a424c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (45000, 3072)\n",
            "Validation data shape: (5000, 3072)\n",
            "Test data shape: (10000, 3072)\n",
            "Training output shape: (45000, 1)\n",
            "Validation output shape: (5000, 1)\n",
            "Test output shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "print(f'Training data shape: {x_train_vector.shape}')\n",
        "print(f'Validation data shape: {x_val_vector.shape}')\n",
        "print(f'Test data shape: {x_test_vector.shape}')\n",
        "print(f'Training output shape: {y_train.shape}')\n",
        "print(f'Validation output shape: {y_val.shape}')\n",
        "print(f'Test output shape: {y_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz07wuTVXJnb"
      },
      "outputs": [],
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-52k-ouXVf_"
      },
      "outputs": [],
      "source": [
        "# Activation functions and derivatives\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "def tanh(z):\n",
        "    return (np.exp(z) - np.exp(-z))/(np.exp(z) + np.exp(-z))\n",
        "\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(z, 0.0)\n",
        "\n",
        "\n",
        "def leaky_relu(z):\n",
        "    return np.maximum(z, 0.01*z)\n",
        "\n",
        "\n",
        "def sigmoid_derivative(z):\n",
        "    t = sigmoid(z)\n",
        "    return t * (1 - t)\n",
        "\n",
        "\n",
        "def tanh_derivative(z):\n",
        "    t = tanh(z)\n",
        "    return 1 - np.power(t, 2)\n",
        "\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return np.greater(z, 0).astype(int)\n",
        "\n",
        "\n",
        "def leaky_relu_derivative(z):\n",
        "    gradients = 1. * (z > 0)\n",
        "    gradients[gradients == 0] = 0.01\n",
        "    return gradients\n",
        "\n",
        "\n",
        "def soft_max(scores, output_y):\n",
        "\n",
        "    p = np.exp(scores)\n",
        "\n",
        "    p = p / np.sum(p, axis=0)\n",
        "\n",
        "    s = p * output_y\n",
        "\n",
        "    loss = np.sum(s, axis=0)\n",
        "    loss = -np.log(loss)\n",
        "\n",
        "    cost = np.mean(loss)\n",
        "\n",
        "    dz2 = p - output_y\n",
        "\n",
        "    return cost, dz2\n",
        "\n",
        "def softmax(Z):\n",
        "    expZ = np.exp(Z - np.max(Z)) # Rescale to avoid numerical instability\n",
        "    out = expZ / (expZ.sum(axis=0, keepdims=True))\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKTENrNHuHFv"
      },
      "outputs": [],
      "source": [
        "#One hot encode the output\n",
        "enc = OneHotEncoder(sparse_output=False, categories='auto')\n",
        "train_y = enc.fit_transform(y_train.reshape(len(y_train), -1))\n",
        "test_y  = enc.transform(y_test.reshape(len(y_test), -1))\n",
        "val_y = enc.transform(y_val.reshape(len(y_val), -1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A978OT-NGuoS"
      },
      "outputs": [],
      "source": [
        "# Create a trainset class using torch's dataset class\n",
        "class TrainSet(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx, :], self.y[idx, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhIFjO2GHj-M"
      },
      "outputs": [],
      "source": [
        "train_set = TrainSet(x_train_vector, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZaG_IcB8-WL"
      },
      "outputs": [],
      "source": [
        "train_set_unnorm = TrainSet(x_train_vector_unnorm, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ivDRTKeEuql"
      },
      "outputs": [],
      "source": [
        "inp_dim = x_train_vector.shape[1] # Input dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQZMXxrqXkqj"
      },
      "outputs": [],
      "source": [
        "class MLP:\n",
        "\n",
        "    def __init__(self, activation_func, activation_deriv, n, \n",
        "               layer_size = [inp_dim, 256, 256, 10], btch_sz = 128, train_set=train_set,\n",
        "               X=x_train_vector, Y=train_y, X_val=x_val_vector, Y_val=val_y):\n",
        "        \n",
        "        \n",
        "        self.activation_func=activation_func\n",
        "        self.activation_deriv = activation_deriv\n",
        "        self.params = {}\n",
        "        self.n_layer = len(layer_size)-1 # input and output layers\n",
        "        self.layer_size = layer_size # list of layer sizes\n",
        "        self.n = n # Number of inputs \n",
        "        self.costs = []    \n",
        "        self.train_dat = DataLoader(train_set, batch_size=btch_sz, shuffle=True) # Create batches\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "        self.X_val = X_val\n",
        "        self.Y_val = Y_val\n",
        "        self.val_costs = []\n",
        "    def param_init(self):\n",
        "        '''\n",
        "        Random parameter initilization using random distribution\n",
        "        '''\n",
        "        for l in range(1, self.n_layer+1): # Three sets of initial parameters\n",
        "            \n",
        "            # initial layer values are normalized to avoid large weights with large layers\n",
        "            self.params[\"W\" + str(l)] = np.random.randn(self.layer_size[l], self.layer_size[l - 1]) / np.sqrt(\n",
        "            self.layer_size[l])\n",
        "            # 64 * 3072, 64 * 64, 10 * 64\n",
        "\n",
        "            self.params[\"b\" + str(l)] = np.zeros((self.layer_size[l], 1))\n",
        "            #64, 64, 10\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        cach = {}\n",
        " \n",
        "        A = X.T\n",
        "        for l in range(self.n_layer - 1):\n",
        "            Z = self.params[\"W\" + str(l + 1)] @ A + self.params[\"b\" + str(l + 1)]\n",
        "            A =  self.activation_func(Z)\n",
        "            cach[\"A\" + str(l + 1)] = A\n",
        "            cach[\"W\" + str(l + 1)] = self.params[\"W\" + str(l + 1)]\n",
        "            cach[\"Z\" + str(l + 1)] = Z\n",
        " \n",
        "        Z = self.params[\"W\" + str(self.n_layer)] @ A + self.params[\"b\" + str(self.n_layer)]\n",
        "        A = softmax(Z)\n",
        "        cach[\"A\" + str(self.n_layer)] = A\n",
        "        cach[\"W\" + str(self.n_layer)] = self.params[\"W\" + str(self.n_layer)]\n",
        "        cach[\"Z\" + str(self.n_layer)] = Z\n",
        " \n",
        "        return A, cach\n",
        "\n",
        "    def backward(self, X, Y, cach):\n",
        "        '''\n",
        "        Backpropagation. A cache of stored forward values are also needed for this function\n",
        "\n",
        "        '''\n",
        " \n",
        "        derivatives = {}\n",
        " \n",
        "        cach[\"A0\"] = X.T\n",
        " \n",
        "        A = cach[\"A\" + str(self.n_layer)]\n",
        "        dZ = A - Y.T\n",
        " \n",
        "        dW = dZ.dot(cach[\"A\" + str(self.n_layer - 1)].T) / self.n\n",
        "        db = np.sum(dZ, axis=1, keepdims=True) / self.n\n",
        "        dAPrev = cach[\"W\" + str(self.n_layer)].T.dot(dZ)\n",
        " \n",
        "        derivatives[\"dW\" + str(self.n_layer)] = dW\n",
        "        derivatives[\"db\" + str(self.n_layer)] = db\n",
        " \n",
        "        for l in range(self.n_layer - 1, 0, -1):\n",
        "            dZ = dAPrev * self.activation_deriv(cach[\"Z\" + str(l)])\n",
        "            dW = 1. / self.n * dZ.dot(cach[\"A\" + str(l - 1)].T)\n",
        "            db = 1. / self.n * np.sum(dZ, axis=1, keepdims=True)\n",
        "            if l > 1:\n",
        "                dAPrev = cach[\"W\" + str(l)].T.dot(dZ)\n",
        " \n",
        "            derivatives[\"dW\" + str(l)] = dW\n",
        "            derivatives[\"db\" + str(l)] = db\n",
        " \n",
        "        return derivatives\n",
        "\n",
        "\n",
        "    def fit(self, X, Y, lr=0.01, nitr=25, alpha=0, beta=0): \n",
        "        '''\n",
        "        Full batch gradient descent. Note that as the mini batch model trains faster, \n",
        "        we have only implemented tolerance and early stopping in that framework (below)\n",
        "        '''\n",
        " \n",
        "        self.param_init()\n",
        "\n",
        "        for loop in range(nitr):\n",
        "            if loop%10==0:\n",
        "                print(f'Iteration: {loop}')\n",
        "            A, cach = self.forward(X)\n",
        "            cost = -np.mean(Y * np.log(A.T+ 1e-8))\n",
        "            derivatives = self.backward(X, Y, cach)\n",
        " \n",
        "            for l in range(1, self.n_layer + 1):\n",
        "                self.params[\"W\" + str(l)] = self.params[\"W\" + str(l)] - lr * derivatives[\"dW\" + str(l)]- (lr / self.n) *(alpha*np.sum(self.params[\"W\" + str(l)], axis=None) + \n",
        "                         beta*np.sum(np.sign(self.params[\"W\" + str(l)])))\n",
        "                \n",
        "                self.params[\"b\" + str(l)] = self.params[\"b\" + str(l)] - lr * derivatives[\"db\" + str(l)]\n",
        " \n",
        "            if loop % 5 == 0:\n",
        "\n",
        "                print(\"Cost: \", cost, \"Train Accuracy:\", self.evaluate_acc(X, Y))\n",
        " \n",
        "            if loop % 2 == 0:\n",
        "                self.costs.append(cost)\n",
        "\n",
        "\n",
        "    def fit_btch(self, lr=0.01, nitr=25, alpha=0, beta=0, tol=5, epsilon=1e-4): \n",
        "        '''\n",
        "        Mini-barch stochastic gradient descent optimization  \n",
        "        '''\n",
        " \n",
        "        self.param_init()\n",
        "        tol_count = 0\n",
        "        for loop in range(nitr):\n",
        "            #======= Check tolerance\n",
        "            if tol_count >= tol:\n",
        "                print('Tolerance reached. Halting training')\n",
        "                break\n",
        "\n",
        "            if loop%1==0:\n",
        "                print(f'Iteration: {loop}')\n",
        "\n",
        "            for i, dat in enumerate(self.train_dat):\n",
        "\n",
        "                X, Y = dat\n",
        "                X = X.cpu().detach().numpy()\n",
        "                Y = Y.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "\n",
        "                A, cach = self.forward(X)\n",
        "                #cost = -np.mean(Y * np.log(A.T+ 1e-8))\n",
        "                derivatives = self.backward(X, Y, cach)\n",
        "                #self.costs.append(cost)\n",
        "                for l in range(1, self.n_layer + 1):\n",
        "                    self.params[\"W\" + str(l)] = self.params[\"W\" + str(l)] - lr * derivatives[\"dW\" + str(l)]- (lr / self.n) *(alpha*np.sum(self.params[\"W\" + str(l)], axis=None) + \n",
        "                         beta*np.sum(np.sign(self.params[\"W\" + str(l)])))\n",
        "\n",
        "                    self.params[\"b\" + str(l)] = self.params[\"b\" + str(l)] - lr * derivatives[\"db\" + str(l)]\n",
        "\n",
        "            ac, cost = self.evaluate_acc(self.X, self.Y)\n",
        "            self.costs.append(cost)\n",
        "\n",
        "            ac_val, cost_val = self.evaluate_acc(self.X_val, self.Y_val)\n",
        "            self.val_costs.append(cost_val)\n",
        "\n",
        "            if loop % 2 == 0:\n",
        "                print(\"Cost: \", cost, \"Train Accuracy:\", ac)\n",
        "                print(f'validation cost: {cost_val} Validation accuracy: {ac_val}')\n",
        "\n",
        "           #=== Increase tolerance counter if loss was changed less than threshold\n",
        "            if loop != 0:\n",
        "                if self.val_costs[-2] - cost_val <epsilon:\n",
        "                    tol_count +=1\n",
        "                else:\n",
        "                    tol_count = 0\n",
        "                    \n",
        "\n",
        "            #if loop % 2 == 0:\n",
        "                #self.costs.append(cost)\n",
        "    def evaluate_acc(self, X, Y):\n",
        "        '''\n",
        "        Returns accuracy and classification loss\n",
        "        '''\n",
        "        A, cache = self.forward(X)\n",
        "        y_hat = np.argmax(A, axis=0)\n",
        "        Y_cls = np.argmax(Y, axis=1) #classification Y\n",
        "        accuracy = (y_hat == Y_cls).mean()\n",
        "\n",
        "        cost = -np.mean(Y * np.log(A.T+ 1e-8))\n",
        "        return (accuracy * 100), cost\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        returns prediction\n",
        "        '''\n",
        "        A, cache = self.forward(X)\n",
        "        y_hat = np.argmax(A, axis=0)\n",
        "\n",
        "        return y_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JOxfMGq78Qu"
      },
      "source": [
        "### Unnormalized data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYoiCNrC8Dnb"
      },
      "outputs": [],
      "source": [
        "mlp_unnorm = MLP(activation_func = relu, activation_deriv= relu_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 256, 256, 10], btch_sz=256, train_set = train_set_unnorm, \n",
        "          X=x_train_vector_unnorm, Y=train_y, X_val= x_val_vector_unnorm, Y_val = val_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzeHZe4n8F0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9091a886-95a6-40d1-f302-20acbf160fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-c3df9b77e1c5>:57: RuntimeWarning: invalid value encountered in true_divide\n",
            "  out = expZ / (expZ.sum(axis=0, keepdims=True))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost:  nan Train Accuracy: 10.0\n",
            "validation cost: nan Validation accuracy: 10.0\n",
            "Iteration: 1\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "mlp_unnorm.fit_btch(lr=0.01, nitr= 2, alpha=0, beta=0, tol=5, epsilon=1e-5)\n",
        "t2 = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOuwMecbRgXr"
      },
      "source": [
        "The gradient for unnormalized **image** values becomes unstable, causing nan values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZcdoeksNpBU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZkAOwZ07-77"
      },
      "source": [
        "###Normalized data: Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swJYOs_P2oJh"
      },
      "outputs": [],
      "source": [
        "# Activation functions: relu, leaky_relu, tanh\n",
        "# Derivative: tanh_derivative, relu_derivative, leaky_relu_derivative\n",
        "\n",
        "mlp = MLP(activation_func = relu, activation_deriv= relu_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 1024, 512, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFv4DGYmLGyz",
        "outputId": "daf32c4e-4ccd-4ef2-ccff-85d7db82bdfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0\n",
            "Cost:  0.28022090292022234 Train Accuracy: 14.304444444444444\n",
            "validation cost: 0.27991577321040356 Validation accuracy: 14.580000000000002\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Cost:  0.24647603061712337 Train Accuracy: 19.986666666666668\n",
            "validation cost: 0.2460036827972407 Validation accuracy: 20.5\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Cost:  0.23179297401795868 Train Accuracy: 22.524444444444445\n",
            "validation cost: 0.2314046833193049 Validation accuracy: 23.200000000000003\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Cost:  0.22277956759457732 Train Accuracy: 24.566666666666666\n",
            "validation cost: 0.22277059369125185 Validation accuracy: 24.82\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Cost:  0.21635003616226509 Train Accuracy: 26.179999999999996\n",
            "validation cost: 0.2165975986730451 Validation accuracy: 26.3\n",
            "Iteration: 9\n",
            "10 model iterations took: 517.0555357933044s. 500 iteration will take: 82227576041.12474s equivalent to 7.181326886018117 hours!\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "mlp.fit_btch(lr=0.01, nitr= 10, alpha=0, beta=0, tol=5, epsilon=1e-5)\n",
        "t2 = time.time()\n",
        "print(f'10 model iterations took: {t2-t1}s. 500 iteration will take: {50*t2-t1}s equivalent to {(50/3600)* (t2-t1)} hours!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBpTaZutyWlk"
      },
      "outputs": [],
      "source": [
        "mlp_perf = {'test_perf': mlp.evaluate_acc(x_test_vector, test_y), 'train_time': t2-t1,\n",
        "            'train_cost': mlp.costs, 'val_cost': mlp.val_costs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hhf6YY12xEhs"
      },
      "outputs": [],
      "source": [
        "with open('mlp_mr.pickle', 'wb') as h:\n",
        "    pickle.dump(mlp_perf, h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzRC_L9DxBxj"
      },
      "outputs": [],
      "source": [
        "# get the folder id where you want to save your file\n",
        "file = drive.CreateFile()\n",
        "file.SetContentFile('mlp_mr.pickle')\n",
        "file.Upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dsq7rU9n2uld"
      },
      "outputs": [],
      "source": [
        "# Fit with full batch. Not recommended as it is really slow\n",
        "mlp.fit(x_train_vector, train_y, lr=0.01, nitr= 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JYgdhGOP5Xki"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr-6U8Pon9ya"
      },
      "source": [
        "# Different layer architectures\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQxXIyOX2GL0"
      },
      "source": [
        "### No hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH1G8PFJoDnw"
      },
      "outputs": [],
      "source": [
        "# No hidden\n",
        "\n",
        "mlp_noh = MLP(activation_func = relu, activation_deriv= relu_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30cmICSToDn0",
        "outputId": "e740cdb7-a7e7-4b93-a895-36adccde656a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Cost:  1.0017544165623928 Train Accuracy: 9.793333333333333\n",
            "validation cost: 1.0008518138214086 Validation accuracy: 10.48\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Cost:  0.8489863927148547 Train Accuracy: 9.177777777777777\n",
            "validation cost: 0.8492144275694735 Validation accuracy: 9.5\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Cost:  0.7842596688985923 Train Accuracy: 8.973333333333333\n",
            "validation cost: 0.7850230335453273 Validation accuracy: 9.68\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Cost:  0.735040032586782 Train Accuracy: 9.068888888888889\n",
            "validation cost: 0.7359912202834856 Validation accuracy: 9.54\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Cost:  0.6938210326552396 Train Accuracy: 9.175555555555556\n",
            "validation cost: 0.694835000487332 Validation accuracy: 9.5\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Cost:  0.6608525314737762 Train Accuracy: 9.16\n",
            "validation cost: 0.6621024526262508 Validation accuracy: 9.379999999999999\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Cost:  0.6353068130239745 Train Accuracy: 8.988888888888889\n",
            "validation cost: 0.6367649471391665 Validation accuracy: 9.36\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Cost:  0.6151026747675427 Train Accuracy: 8.911111111111111\n",
            "validation cost: 0.6167025249071816 Validation accuracy: 9.08\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Cost:  0.5995546579636513 Train Accuracy: 8.811111111111112\n",
            "validation cost: 0.601295460004722 Validation accuracy: 9.1\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Cost:  0.5886062169250975 Train Accuracy: 8.802222222222223\n",
            "validation cost: 0.5904412766943228 Validation accuracy: 9.139999999999999\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Cost:  0.5812329931187727 Train Accuracy: 8.873333333333333\n",
            "validation cost: 0.5831060242830439 Validation accuracy: 9.379999999999999\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Cost:  0.5758024781389064 Train Accuracy: 9.037777777777778\n",
            "validation cost: 0.5776661238465614 Validation accuracy: 9.379999999999999\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Cost:  0.5711561082585738 Train Accuracy: 9.168888888888889\n",
            "validation cost: 0.5729726391378323 Validation accuracy: 9.56\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Cost:  0.5668086346667127 Train Accuracy: 9.24\n",
            "validation cost: 0.5685610597850664 Validation accuracy: 9.700000000000001\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Cost:  0.5626022263217366 Train Accuracy: 9.348888888888888\n",
            "validation cost: 0.5642751265811564 Validation accuracy: 9.86\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Cost:  0.5584943866479983 Train Accuracy: 9.384444444444444\n",
            "validation cost: 0.5600842695592121 Validation accuracy: 10.0\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Cost:  0.5544732275877592 Train Accuracy: 9.515555555555554\n",
            "validation cost: 0.5559735569021419 Validation accuracy: 10.14\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Cost:  0.5505355018376824 Train Accuracy: 9.608888888888888\n",
            "validation cost: 0.5519495140649849 Validation accuracy: 10.24\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Cost:  0.5466805206404036 Train Accuracy: 9.700000000000001\n",
            "validation cost: 0.5480072639674897 Validation accuracy: 10.280000000000001\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Cost:  0.542907005300902 Train Accuracy: 9.791111111111112\n",
            "validation cost: 0.5441461841080899 Validation accuracy: 10.36\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Cost:  0.5392150260759735 Train Accuracy: 9.857777777777779\n",
            "validation cost: 0.540368910720941 Validation accuracy: 10.5\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Cost:  0.53560301881628 Train Accuracy: 9.968888888888888\n",
            "validation cost: 0.5366703326899972 Validation accuracy: 10.56\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Cost:  0.5320704323966333 Train Accuracy: 10.068888888888889\n",
            "validation cost: 0.533053341072769 Validation accuracy: 10.6\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Cost:  0.5286157518221078 Train Accuracy: 10.193333333333333\n",
            "validation cost: 0.5295175956496967 Validation accuracy: 10.74\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Cost:  0.5252388317848197 Train Accuracy: 10.293333333333333\n",
            "validation cost: 0.5260601507484883 Validation accuracy: 10.76\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Cost:  0.5219382870398672 Train Accuracy: 10.404444444444444\n",
            "validation cost: 0.5226788942095724 Validation accuracy: 10.780000000000001\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Cost:  0.5187121307670104 Train Accuracy: 10.488888888888889\n",
            "validation cost: 0.5193758402362697 Validation accuracy: 11.0\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Cost:  0.5155601461348309 Train Accuracy: 10.584444444444445\n",
            "validation cost: 0.5161473439248229 Validation accuracy: 11.1\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Cost:  0.5124806042588131 Train Accuracy: 10.664444444444445\n",
            "validation cost: 0.5129957269233707 Validation accuracy: 11.200000000000001\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Cost:  0.5094720014958201 Train Accuracy: 10.768888888888888\n",
            "validation cost: 0.5099145314587337 Validation accuracy: 11.18\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Cost:  0.5065330194822045 Train Accuracy: 10.891111111111112\n",
            "validation cost: 0.5069071837514281 Validation accuracy: 11.3\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Cost:  0.5036622433223633 Train Accuracy: 10.975555555555555\n",
            "validation cost: 0.5039692727957676 Validation accuracy: 11.459999999999999\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Cost:  0.5008581823723325 Train Accuracy: 11.046666666666667\n",
            "validation cost: 0.5010996133311706 Validation accuracy: 11.68\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Cost:  0.49811939837481967 Train Accuracy: 11.188888888888888\n",
            "validation cost: 0.49829773819237866 Validation accuracy: 11.72\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Cost:  0.49544431765229546 Train Accuracy: 11.28\n",
            "validation cost: 0.4955611985078543 Validation accuracy: 11.86\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Cost:  0.49283148372098085 Train Accuracy: 11.366666666666667\n",
            "validation cost: 0.49289120836353095 Validation accuracy: 11.86\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Cost:  0.4902796877662726 Train Accuracy: 11.455555555555556\n",
            "validation cost: 0.4902821932007026 Validation accuracy: 11.940000000000001\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Cost:  0.48778746124476136 Train Accuracy: 11.52\n",
            "validation cost: 0.4877332983552185 Validation accuracy: 12.04\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Cost:  0.48535285502315123 Train Accuracy: 11.624444444444444\n",
            "validation cost: 0.4852443042930544 Validation accuracy: 12.16\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Cost:  0.48297468139170396 Train Accuracy: 11.744444444444445\n",
            "validation cost: 0.48281184385263604 Validation accuracy: 12.32\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Cost:  0.48065129439005033 Train Accuracy: 11.855555555555556\n",
            "validation cost: 0.48043907466018543 Validation accuracy: 12.479999999999999\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Cost:  0.4783817508938307 Train Accuracy: 11.931111111111111\n",
            "validation cost: 0.47811903974611897 Validation accuracy: 12.559999999999999\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Cost:  0.4761640285871268 Train Accuracy: 12.068888888888889\n",
            "validation cost: 0.47585721756436394 Validation accuracy: 12.64\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Cost:  0.4739972980034992 Train Accuracy: 12.18888888888889\n",
            "validation cost: 0.4736447490240498 Validation accuracy: 12.72\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Cost:  0.47187962414879037 Train Accuracy: 12.237777777777778\n",
            "validation cost: 0.4714854117524446 Validation accuracy: 12.839999999999998\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Cost:  0.469810159841275 Train Accuracy: 12.315555555555555\n",
            "validation cost: 0.46937234086302604 Validation accuracy: 12.94\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Cost:  0.46778716222513933 Train Accuracy: 12.364444444444445\n",
            "validation cost: 0.46730934569158705 Validation accuracy: 13.0\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Cost:  0.46580963477171744 Train Accuracy: 12.404444444444444\n",
            "validation cost: 0.4652934398949395 Validation accuracy: 13.059999999999999\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Cost:  0.46387600794125783 Train Accuracy: 12.482222222222223\n",
            "validation cost: 0.4633235469337338 Validation accuracy: 13.04\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Cost:  0.46198545066826685 Train Accuracy: 12.55777777777778\n",
            "validation cost: 0.46139447295256886 Validation accuracy: 13.059999999999999\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Cost:  0.4601362996565928 Train Accuracy: 12.637777777777778\n",
            "validation cost: 0.4595113837776412 Validation accuracy: 13.08\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Cost:  0.45832759864257216 Train Accuracy: 12.711111111111112\n",
            "validation cost: 0.45766780427886594 Validation accuracy: 13.200000000000001\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Cost:  0.4565580740434259 Train Accuracy: 12.766666666666667\n",
            "validation cost: 0.45586538590797754 Validation accuracy: 13.239999999999998\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Cost:  0.4548263659601253 Train Accuracy: 12.86\n",
            "validation cost: 0.45410325282257524 Validation accuracy: 13.320000000000002\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Cost:  0.45313162887191055 Train Accuracy: 12.935555555555556\n",
            "validation cost: 0.45237738846856046 Validation accuracy: 13.48\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Cost:  0.451472751809601 Train Accuracy: 12.991111111111111\n",
            "validation cost: 0.4506885102921893 Validation accuracy: 13.52\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Cost:  0.44984872702809564 Train Accuracy: 13.068888888888889\n",
            "validation cost: 0.44903538520919734 Validation accuracy: 13.62\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Cost:  0.44825839296425757 Train Accuracy: 13.155555555555557\n",
            "validation cost: 0.44741603332679597 Validation accuracy: 13.719999999999999\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Cost:  0.44670067109462525 Train Accuracy: 13.224444444444444\n",
            "validation cost: 0.445829926134791 Validation accuracy: 13.86\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Cost:  0.4451746618339796 Train Accuracy: 13.3\n",
            "validation cost: 0.444276550975298 Validation accuracy: 13.96\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Cost:  0.4436792955564251 Train Accuracy: 13.353333333333333\n",
            "validation cost: 0.44275678731519147 Validation accuracy: 14.099999999999998\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Cost:  0.4422136884301754 Train Accuracy: 13.431111111111111\n",
            "validation cost: 0.441267765507109 Validation accuracy: 14.16\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Cost:  0.4407770686884817 Train Accuracy: 13.50222222222222\n",
            "validation cost: 0.4398047072845387 Validation accuracy: 14.180000000000001\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Cost:  0.43936832406019927 Train Accuracy: 13.577777777777778\n",
            "validation cost: 0.43837271092634794 Validation accuracy: 14.219999999999999\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Cost:  0.43798686462346004 Train Accuracy: 13.626666666666667\n",
            "validation cost: 0.4369677273298672 Validation accuracy: 14.34\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Cost:  0.4366317370672695 Train Accuracy: 13.686666666666666\n",
            "validation cost: 0.4355876572052462 Validation accuracy: 14.34\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Cost:  0.4353021044483984 Train Accuracy: 13.744444444444445\n",
            "validation cost: 0.4342362143208785 Validation accuracy: 14.34\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Cost:  0.4339972423738549 Train Accuracy: 13.835555555555556\n",
            "validation cost: 0.43290773418525635 Validation accuracy: 14.38\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Cost:  0.43271647965950205 Train Accuracy: 13.919999999999998\n",
            "validation cost: 0.4316059570809561 Validation accuracy: 14.46\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Cost:  0.4314587394210079 Train Accuracy: 13.942222222222222\n",
            "validation cost: 0.43032890588700046 Validation accuracy: 14.56\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Cost:  0.4302235680835449 Train Accuracy: 13.995555555555555\n",
            "validation cost: 0.42907474367593545 Validation accuracy: 14.6\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Cost:  0.42901038857851354 Train Accuracy: 14.066666666666666\n",
            "validation cost: 0.4278417484522039 Validation accuracy: 14.7\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Cost:  0.4278185049996593 Train Accuracy: 14.153333333333334\n",
            "validation cost: 0.42663008044533146 Validation accuracy: 14.760000000000002\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Cost:  0.4266472720586184 Train Accuracy: 14.215555555555556\n",
            "validation cost: 0.4254408407120209 Validation accuracy: 14.899999999999999\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Cost:  0.4254960109331295 Train Accuracy: 14.28888888888889\n",
            "validation cost: 0.42427153302338416 Validation accuracy: 14.92\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Cost:  0.42436419977087564 Train Accuracy: 14.351111111111111\n",
            "validation cost: 0.42312088177106133 Validation accuracy: 15.040000000000001\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Cost:  0.42325128730080364 Train Accuracy: 14.408888888888887\n",
            "validation cost: 0.4219902431246788 Validation accuracy: 15.22\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Cost:  0.4221566429342364 Train Accuracy: 14.446666666666665\n",
            "validation cost: 0.42087801236107714 Validation accuracy: 15.28\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "Cost:  0.4210798801606366 Train Accuracy: 14.511111111111111\n",
            "validation cost: 0.41978390800067544 Validation accuracy: 15.28\n",
            "Iteration: 157\n",
            "Iteration: 158\n",
            "Cost:  0.42002039191960955 Train Accuracy: 14.575555555555555\n",
            "validation cost: 0.41870780153404236 Validation accuracy: 15.379999999999999\n",
            "Iteration: 159\n",
            "Iteration: 160\n",
            "Cost:  0.4189776466087345 Train Accuracy: 14.642222222222223\n",
            "validation cost: 0.4176488253217355 Validation accuracy: 15.42\n",
            "Iteration: 161\n",
            "Iteration: 162\n",
            "Cost:  0.4179512991370629 Train Accuracy: 14.704444444444444\n",
            "validation cost: 0.41660696077911175 Validation accuracy: 15.379999999999999\n",
            "Iteration: 163\n",
            "Iteration: 164\n",
            "Cost:  0.4169408600285826 Train Accuracy: 14.775555555555556\n",
            "validation cost: 0.41557911170947076 Validation accuracy: 15.36\n",
            "Iteration: 165\n",
            "Iteration: 166\n",
            "Cost:  0.41594578925231707 Train Accuracy: 14.82\n",
            "validation cost: 0.4145685871044878 Validation accuracy: 15.4\n",
            "Iteration: 167\n",
            "Iteration: 168\n",
            "Cost:  0.41496559694844937 Train Accuracy: 14.882222222222222\n",
            "validation cost: 0.4135758695375433 Validation accuracy: 15.440000000000001\n",
            "Iteration: 169\n",
            "Iteration: 170\n",
            "Cost:  0.414000059919145 Train Accuracy: 14.928888888888888\n",
            "validation cost: 0.41259611697688053 Validation accuracy: 15.5\n",
            "Iteration: 171\n",
            "Iteration: 172\n",
            "Cost:  0.4130487857193023 Train Accuracy: 15.015555555555554\n",
            "validation cost: 0.41163217898135973 Validation accuracy: 15.52\n",
            "Iteration: 173\n",
            "Iteration: 174\n",
            "Cost:  0.4121113033970242 Train Accuracy: 15.104444444444445\n",
            "validation cost: 0.41067967368793185 Validation accuracy: 15.58\n",
            "Iteration: 175\n",
            "Iteration: 176\n",
            "Cost:  0.4111873261336189 Train Accuracy: 15.18\n",
            "validation cost: 0.40974060246694777 Validation accuracy: 15.68\n",
            "Iteration: 177\n",
            "Iteration: 178\n",
            "Cost:  0.41027646478258006 Train Accuracy: 15.253333333333332\n",
            "validation cost: 0.40881658577788027 Validation accuracy: 15.659999999999998\n",
            "Iteration: 179\n",
            "Iteration: 180\n",
            "Cost:  0.40937833440354743 Train Accuracy: 15.293333333333333\n",
            "validation cost: 0.40790451768249325 Validation accuracy: 15.68\n",
            "Iteration: 181\n",
            "Iteration: 182\n",
            "Cost:  0.40849261195853287 Train Accuracy: 15.335555555555555\n",
            "validation cost: 0.40700721952447266 Validation accuracy: 15.68\n",
            "Iteration: 183\n",
            "Iteration: 184\n",
            "Cost:  0.40761910892165565 Train Accuracy: 15.36888888888889\n",
            "validation cost: 0.4061221751601761 Validation accuracy: 15.64\n",
            "Iteration: 185\n",
            "Iteration: 186\n",
            "Cost:  0.40675727830058506 Train Accuracy: 15.428888888888888\n",
            "validation cost: 0.4052499487518058 Validation accuracy: 15.68\n",
            "Iteration: 187\n",
            "Iteration: 188\n",
            "Cost:  0.40590689918517253 Train Accuracy: 15.484444444444446\n",
            "validation cost: 0.4043880553021435 Validation accuracy: 15.78\n",
            "Iteration: 189\n",
            "Iteration: 190\n",
            "Cost:  0.40506786682073553 Train Accuracy: 15.546666666666667\n",
            "validation cost: 0.4035371783311626 Validation accuracy: 15.8\n",
            "Iteration: 191\n",
            "Iteration: 192\n",
            "Cost:  0.40423969217888645 Train Accuracy: 15.622222222222224\n",
            "validation cost: 0.4026965474616253 Validation accuracy: 15.86\n",
            "Iteration: 193\n",
            "Iteration: 194\n",
            "Cost:  0.4034222149096345 Train Accuracy: 15.666666666666668\n",
            "validation cost: 0.4018674543829383 Validation accuracy: 15.879999999999999\n",
            "Iteration: 195\n",
            "Iteration: 196\n",
            "Cost:  0.4026151826039925 Train Accuracy: 15.737777777777778\n",
            "validation cost: 0.401050357207244 Validation accuracy: 15.9\n",
            "Iteration: 197\n",
            "Iteration: 198\n",
            "Cost:  0.4018184291149145 Train Accuracy: 15.804444444444442\n",
            "validation cost: 0.40024043971794215 Validation accuracy: 15.939999999999998\n",
            "Iteration: 199\n",
            "Iteration: 200\n",
            "Cost:  0.4010315309380888 Train Accuracy: 15.86\n",
            "validation cost: 0.3994433588085018 Validation accuracy: 16.08\n",
            "Iteration: 201\n",
            "Iteration: 202\n",
            "Cost:  0.400254386456855 Train Accuracy: 15.868888888888888\n",
            "validation cost: 0.398656607512138 Validation accuracy: 16.08\n",
            "Iteration: 203\n",
            "Iteration: 204\n",
            "Cost:  0.3994865142277104 Train Accuracy: 15.92222222222222\n",
            "validation cost: 0.39787908907734737 Validation accuracy: 16.14\n",
            "Iteration: 205\n",
            "Iteration: 206\n",
            "Cost:  0.3987278359935838 Train Accuracy: 15.973333333333334\n",
            "validation cost: 0.39711182294518543 Validation accuracy: 16.24\n",
            "Iteration: 207\n",
            "Iteration: 208\n",
            "Cost:  0.3979782890382206 Train Accuracy: 16.026666666666667\n",
            "validation cost: 0.39635486689241284 Validation accuracy: 16.28\n",
            "Iteration: 209\n",
            "Iteration: 210\n",
            "Cost:  0.39723768545022575 Train Accuracy: 16.07111111111111\n",
            "validation cost: 0.3956045318644102 Validation accuracy: 16.259999999999998\n",
            "Iteration: 211\n",
            "Iteration: 212\n",
            "Cost:  0.39650563718222187 Train Accuracy: 16.11111111111111\n",
            "validation cost: 0.3948642109290335 Validation accuracy: 16.259999999999998\n",
            "Iteration: 213\n",
            "Iteration: 214\n",
            "Cost:  0.39578198163257794 Train Accuracy: 16.17111111111111\n",
            "validation cost: 0.3941334864610935 Validation accuracy: 16.28\n",
            "Iteration: 215\n",
            "Iteration: 216\n",
            "Cost:  0.39506662965405515 Train Accuracy: 16.21777777777778\n",
            "validation cost: 0.3934098346731752 Validation accuracy: 16.32\n",
            "Iteration: 217\n",
            "Iteration: 218\n",
            "Cost:  0.3943595062708617 Train Accuracy: 16.284444444444446\n",
            "validation cost: 0.3926933136108262 Validation accuracy: 16.3\n",
            "Iteration: 219\n",
            "Iteration: 220\n",
            "Cost:  0.39366014599576754 Train Accuracy: 16.353333333333335\n",
            "validation cost: 0.3919868742155587 Validation accuracy: 16.38\n",
            "Iteration: 221\n",
            "Iteration: 222\n",
            "Cost:  0.39296855699936123 Train Accuracy: 16.353333333333335\n",
            "validation cost: 0.39128738718358824 Validation accuracy: 16.42\n",
            "Iteration: 223\n",
            "Iteration: 224\n",
            "Cost:  0.3922846221995748 Train Accuracy: 16.397777777777776\n",
            "validation cost: 0.3905950511279011 Validation accuracy: 16.36\n",
            "Iteration: 225\n",
            "Iteration: 226\n",
            "Cost:  0.39160805677456256 Train Accuracy: 16.45111111111111\n",
            "validation cost: 0.38991134023414464 Validation accuracy: 16.42\n",
            "Iteration: 227\n",
            "Iteration: 228\n",
            "Cost:  0.3909387194217597 Train Accuracy: 16.502222222222223\n",
            "validation cost: 0.3892360569230332 Validation accuracy: 16.48\n",
            "Iteration: 229\n",
            "Iteration: 230\n",
            "Cost:  0.3902764969479229 Train Accuracy: 16.526666666666667\n",
            "validation cost: 0.3885687271328492 Validation accuracy: 16.5\n",
            "Iteration: 231\n",
            "Iteration: 232\n",
            "Cost:  0.3896214670582881 Train Accuracy: 16.553333333333335\n",
            "validation cost: 0.3879065753711144 Validation accuracy: 16.520000000000003\n",
            "Iteration: 233\n",
            "Iteration: 234\n",
            "Cost:  0.38897311547135177 Train Accuracy: 16.62888888888889\n",
            "validation cost: 0.3872526998746138 Validation accuracy: 16.54\n",
            "Iteration: 235\n",
            "Iteration: 236\n",
            "Cost:  0.3883315076035603 Train Accuracy: 16.664444444444445\n",
            "validation cost: 0.3866042204326601 Validation accuracy: 16.6\n",
            "Iteration: 237\n",
            "Iteration: 238\n",
            "Cost:  0.3876965179542832 Train Accuracy: 16.686666666666667\n",
            "validation cost: 0.38596433143769704 Validation accuracy: 16.72\n",
            "Iteration: 239\n",
            "Iteration: 240\n",
            "Cost:  0.3870679583382581 Train Accuracy: 16.68888888888889\n",
            "validation cost: 0.38532905317225125 Validation accuracy: 16.78\n",
            "Iteration: 241\n",
            "Iteration: 242\n",
            "Cost:  0.38644581726330124 Train Accuracy: 16.72888888888889\n",
            "validation cost: 0.38470093601447736 Validation accuracy: 16.76\n",
            "Iteration: 243\n",
            "Iteration: 244\n",
            "Cost:  0.38582984629827927 Train Accuracy: 16.766666666666666\n",
            "validation cost: 0.3840801650163854 Validation accuracy: 16.74\n",
            "Iteration: 245\n",
            "Iteration: 246\n",
            "Cost:  0.3852199489747739 Train Accuracy: 16.795555555555556\n",
            "validation cost: 0.3834647237405784 Validation accuracy: 16.7\n",
            "Iteration: 247\n",
            "Iteration: 248\n",
            "Cost:  0.38461607024700406 Train Accuracy: 16.813333333333333\n",
            "validation cost: 0.3828558954928957 Validation accuracy: 16.76\n",
            "Iteration: 249\n",
            "Iteration: 250\n",
            "Cost:  0.38401804859579114 Train Accuracy: 16.833333333333332\n",
            "validation cost: 0.38225300430344417 Validation accuracy: 16.74\n",
            "Iteration: 251\n",
            "Iteration: 252\n",
            "Cost:  0.3834259030603459 Train Accuracy: 16.844444444444445\n",
            "validation cost: 0.38165668769370836 Validation accuracy: 16.7\n",
            "Iteration: 253\n",
            "Iteration: 254\n",
            "Cost:  0.38283945779435496 Train Accuracy: 16.88888888888889\n",
            "validation cost: 0.3810640926448892 Validation accuracy: 16.74\n",
            "Iteration: 255\n",
            "Iteration: 256\n",
            "Cost:  0.38225848389928047 Train Accuracy: 16.904444444444444\n",
            "validation cost: 0.3804786084747951 Validation accuracy: 16.8\n",
            "Iteration: 257\n",
            "Iteration: 258\n",
            "Cost:  0.3816830122123284 Train Accuracy: 16.933333333333334\n",
            "validation cost: 0.3799000690015645 Validation accuracy: 16.82\n",
            "Iteration: 259\n",
            "Iteration: 260\n",
            "Cost:  0.3811129169745402 Train Accuracy: 16.962222222222223\n",
            "validation cost: 0.37932545177938287 Validation accuracy: 16.88\n",
            "Iteration: 261\n",
            "Iteration: 262\n",
            "Cost:  0.38054822815211925 Train Accuracy: 17.01111111111111\n",
            "validation cost: 0.37875664491987815 Validation accuracy: 16.919999999999998\n",
            "Iteration: 263\n",
            "Iteration: 264\n",
            "Cost:  0.3799886891510657 Train Accuracy: 17.04888888888889\n",
            "validation cost: 0.378192655509791 Validation accuracy: 16.96\n",
            "Iteration: 265\n",
            "Iteration: 266\n",
            "Cost:  0.3794342638272167 Train Accuracy: 17.115555555555556\n",
            "validation cost: 0.3776358394632338 Validation accuracy: 17.0\n",
            "Iteration: 267\n",
            "Iteration: 268\n",
            "Cost:  0.3788848870138934 Train Accuracy: 17.15111111111111\n",
            "validation cost: 0.37708307705101257 Validation accuracy: 16.98\n",
            "Iteration: 269\n",
            "Iteration: 270\n",
            "Cost:  0.37834041936372564 Train Accuracy: 17.18\n",
            "validation cost: 0.37653622524987607 Validation accuracy: 16.98\n",
            "Iteration: 271\n",
            "Iteration: 272\n",
            "Cost:  0.37780092858978265 Train Accuracy: 17.226666666666667\n",
            "validation cost: 0.3759931248527651 Validation accuracy: 17.02\n",
            "Iteration: 273\n",
            "Iteration: 274\n",
            "Cost:  0.37726619478218393 Train Accuracy: 17.255555555555553\n",
            "validation cost: 0.3754544099470595 Validation accuracy: 17.119999999999997\n",
            "Iteration: 275\n",
            "Iteration: 276\n",
            "Cost:  0.3767361357322878 Train Accuracy: 17.286666666666665\n",
            "validation cost: 0.3749217757310255 Validation accuracy: 17.080000000000002\n",
            "Iteration: 277\n",
            "Iteration: 278\n",
            "Cost:  0.3762108227150102 Train Accuracy: 17.324444444444445\n",
            "validation cost: 0.374392287781453 Validation accuracy: 17.14\n",
            "Iteration: 279\n",
            "Iteration: 280\n",
            "Cost:  0.37569009681602944 Train Accuracy: 17.353333333333335\n",
            "validation cost: 0.3738693511790901 Validation accuracy: 17.16\n",
            "Iteration: 281\n",
            "Iteration: 282\n",
            "Cost:  0.37517380836649333 Train Accuracy: 17.366666666666667\n",
            "validation cost: 0.37335128031614406 Validation accuracy: 17.16\n",
            "Iteration: 283\n",
            "Iteration: 284\n",
            "Cost:  0.3746619986964616 Train Accuracy: 17.404444444444444\n",
            "validation cost: 0.3728363453698764 Validation accuracy: 17.2\n",
            "Iteration: 285\n",
            "Iteration: 286\n",
            "Cost:  0.37415456979263456 Train Accuracy: 17.435555555555556\n",
            "validation cost: 0.3723259591905484 Validation accuracy: 17.24\n",
            "Iteration: 287\n",
            "Iteration: 288\n",
            "Cost:  0.37365143291723274 Train Accuracy: 17.45777777777778\n",
            "validation cost: 0.3718206538063132 Validation accuracy: 17.26\n",
            "Iteration: 289\n",
            "Iteration: 290\n",
            "Cost:  0.3731525166057513 Train Accuracy: 17.5\n",
            "validation cost: 0.3713202408575806 Validation accuracy: 17.28\n",
            "Iteration: 291\n",
            "Iteration: 292\n",
            "Cost:  0.37265781766365186 Train Accuracy: 17.533333333333335\n",
            "validation cost: 0.3708238334064235 Validation accuracy: 17.380000000000003\n",
            "Iteration: 293\n",
            "Iteration: 294\n",
            "Cost:  0.37216731708563716 Train Accuracy: 17.575555555555557\n",
            "validation cost: 0.37033072105831105 Validation accuracy: 17.4\n",
            "Iteration: 295\n",
            "Iteration: 296\n",
            "Cost:  0.3716808005262379 Train Accuracy: 17.604444444444447\n",
            "validation cost: 0.36984280110413126 Validation accuracy: 17.46\n",
            "Iteration: 297\n",
            "Iteration: 298\n",
            "Cost:  0.37119828438468405 Train Accuracy: 17.637777777777778\n",
            "validation cost: 0.36935856043994286 Validation accuracy: 17.52\n",
            "Iteration: 299\n",
            "Iteration: 300\n",
            "Cost:  0.37071974741914576 Train Accuracy: 17.66888888888889\n",
            "validation cost: 0.3688780674912986 Validation accuracy: 17.52\n",
            "Iteration: 301\n",
            "Iteration: 302\n",
            "Cost:  0.3702450836891493 Train Accuracy: 17.68888888888889\n",
            "validation cost: 0.3684012923851419 Validation accuracy: 17.5\n",
            "Iteration: 303\n",
            "Iteration: 304\n",
            "Cost:  0.36977425350503484 Train Accuracy: 17.72222222222222\n",
            "validation cost: 0.3679295739655175 Validation accuracy: 17.52\n",
            "Iteration: 305\n",
            "Iteration: 306\n",
            "Cost:  0.3693072290363307 Train Accuracy: 17.733333333333334\n",
            "validation cost: 0.36746193768540625 Validation accuracy: 17.580000000000002\n",
            "Iteration: 307\n",
            "Iteration: 308\n",
            "Cost:  0.3688439662865631 Train Accuracy: 17.76\n",
            "validation cost: 0.36699660382398397 Validation accuracy: 17.580000000000002\n",
            "Iteration: 309\n",
            "Iteration: 310\n",
            "Cost:  0.3683844300648468 Train Accuracy: 17.78666666666667\n",
            "validation cost: 0.36653463639608 Validation accuracy: 17.599999999999998\n",
            "Iteration: 311\n",
            "Iteration: 312\n",
            "Cost:  0.36792838842703957 Train Accuracy: 17.824444444444445\n",
            "validation cost: 0.36607864355590697 Validation accuracy: 17.62\n",
            "Iteration: 313\n",
            "Iteration: 314\n",
            "Cost:  0.3674760526415432 Train Accuracy: 17.87777777777778\n",
            "validation cost: 0.3656245968252363 Validation accuracy: 17.62\n",
            "Iteration: 315\n",
            "Iteration: 316\n",
            "Cost:  0.36702728169915255 Train Accuracy: 17.895555555555557\n",
            "validation cost: 0.3651753967019029 Validation accuracy: 17.68\n",
            "Iteration: 317\n",
            "Iteration: 318\n",
            "Cost:  0.36658205288755136 Train Accuracy: 17.924444444444447\n",
            "validation cost: 0.3647290591423722 Validation accuracy: 17.64\n",
            "Iteration: 319\n",
            "Iteration: 320\n",
            "Cost:  0.3661401674985143 Train Accuracy: 17.933333333333334\n",
            "validation cost: 0.3642858045430693 Validation accuracy: 17.66\n",
            "Iteration: 321\n",
            "Iteration: 322\n",
            "Cost:  0.3657015993156829 Train Accuracy: 17.96666666666667\n",
            "validation cost: 0.36384638505183364 Validation accuracy: 17.72\n",
            "Iteration: 323\n",
            "Iteration: 324\n",
            "Cost:  0.36526652648898167 Train Accuracy: 18.024444444444445\n",
            "validation cost: 0.36341071297941996 Validation accuracy: 17.740000000000002\n",
            "Iteration: 325\n",
            "Iteration: 326\n",
            "Cost:  0.3648347895785596 Train Accuracy: 18.055555555555554\n",
            "validation cost: 0.3629782144555524 Validation accuracy: 17.8\n",
            "Iteration: 327\n",
            "Iteration: 328\n",
            "Cost:  0.36440629891648507 Train Accuracy: 18.075555555555557\n",
            "validation cost: 0.3625496304749638 Validation accuracy: 17.82\n",
            "Iteration: 329\n",
            "Iteration: 330\n",
            "Cost:  0.36398104928607733 Train Accuracy: 18.102222222222224\n",
            "validation cost: 0.3621242056532669 Validation accuracy: 17.78\n",
            "Iteration: 331\n",
            "Iteration: 332\n",
            "Cost:  0.363559030493331 Train Accuracy: 18.12\n",
            "validation cost: 0.36170193835873665 Validation accuracy: 17.78\n",
            "Iteration: 333\n",
            "Iteration: 334\n",
            "Cost:  0.36314014104759257 Train Accuracy: 18.14666666666667\n",
            "validation cost: 0.36128316401702976 Validation accuracy: 17.86\n",
            "Iteration: 335\n",
            "Iteration: 336\n",
            "Cost:  0.36272427650088573 Train Accuracy: 18.175555555555555\n",
            "validation cost: 0.36086678820906914 Validation accuracy: 17.9\n",
            "Iteration: 337\n",
            "Iteration: 338\n",
            "Cost:  0.36231159579080724 Train Accuracy: 18.202222222222222\n",
            "validation cost: 0.3604529810316483 Validation accuracy: 17.98\n",
            "Iteration: 339\n",
            "Iteration: 340\n",
            "Cost:  0.3619019909040216 Train Accuracy: 18.217777777777776\n",
            "validation cost: 0.3600430360156056 Validation accuracy: 17.98\n",
            "Iteration: 341\n",
            "Iteration: 342\n",
            "Cost:  0.36149535234288765 Train Accuracy: 18.22888888888889\n",
            "validation cost: 0.35963662286454867 Validation accuracy: 17.98\n",
            "Iteration: 343\n",
            "Iteration: 344\n",
            "Cost:  0.36109167895968985 Train Accuracy: 18.255555555555556\n",
            "validation cost: 0.35923216959037024 Validation accuracy: 17.96\n",
            "Iteration: 345\n",
            "Iteration: 346\n",
            "Cost:  0.36069095370270066 Train Accuracy: 18.264444444444443\n",
            "validation cost: 0.3588314436673631 Validation accuracy: 17.96\n",
            "Iteration: 347\n",
            "Iteration: 348\n",
            "Cost:  0.36029311739517544 Train Accuracy: 18.288888888888888\n",
            "validation cost: 0.3584329039320628 Validation accuracy: 18.0\n",
            "Iteration: 349\n",
            "Iteration: 350\n",
            "Cost:  0.35989816952747133 Train Accuracy: 18.306666666666665\n",
            "validation cost: 0.358038828343458 Validation accuracy: 18.099999999999998\n",
            "Iteration: 351\n",
            "Iteration: 352\n",
            "Cost:  0.3595060609902279 Train Accuracy: 18.331111111111113\n",
            "validation cost: 0.3576463065300053 Validation accuracy: 18.12\n",
            "Iteration: 353\n",
            "Iteration: 354\n",
            "Cost:  0.35911671485521596 Train Accuracy: 18.360000000000003\n",
            "validation cost: 0.3572578809955698 Validation accuracy: 18.2\n",
            "Iteration: 355\n",
            "Iteration: 356\n",
            "Cost:  0.3587302934178188 Train Accuracy: 18.395555555555557\n",
            "validation cost: 0.35687181608081214 Validation accuracy: 18.26\n",
            "Iteration: 357\n",
            "Iteration: 358\n",
            "Cost:  0.35834642954533164 Train Accuracy: 18.40888888888889\n",
            "validation cost: 0.35648813821173847 Validation accuracy: 18.279999999999998\n",
            "Iteration: 359\n",
            "Iteration: 360\n",
            "Cost:  0.3579652856122566 Train Accuracy: 18.422222222222224\n",
            "validation cost: 0.35610694549486804 Validation accuracy: 18.32\n",
            "Iteration: 361\n",
            "Iteration: 362\n",
            "Cost:  0.35758691318009084 Train Accuracy: 18.44222222222222\n",
            "validation cost: 0.3557297556858353 Validation accuracy: 18.38\n",
            "Iteration: 363\n",
            "Iteration: 364\n",
            "Cost:  0.3572111922633357 Train Accuracy: 18.475555555555555\n",
            "validation cost: 0.3553528295165067 Validation accuracy: 18.38\n",
            "Iteration: 365\n",
            "Iteration: 366\n",
            "Cost:  0.3568379700707346 Train Accuracy: 18.511111111111113\n",
            "validation cost: 0.3549807454082047 Validation accuracy: 18.48\n",
            "Iteration: 367\n",
            "Iteration: 368\n",
            "Cost:  0.3564674287847921 Train Accuracy: 18.544444444444444\n",
            "validation cost: 0.3546119859109493 Validation accuracy: 18.48\n",
            "Iteration: 369\n",
            "Iteration: 370\n",
            "Cost:  0.3560994132171748 Train Accuracy: 18.577777777777776\n",
            "validation cost: 0.35424390482222295 Validation accuracy: 18.52\n",
            "Iteration: 371\n",
            "Iteration: 372\n",
            "Cost:  0.35573389325662413 Train Accuracy: 18.608888888888888\n",
            "validation cost: 0.3538789353682155 Validation accuracy: 18.52\n",
            "Iteration: 373\n",
            "Iteration: 374\n",
            "Cost:  0.35537090397835713 Train Accuracy: 18.628888888888888\n",
            "validation cost: 0.35351686913129104 Validation accuracy: 18.54\n",
            "Iteration: 375\n",
            "Iteration: 376\n",
            "Cost:  0.3550104702213498 Train Accuracy: 18.68\n",
            "validation cost: 0.3531556015687904 Validation accuracy: 18.5\n",
            "Iteration: 377\n",
            "Iteration: 378\n",
            "Cost:  0.35465238631354923 Train Accuracy: 18.7\n",
            "validation cost: 0.3527987212397216 Validation accuracy: 18.56\n",
            "Iteration: 379\n",
            "Iteration: 380\n",
            "Cost:  0.3542967146788947 Train Accuracy: 18.70888888888889\n",
            "validation cost: 0.35244338608746184 Validation accuracy: 18.62\n",
            "Iteration: 381\n",
            "Iteration: 382\n",
            "Cost:  0.35394352724608635 Train Accuracy: 18.73111111111111\n",
            "validation cost: 0.35209037697397544 Validation accuracy: 18.62\n",
            "Iteration: 383\n",
            "Iteration: 384\n",
            "Cost:  0.353592679097701 Train Accuracy: 18.76222222222222\n",
            "validation cost: 0.3517403823365077 Validation accuracy: 18.68\n",
            "Iteration: 385\n",
            "Iteration: 386\n",
            "Cost:  0.3532441677469475 Train Accuracy: 18.788888888888888\n",
            "validation cost: 0.3513937155819053 Validation accuracy: 18.68\n",
            "Iteration: 387\n",
            "Iteration: 388\n",
            "Cost:  0.3528979660341822 Train Accuracy: 18.793333333333333\n",
            "validation cost: 0.3510481729800091 Validation accuracy: 18.72\n",
            "Iteration: 389\n",
            "Iteration: 390\n",
            "Cost:  0.3525541108088135 Train Accuracy: 18.813333333333336\n",
            "validation cost: 0.3507052266314893 Validation accuracy: 18.78\n",
            "Iteration: 391\n",
            "Iteration: 392\n",
            "Cost:  0.35221251155508193 Train Accuracy: 18.826666666666668\n",
            "validation cost: 0.3503631895977618 Validation accuracy: 18.78\n",
            "Iteration: 393\n",
            "Iteration: 394\n",
            "Cost:  0.3518731432055999 Train Accuracy: 18.85333333333333\n",
            "validation cost: 0.35002368648266446 Validation accuracy: 18.84\n",
            "Iteration: 395\n",
            "Iteration: 396\n",
            "Cost:  0.3515359805398457 Train Accuracy: 18.877777777777776\n",
            "validation cost: 0.34968768191813987 Validation accuracy: 18.84\n",
            "Iteration: 397\n",
            "Iteration: 398\n",
            "Cost:  0.35120096859787625 Train Accuracy: 18.88\n",
            "validation cost: 0.3493541376093441 Validation accuracy: 18.8\n",
            "Iteration: 399\n",
            "Iteration: 400\n",
            "Cost:  0.35086819622849896 Train Accuracy: 18.91333333333333\n",
            "validation cost: 0.34902302127919466 Validation accuracy: 18.9\n",
            "Iteration: 401\n",
            "Iteration: 402\n",
            "Cost:  0.35053758352880265 Train Accuracy: 18.922222222222224\n",
            "validation cost: 0.34869419674889446 Validation accuracy: 18.9\n",
            "Iteration: 403\n",
            "Iteration: 404\n",
            "Cost:  0.35020905714489964 Train Accuracy: 18.922222222222224\n",
            "validation cost: 0.34836625745852606 Validation accuracy: 18.9\n",
            "Iteration: 405\n",
            "Iteration: 406\n",
            "Cost:  0.3498826951207598 Train Accuracy: 18.95111111111111\n",
            "validation cost: 0.3480419262957301 Validation accuracy: 18.94\n",
            "Iteration: 407\n",
            "Iteration: 408\n",
            "Cost:  0.34955839362011226 Train Accuracy: 18.95111111111111\n",
            "validation cost: 0.3477183532325496 Validation accuracy: 18.92\n",
            "Iteration: 409\n",
            "Iteration: 410\n",
            "Cost:  0.34923622487607325 Train Accuracy: 18.977777777777778\n",
            "validation cost: 0.34739777376115183 Validation accuracy: 18.98\n",
            "Iteration: 411\n",
            "Iteration: 412\n",
            "Cost:  0.3489160385226159 Train Accuracy: 19.011111111111113\n",
            "validation cost: 0.34707772634776135 Validation accuracy: 18.96\n",
            "Iteration: 413\n",
            "Iteration: 414\n",
            "Cost:  0.34859787303796463 Train Accuracy: 19.053333333333335\n",
            "validation cost: 0.34676116548155705 Validation accuracy: 18.96\n",
            "Iteration: 415\n",
            "Iteration: 416\n",
            "Cost:  0.34828173190956785 Train Accuracy: 19.084444444444447\n",
            "validation cost: 0.34644568947427923 Validation accuracy: 18.98\n",
            "Iteration: 417\n",
            "Iteration: 418\n",
            "Cost:  0.34796764834695765 Train Accuracy: 19.106666666666666\n",
            "validation cost: 0.34613401328561466 Validation accuracy: 19.0\n",
            "Iteration: 419\n",
            "Iteration: 420\n",
            "Cost:  0.34765548349518965 Train Accuracy: 19.115555555555556\n",
            "validation cost: 0.34582300739439475 Validation accuracy: 19.040000000000003\n",
            "Iteration: 421\n",
            "Iteration: 422\n",
            "Cost:  0.3473452567374644 Train Accuracy: 19.135555555555555\n",
            "validation cost: 0.3455122501830123 Validation accuracy: 19.1\n",
            "Iteration: 423\n",
            "Iteration: 424\n",
            "Cost:  0.3470368798505052 Train Accuracy: 19.164444444444445\n",
            "validation cost: 0.3452057006438802 Validation accuracy: 19.08\n",
            "Iteration: 425\n",
            "Iteration: 426\n",
            "Cost:  0.346730484728567 Train Accuracy: 19.17111111111111\n",
            "validation cost: 0.34490023984059 Validation accuracy: 19.1\n",
            "Iteration: 427\n",
            "Iteration: 428\n",
            "Cost:  0.3464259811613104 Train Accuracy: 19.186666666666667\n",
            "validation cost: 0.3445973211974943 Validation accuracy: 19.12\n",
            "Iteration: 429\n",
            "Iteration: 430\n",
            "Cost:  0.3461233265938034 Train Accuracy: 19.191111111111113\n",
            "validation cost: 0.3442960366819365 Validation accuracy: 19.1\n",
            "Iteration: 431\n",
            "Iteration: 432\n",
            "Cost:  0.3458225597116778 Train Accuracy: 19.217777777777776\n",
            "validation cost: 0.3439966586966984 Validation accuracy: 19.12\n",
            "Iteration: 433\n",
            "Iteration: 434\n",
            "Cost:  0.34552363146173476 Train Accuracy: 19.23777777777778\n",
            "validation cost: 0.3436982151719041 Validation accuracy: 19.220000000000002\n",
            "Iteration: 435\n",
            "Iteration: 436\n",
            "Cost:  0.3452264571599332 Train Accuracy: 19.255555555555556\n",
            "validation cost: 0.34340233219729643 Validation accuracy: 19.24\n",
            "Iteration: 437\n",
            "Iteration: 438\n",
            "Cost:  0.3449311213546048 Train Accuracy: 19.264444444444447\n",
            "validation cost: 0.3431085260397553 Validation accuracy: 19.24\n",
            "Iteration: 439\n",
            "Iteration: 440\n",
            "Cost:  0.3446376040777574 Train Accuracy: 19.27777777777778\n",
            "validation cost: 0.34281694586462624 Validation accuracy: 19.28\n",
            "Iteration: 441\n",
            "Iteration: 442\n",
            "Cost:  0.34434575547222324 Train Accuracy: 19.288888888888888\n",
            "validation cost: 0.34252578247419596 Validation accuracy: 19.259999999999998\n",
            "Iteration: 443\n",
            "Iteration: 444\n",
            "Cost:  0.3440556553649146 Train Accuracy: 19.315555555555555\n",
            "validation cost: 0.34223721404186597 Validation accuracy: 19.28\n",
            "Iteration: 445\n",
            "Iteration: 446\n",
            "Cost:  0.34376735203218833 Train Accuracy: 19.33111111111111\n",
            "validation cost: 0.34195063577484225 Validation accuracy: 19.34\n",
            "Iteration: 447\n",
            "Iteration: 448\n",
            "Cost:  0.3434807422653473 Train Accuracy: 19.34\n",
            "validation cost: 0.34166621517857243 Validation accuracy: 19.36\n",
            "Iteration: 449\n",
            "Iteration: 450\n",
            "Cost:  0.34319585490106697 Train Accuracy: 19.36\n",
            "validation cost: 0.3413819682375959 Validation accuracy: 19.38\n",
            "Iteration: 451\n",
            "Iteration: 452\n",
            "Cost:  0.34291257352324017 Train Accuracy: 19.38\n",
            "validation cost: 0.3410989963472549 Validation accuracy: 19.400000000000002\n",
            "Iteration: 453\n",
            "Iteration: 454\n",
            "Cost:  0.34263102429863107 Train Accuracy: 19.38\n",
            "validation cost: 0.34081877787588094 Validation accuracy: 19.42\n",
            "Iteration: 455\n",
            "Iteration: 456\n",
            "Cost:  0.34235110843139877 Train Accuracy: 19.38888888888889\n",
            "validation cost: 0.34053963117112535 Validation accuracy: 19.38\n",
            "Iteration: 457\n",
            "Iteration: 458\n",
            "Cost:  0.34207276537783043 Train Accuracy: 19.391111111111112\n",
            "validation cost: 0.34026377742016833 Validation accuracy: 19.439999999999998\n",
            "Iteration: 459\n",
            "Iteration: 460\n",
            "Cost:  0.34179610643611313 Train Accuracy: 19.413333333333334\n",
            "validation cost: 0.3399880138917164 Validation accuracy: 19.5\n",
            "Iteration: 461\n",
            "Iteration: 462\n",
            "Cost:  0.3415210801490329 Train Accuracy: 19.435555555555556\n",
            "validation cost: 0.3397146411282558 Validation accuracy: 19.52\n",
            "Iteration: 463\n",
            "Iteration: 464\n",
            "Cost:  0.34124755305125476 Train Accuracy: 19.45777777777778\n",
            "validation cost: 0.339442840799682 Validation accuracy: 19.52\n",
            "Iteration: 465\n",
            "Iteration: 466\n",
            "Cost:  0.34097567250572286 Train Accuracy: 19.482222222222223\n",
            "validation cost: 0.3391725064039287 Validation accuracy: 19.5\n",
            "Iteration: 467\n",
            "Iteration: 468\n",
            "Cost:  0.34070528328411587 Train Accuracy: 19.506666666666668\n",
            "validation cost: 0.3389021428441978 Validation accuracy: 19.56\n",
            "Iteration: 469\n",
            "Iteration: 470\n",
            "Cost:  0.34043641396360835 Train Accuracy: 19.513333333333332\n",
            "validation cost: 0.338635723052978 Validation accuracy: 19.62\n",
            "Iteration: 471\n",
            "Iteration: 472\n",
            "Cost:  0.3401691241443007 Train Accuracy: 19.524444444444445\n",
            "validation cost: 0.3383703260084297 Validation accuracy: 19.6\n",
            "Iteration: 473\n",
            "Iteration: 474\n",
            "Cost:  0.3399033750793791 Train Accuracy: 19.54888888888889\n",
            "validation cost: 0.3381058114157462 Validation accuracy: 19.66\n",
            "Iteration: 475\n",
            "Iteration: 476\n",
            "Cost:  0.33963908774522533 Train Accuracy: 19.557777777777776\n",
            "validation cost: 0.3378431184126099 Validation accuracy: 19.7\n",
            "Iteration: 477\n",
            "Iteration: 478\n",
            "Cost:  0.3393762746337131 Train Accuracy: 19.586666666666666\n",
            "validation cost: 0.33758188302776515 Validation accuracy: 19.7\n",
            "Iteration: 479\n",
            "Iteration: 480\n",
            "Cost:  0.33911488535765244 Train Accuracy: 19.60222222222222\n",
            "validation cost: 0.33732122964203815 Validation accuracy: 19.72\n",
            "Iteration: 481\n",
            "Iteration: 482\n",
            "Cost:  0.33885510942635966 Train Accuracy: 19.624444444444443\n",
            "validation cost: 0.3370630254418169 Validation accuracy: 19.759999999999998\n",
            "Iteration: 483\n",
            "Iteration: 484\n",
            "Cost:  0.3385965805662799 Train Accuracy: 19.633333333333333\n",
            "validation cost: 0.33680563423159854 Validation accuracy: 19.78\n",
            "Iteration: 485\n",
            "Iteration: 486\n",
            "Cost:  0.33833959989056345 Train Accuracy: 19.642222222222223\n",
            "validation cost: 0.3365508709379108 Validation accuracy: 19.759999999999998\n",
            "Iteration: 487\n",
            "Iteration: 488\n",
            "Cost:  0.3380839947859997 Train Accuracy: 19.65111111111111\n",
            "validation cost: 0.3362957645049699 Validation accuracy: 19.78\n",
            "Iteration: 489\n",
            "Iteration: 490\n",
            "Cost:  0.3378298225764698 Train Accuracy: 19.662222222222223\n",
            "validation cost: 0.3360435578441253 Validation accuracy: 19.86\n",
            "Iteration: 491\n",
            "Iteration: 492\n",
            "Cost:  0.3375771171450443 Train Accuracy: 19.68888888888889\n",
            "validation cost: 0.33579241432302026 Validation accuracy: 19.86\n",
            "Iteration: 493\n",
            "Iteration: 494\n",
            "Cost:  0.3373256576631455 Train Accuracy: 19.702222222222222\n",
            "validation cost: 0.33554284804924545 Validation accuracy: 19.88\n",
            "Iteration: 495\n",
            "Iteration: 496\n",
            "Cost:  0.3370756457405906 Train Accuracy: 19.71333333333333\n",
            "validation cost: 0.33529391120990704 Validation accuracy: 19.86\n",
            "Iteration: 497\n",
            "Iteration: 498\n",
            "Cost:  0.3368268957458266 Train Accuracy: 19.72\n",
            "validation cost: 0.3350467585150995 Validation accuracy: 19.900000000000002\n",
            "Iteration: 499\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "mlp_noh.fit_btch(lr=0.01, nitr= 500, alpha=0, beta=0, tol=5, epsilon=1e-5)\n",
        "t2 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6ZBeo9xoJsc",
        "outputId": "efb08c4f-7362-4164-d8ec-b9454a45d341"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20.119999999999997, 0.33889570300388094)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_noh.evaluate_acc(x_test_vector, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6T7a3j104vQ"
      },
      "outputs": [],
      "source": [
        "mlp_noh_perf = {'test_perf': mlp_noh.evaluate_acc(x_test_vector, test_y), 'train_time': t2-t1,\n",
        "            'train_cost': mlp_noh.costs, 'val_cost': mlp_noh.val_costs}\n",
        "with open('mlp_noh.pickle', 'wb') as h:\n",
        "    pickle.dump(mlp_noh_perf, h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bijhsjQb02qk"
      },
      "outputs": [],
      "source": [
        "del file\n",
        "file = drive.CreateFile()\n",
        "file.SetContentFile('mlp_noh.pickle')\n",
        "file.Upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc08Sc3s2DOz"
      },
      "source": [
        "### One 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-dv4EJzoLur"
      },
      "outputs": [],
      "source": [
        "# One 256\n",
        "\n",
        "mlp_1 = MLP(activation_func = relu, activation_deriv= relu_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 256, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEBXgsKGoLuu",
        "outputId": "d1c8c08e-3e41-40f1-ae3d-b00dbd71c3c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Cost:  0.4032823796907152 Train Accuracy: 11.233333333333333\n",
            "validation cost: 0.4086227704511434 Validation accuracy: 11.28\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Cost:  0.34758876458850946 Train Accuracy: 13.764444444444447\n",
            "validation cost: 0.3520026498009855 Validation accuracy: 13.26\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Cost:  0.32536138512979357 Train Accuracy: 15.293333333333333\n",
            "validation cost: 0.3296924191418259 Validation accuracy: 14.26\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Cost:  0.30960022696561407 Train Accuracy: 16.497777777777777\n",
            "validation cost: 0.3138044098415419 Validation accuracy: 15.659999999999998\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Cost:  0.29778029475518514 Train Accuracy: 17.551111111111112\n",
            "validation cost: 0.30189445140628957 Validation accuracy: 16.5\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Cost:  0.2886913344075842 Train Accuracy: 18.486666666666668\n",
            "validation cost: 0.29273531695586047 Validation accuracy: 17.119999999999997\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Cost:  0.2814846696119501 Train Accuracy: 19.12222222222222\n",
            "validation cost: 0.28534812724704706 Validation accuracy: 17.7\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Cost:  0.2756581649239711 Train Accuracy: 19.90222222222222\n",
            "validation cost: 0.27941207856333017 Validation accuracy: 18.3\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Cost:  0.270798974438599 Train Accuracy: 20.52\n",
            "validation cost: 0.2744342441552409 Validation accuracy: 18.98\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Cost:  0.2666065068217015 Train Accuracy: 20.979999999999997\n",
            "validation cost: 0.2701530933138266 Validation accuracy: 19.36\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Cost:  0.26295977757156797 Train Accuracy: 21.49111111111111\n",
            "validation cost: 0.2664007879666478 Validation accuracy: 19.96\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Cost:  0.25970679010407993 Train Accuracy: 21.824444444444442\n",
            "validation cost: 0.2631263033703154 Validation accuracy: 20.44\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Cost:  0.25680565385688325 Train Accuracy: 22.186666666666667\n",
            "validation cost: 0.26015771580593017 Validation accuracy: 20.86\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Cost:  0.2541718150192788 Train Accuracy: 22.57111111111111\n",
            "validation cost: 0.25751378408009384 Validation accuracy: 21.34\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Cost:  0.25177410007321255 Train Accuracy: 22.939999999999998\n",
            "validation cost: 0.2551013828185425 Validation accuracy: 21.740000000000002\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Cost:  0.24957690781795952 Train Accuracy: 23.21777777777778\n",
            "validation cost: 0.25292591281144244 Validation accuracy: 22.3\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Cost:  0.24754251014988563 Train Accuracy: 23.646666666666665\n",
            "validation cost: 0.25093145089635216 Validation accuracy: 22.56\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Cost:  0.24564349913767847 Train Accuracy: 23.942222222222224\n",
            "validation cost: 0.2489989720430948 Validation accuracy: 22.720000000000002\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Cost:  0.24391321839725494 Train Accuracy: 24.213333333333335\n",
            "validation cost: 0.24728589075941712 Validation accuracy: 22.98\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Cost:  0.24227718005912838 Train Accuracy: 24.477777777777778\n",
            "validation cost: 0.24568136196821352 Validation accuracy: 23.1\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Cost:  0.24072152597083007 Train Accuracy: 24.66\n",
            "validation cost: 0.2441251357968976 Validation accuracy: 23.34\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Cost:  0.23926888436954155 Train Accuracy: 24.844444444444445\n",
            "validation cost: 0.24271309161679977 Validation accuracy: 23.54\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Cost:  0.23789094104217115 Train Accuracy: 25.135555555555555\n",
            "validation cost: 0.24138692092443093 Validation accuracy: 23.799999999999997\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Cost:  0.23660667989737275 Train Accuracy: 25.308888888888887\n",
            "validation cost: 0.24008068049741893 Validation accuracy: 23.94\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Cost:  0.23535075648609055 Train Accuracy: 25.493333333333336\n",
            "validation cost: 0.23888655419965987 Validation accuracy: 24.2\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Cost:  0.23418600773073978 Train Accuracy: 25.666666666666664\n",
            "validation cost: 0.2377027810594826 Validation accuracy: 24.44\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Cost:  0.23306863590909976 Train Accuracy: 25.85777777777778\n",
            "validation cost: 0.23658407522393515 Validation accuracy: 24.52\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Cost:  0.23200705769253643 Train Accuracy: 26.046666666666667\n",
            "validation cost: 0.2355336640725106 Validation accuracy: 24.959999999999997\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Cost:  0.23098230709263531 Train Accuracy: 26.211111111111112\n",
            "validation cost: 0.23455138976539008 Validation accuracy: 25.019999999999996\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Cost:  0.23002245778540806 Train Accuracy: 26.337777777777777\n",
            "validation cost: 0.23357764872243064 Validation accuracy: 25.34\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Cost:  0.22906664141762165 Train Accuracy: 26.51777777777778\n",
            "validation cost: 0.2326183990633209 Validation accuracy: 25.4\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Cost:  0.22817106188834776 Train Accuracy: 26.68888888888889\n",
            "validation cost: 0.23172428249245 Validation accuracy: 25.64\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Cost:  0.22730465937280458 Train Accuracy: 26.793333333333337\n",
            "validation cost: 0.23084607840826427 Validation accuracy: 25.779999999999998\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Cost:  0.22650011313701449 Train Accuracy: 26.886666666666663\n",
            "validation cost: 0.23002366815346573 Validation accuracy: 26.22\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Cost:  0.2256553796634299 Train Accuracy: 27.157777777777774\n",
            "validation cost: 0.22921067370900045 Validation accuracy: 26.040000000000003\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Cost:  0.22488159800999027 Train Accuracy: 27.284444444444446\n",
            "validation cost: 0.22845045822795157 Validation accuracy: 26.179999999999996\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Cost:  0.2241411611987823 Train Accuracy: 27.404444444444444\n",
            "validation cost: 0.22771865636382704 Validation accuracy: 26.38\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Cost:  0.22343244186721375 Train Accuracy: 27.535555555555558\n",
            "validation cost: 0.22700153556296104 Validation accuracy: 26.56\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Cost:  0.22269253442826767 Train Accuracy: 27.684444444444445\n",
            "validation cost: 0.22622554985192878 Validation accuracy: 26.58\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Cost:  0.2220064578686143 Train Accuracy: 27.78888888888889\n",
            "validation cost: 0.22553967239952077 Validation accuracy: 26.76\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Cost:  0.22134161643366326 Train Accuracy: 27.897777777777776\n",
            "validation cost: 0.22483512164666516 Validation accuracy: 26.86\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Cost:  0.22068609498071518 Train Accuracy: 27.953333333333337\n",
            "validation cost: 0.22418767877739512 Validation accuracy: 27.08\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Cost:  0.22005986405440361 Train Accuracy: 28.191111111111113\n",
            "validation cost: 0.2235834928316605 Validation accuracy: 27.24\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Cost:  0.21944896248351844 Train Accuracy: 28.304444444444442\n",
            "validation cost: 0.22296541518762966 Validation accuracy: 27.339999999999996\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Cost:  0.2188583188119853 Train Accuracy: 28.475555555555555\n",
            "validation cost: 0.22239838008332966 Validation accuracy: 27.52\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Cost:  0.21826466969147978 Train Accuracy: 28.531111111111112\n",
            "validation cost: 0.2218103154822146 Validation accuracy: 27.48\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Cost:  0.21770584789619113 Train Accuracy: 28.626666666666665\n",
            "validation cost: 0.22125879983485439 Validation accuracy: 27.46\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Cost:  0.2171401066490965 Train Accuracy: 28.735555555555553\n",
            "validation cost: 0.22073791204913404 Validation accuracy: 27.92\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Cost:  0.21659536909000482 Train Accuracy: 28.837777777777777\n",
            "validation cost: 0.22019008456169983 Validation accuracy: 27.779999999999998\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Cost:  0.2160651388240067 Train Accuracy: 28.95111111111111\n",
            "validation cost: 0.2196772141787468 Validation accuracy: 28.1\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Cost:  0.21556116023568475 Train Accuracy: 29.035555555555554\n",
            "validation cost: 0.21919170982339806 Validation accuracy: 27.98\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Cost:  0.21506275245372192 Train Accuracy: 29.153333333333332\n",
            "validation cost: 0.21873442939393162 Validation accuracy: 28.1\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Cost:  0.21458445985668134 Train Accuracy: 29.26666666666667\n",
            "validation cost: 0.21825986048115648 Validation accuracy: 28.060000000000002\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Cost:  0.2141275662722904 Train Accuracy: 29.331111111111113\n",
            "validation cost: 0.21782448366004198 Validation accuracy: 28.26\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Cost:  0.21364034577069904 Train Accuracy: 29.42666666666667\n",
            "validation cost: 0.21734020894171666 Validation accuracy: 28.1\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Cost:  0.2131947476048957 Train Accuracy: 29.513333333333335\n",
            "validation cost: 0.21689517376240353 Validation accuracy: 28.199999999999996\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Cost:  0.21275591402533836 Train Accuracy: 29.54\n",
            "validation cost: 0.21646349658373729 Validation accuracy: 28.22\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Cost:  0.21233735510888538 Train Accuracy: 29.688888888888886\n",
            "validation cost: 0.21606440212704514 Validation accuracy: 28.26\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Cost:  0.211909903216043 Train Accuracy: 29.81111111111111\n",
            "validation cost: 0.21563129313568505 Validation accuracy: 28.46\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Cost:  0.21151313903866698 Train Accuracy: 29.86888888888889\n",
            "validation cost: 0.2152516443055568 Validation accuracy: 28.439999999999998\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Cost:  0.21110837811752575 Train Accuracy: 29.944444444444446\n",
            "validation cost: 0.21486636640803725 Validation accuracy: 28.62\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Cost:  0.21072586568419963 Train Accuracy: 30.046666666666667\n",
            "validation cost: 0.21450727565331446 Validation accuracy: 28.62\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Cost:  0.2103261706575103 Train Accuracy: 30.122222222222224\n",
            "validation cost: 0.2140876274918676 Validation accuracy: 28.660000000000004\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Cost:  0.20995228582135256 Train Accuracy: 30.21333333333333\n",
            "validation cost: 0.21370317840112646 Validation accuracy: 28.84\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Cost:  0.20957684277377944 Train Accuracy: 30.366666666666664\n",
            "validation cost: 0.21335640250576052 Validation accuracy: 29.099999999999998\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Cost:  0.2092190432970644 Train Accuracy: 30.44\n",
            "validation cost: 0.21299449439552898 Validation accuracy: 29.26\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Cost:  0.2088804744978948 Train Accuracy: 30.495555555555555\n",
            "validation cost: 0.21264344584912323 Validation accuracy: 29.080000000000002\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Cost:  0.20851018483982456 Train Accuracy: 30.54222222222222\n",
            "validation cost: 0.21227352338488273 Validation accuracy: 29.26\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Cost:  0.20817037278062464 Train Accuracy: 30.591111111111115\n",
            "validation cost: 0.21193167254803608 Validation accuracy: 29.520000000000003\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Cost:  0.20784590808893577 Train Accuracy: 30.63777777777778\n",
            "validation cost: 0.211565838478936 Validation accuracy: 29.26\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Cost:  0.20749876273650059 Train Accuracy: 30.744444444444447\n",
            "validation cost: 0.21123880874582723 Validation accuracy: 29.48\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Cost:  0.20717945084835065 Train Accuracy: 30.777777777777775\n",
            "validation cost: 0.21094074626405288 Validation accuracy: 29.62\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Cost:  0.20686034385861202 Train Accuracy: 30.877777777777776\n",
            "validation cost: 0.2106140637186077 Validation accuracy: 29.7\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Cost:  0.20655056493224158 Train Accuracy: 30.835555555555555\n",
            "validation cost: 0.21024788094204938 Validation accuracy: 29.64\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Cost:  0.20622360329744072 Train Accuracy: 30.891111111111115\n",
            "validation cost: 0.20993179731428308 Validation accuracy: 29.7\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Cost:  0.20591238010805205 Train Accuracy: 31.04\n",
            "validation cost: 0.20960773634231408 Validation accuracy: 29.78\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Cost:  0.20562005446634948 Train Accuracy: 31.115555555555556\n",
            "validation cost: 0.20931579086002075 Validation accuracy: 29.9\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Cost:  0.20529591422555932 Train Accuracy: 31.153333333333332\n",
            "validation cost: 0.20897985327992397 Validation accuracy: 30.04\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "Cost:  0.20501616030068848 Train Accuracy: 31.22666666666667\n",
            "validation cost: 0.20872998315418986 Validation accuracy: 30.0\n",
            "Iteration: 157\n",
            "Iteration: 158\n",
            "Cost:  0.2046969257044252 Train Accuracy: 31.275555555555556\n",
            "validation cost: 0.20839554951222625 Validation accuracy: 30.099999999999998\n",
            "Iteration: 159\n",
            "Iteration: 160\n",
            "Cost:  0.20440380842784545 Train Accuracy: 31.295555555555556\n",
            "validation cost: 0.20807699650706135 Validation accuracy: 29.98\n",
            "Iteration: 161\n",
            "Iteration: 162\n",
            "Cost:  0.20413848058038278 Train Accuracy: 31.39777777777778\n",
            "validation cost: 0.20782577174591074 Validation accuracy: 30.080000000000002\n",
            "Iteration: 163\n",
            "Iteration: 164\n",
            "Cost:  0.2038365068441168 Train Accuracy: 31.47333333333333\n",
            "validation cost: 0.20749484279018446 Validation accuracy: 30.12\n",
            "Iteration: 165\n",
            "Iteration: 166\n",
            "Cost:  0.2035759680964778 Train Accuracy: 31.575555555555557\n",
            "validation cost: 0.20726814211893863 Validation accuracy: 30.36\n",
            "Iteration: 167\n",
            "Iteration: 168\n",
            "Cost:  0.20328690289152349 Train Accuracy: 31.61111111111111\n",
            "validation cost: 0.2069529536899718 Validation accuracy: 30.36\n",
            "Iteration: 169\n",
            "Iteration: 170\n",
            "Cost:  0.2030272729419143 Train Accuracy: 31.73111111111111\n",
            "validation cost: 0.20668419031407037 Validation accuracy: 30.44\n",
            "Iteration: 171\n",
            "Iteration: 172\n",
            "Cost:  0.20276285110398765 Train Accuracy: 31.724444444444444\n",
            "validation cost: 0.20640845246722936 Validation accuracy: 30.44\n",
            "Iteration: 173\n",
            "Iteration: 174\n",
            "Cost:  0.20250594333542413 Train Accuracy: 31.79777777777778\n",
            "validation cost: 0.20616331986487318 Validation accuracy: 30.580000000000002\n",
            "Iteration: 175\n",
            "Iteration: 176\n",
            "Cost:  0.20224247826611605 Train Accuracy: 31.864444444444445\n",
            "validation cost: 0.20590014340495497 Validation accuracy: 30.56\n",
            "Iteration: 177\n",
            "Iteration: 178\n",
            "Cost:  0.201994397060759 Train Accuracy: 31.973333333333333\n",
            "validation cost: 0.20565363711343493 Validation accuracy: 30.659999999999997\n",
            "Iteration: 179\n",
            "Iteration: 180\n",
            "Cost:  0.201761017835451 Train Accuracy: 32.019999999999996\n",
            "validation cost: 0.2054254391109426 Validation accuracy: 30.599999999999998\n",
            "Iteration: 181\n",
            "Iteration: 182\n",
            "Cost:  0.2015062158311947 Train Accuracy: 32.07111111111111\n",
            "validation cost: 0.20517366161098263 Validation accuracy: 30.759999999999998\n",
            "Iteration: 183\n",
            "Iteration: 184\n",
            "Cost:  0.20126718450147824 Train Accuracy: 32.18666666666667\n",
            "validation cost: 0.20495477481951355 Validation accuracy: 30.8\n",
            "Iteration: 185\n",
            "Iteration: 186\n",
            "Cost:  0.20102525304772503 Train Accuracy: 32.16444444444445\n",
            "validation cost: 0.2047012750482788 Validation accuracy: 31.019999999999996\n",
            "Iteration: 187\n",
            "Iteration: 188\n",
            "Cost:  0.20079290962256016 Train Accuracy: 32.18222222222222\n",
            "validation cost: 0.2044929900525539 Validation accuracy: 30.759999999999998\n",
            "Iteration: 189\n",
            "Iteration: 190\n",
            "Cost:  0.20056138599113912 Train Accuracy: 32.24666666666667\n",
            "validation cost: 0.2042613101808501 Validation accuracy: 30.94\n",
            "Iteration: 191\n",
            "Iteration: 192\n",
            "Cost:  0.2003282271237264 Train Accuracy: 32.28\n",
            "validation cost: 0.2040397554695994 Validation accuracy: 31.1\n",
            "Iteration: 193\n",
            "Iteration: 194\n",
            "Cost:  0.20010371736161528 Train Accuracy: 32.379999999999995\n",
            "validation cost: 0.20381927654868215 Validation accuracy: 31.180000000000003\n",
            "Iteration: 195\n",
            "Iteration: 196\n",
            "Cost:  0.19988366766235624 Train Accuracy: 32.37111111111111\n",
            "validation cost: 0.20360326358595957 Validation accuracy: 31.16\n",
            "Iteration: 197\n",
            "Iteration: 198\n",
            "Cost:  0.1996883487595827 Train Accuracy: 32.48222222222223\n",
            "validation cost: 0.20343244004826208 Validation accuracy: 31.240000000000002\n",
            "Iteration: 199\n",
            "Iteration: 200\n",
            "Cost:  0.19945745293665249 Train Accuracy: 32.51555555555555\n",
            "validation cost: 0.20320665409865382 Validation accuracy: 31.180000000000003\n",
            "Iteration: 201\n",
            "Iteration: 202\n",
            "Cost:  0.19926380144800887 Train Accuracy: 32.58\n",
            "validation cost: 0.2030114867376821 Validation accuracy: 31.34\n",
            "Iteration: 203\n",
            "Iteration: 204\n",
            "Cost:  0.19904523605199084 Train Accuracy: 32.62\n",
            "validation cost: 0.20278700404483613 Validation accuracy: 31.34\n",
            "Iteration: 205\n",
            "Iteration: 206\n",
            "Cost:  0.19882554964891103 Train Accuracy: 32.56888888888889\n",
            "validation cost: 0.20258047344601718 Validation accuracy: 31.380000000000003\n",
            "Iteration: 207\n",
            "Iteration: 208\n",
            "Cost:  0.19862024525598834 Train Accuracy: 32.70666666666667\n",
            "validation cost: 0.20237934859992182 Validation accuracy: 31.380000000000003\n",
            "Iteration: 209\n",
            "Iteration: 210\n",
            "Cost:  0.19842603572043183 Train Accuracy: 32.67111111111111\n",
            "validation cost: 0.2022094619654381 Validation accuracy: 31.52\n",
            "Iteration: 211\n",
            "Iteration: 212\n",
            "Cost:  0.19823392969193196 Train Accuracy: 32.83111111111111\n",
            "validation cost: 0.2020384214750586 Validation accuracy: 31.34\n",
            "Iteration: 213\n",
            "Iteration: 214\n",
            "Cost:  0.19802239975032018 Train Accuracy: 32.824444444444445\n",
            "validation cost: 0.20180210589315725 Validation accuracy: 31.580000000000002\n",
            "Iteration: 215\n",
            "Iteration: 216\n",
            "Cost:  0.19783932191373582 Train Accuracy: 32.89333333333334\n",
            "validation cost: 0.20161595086642572 Validation accuracy: 31.52\n",
            "Iteration: 217\n",
            "Iteration: 218\n",
            "Cost:  0.1976342303253812 Train Accuracy: 32.92666666666666\n",
            "validation cost: 0.2014294426680126 Validation accuracy: 31.5\n",
            "Iteration: 219\n",
            "Iteration: 220\n",
            "Cost:  0.1974488987275566 Train Accuracy: 32.89111111111111\n",
            "validation cost: 0.20124231552730795 Validation accuracy: 31.580000000000002\n",
            "Iteration: 221\n",
            "Iteration: 222\n",
            "Cost:  0.1972591511170229 Train Accuracy: 33.01777777777778\n",
            "validation cost: 0.20105106325516547 Validation accuracy: 31.7\n",
            "Iteration: 223\n",
            "Iteration: 224\n",
            "Cost:  0.1970678172498549 Train Accuracy: 33.044444444444444\n",
            "validation cost: 0.2008867623465173 Validation accuracy: 31.7\n",
            "Iteration: 225\n",
            "Iteration: 226\n",
            "Cost:  0.196883652242931 Train Accuracy: 33.08888888888889\n",
            "validation cost: 0.2007147671885516 Validation accuracy: 31.819999999999997\n",
            "Iteration: 227\n",
            "Iteration: 228\n",
            "Cost:  0.19669968841771018 Train Accuracy: 33.193333333333335\n",
            "validation cost: 0.2005297321021469 Validation accuracy: 31.7\n",
            "Iteration: 229\n",
            "Iteration: 230\n",
            "Cost:  0.196520884595383 Train Accuracy: 33.19111111111111\n",
            "validation cost: 0.20035535881481836 Validation accuracy: 31.819999999999997\n",
            "Iteration: 231\n",
            "Iteration: 232\n",
            "Cost:  0.19635767546392308 Train Accuracy: 33.22\n",
            "validation cost: 0.20021170541479003 Validation accuracy: 31.64\n",
            "Iteration: 233\n",
            "Iteration: 234\n",
            "Cost:  0.1961666351032898 Train Accuracy: 33.33555555555556\n",
            "validation cost: 0.20004843034010344 Validation accuracy: 31.879999999999995\n",
            "Iteration: 235\n",
            "Iteration: 236\n",
            "Cost:  0.19598850134756873 Train Accuracy: 33.33333333333333\n",
            "validation cost: 0.19985210071779677 Validation accuracy: 31.919999999999998\n",
            "Iteration: 237\n",
            "Iteration: 238\n",
            "Cost:  0.19581944493785913 Train Accuracy: 33.39555555555555\n",
            "validation cost: 0.19968759212133463 Validation accuracy: 31.979999999999997\n",
            "Iteration: 239\n",
            "Iteration: 240\n",
            "Cost:  0.19564449084837165 Train Accuracy: 33.44888888888889\n",
            "validation cost: 0.19952807842722545 Validation accuracy: 32.0\n",
            "Iteration: 241\n",
            "Iteration: 242\n",
            "Cost:  0.1954707293987266 Train Accuracy: 33.437777777777775\n",
            "validation cost: 0.19937480788185036 Validation accuracy: 32.04\n",
            "Iteration: 243\n",
            "Iteration: 244\n",
            "Cost:  0.1953119653789915 Train Accuracy: 33.50666666666667\n",
            "validation cost: 0.1992209901185763 Validation accuracy: 32.0\n",
            "Iteration: 245\n",
            "Iteration: 246\n",
            "Cost:  0.19513984244856003 Train Accuracy: 33.48888888888889\n",
            "validation cost: 0.199061500873066 Validation accuracy: 31.919999999999998\n",
            "Iteration: 247\n",
            "Iteration: 248\n",
            "Cost:  0.19497757549152694 Train Accuracy: 33.602222222222224\n",
            "validation cost: 0.1988934144879661 Validation accuracy: 32.2\n",
            "Iteration: 249\n",
            "Iteration: 250\n",
            "Cost:  0.19481033557659444 Train Accuracy: 33.62444444444444\n",
            "validation cost: 0.19873394140644893 Validation accuracy: 32.18\n",
            "Iteration: 251\n",
            "Iteration: 252\n",
            "Cost:  0.1946454297952734 Train Accuracy: 33.63333333333333\n",
            "validation cost: 0.19857390013924675 Validation accuracy: 32.26\n",
            "Iteration: 253\n",
            "Iteration: 254\n",
            "Cost:  0.19448827967298077 Train Accuracy: 33.68888888888889\n",
            "validation cost: 0.19844088296998813 Validation accuracy: 32.24\n",
            "Iteration: 255\n",
            "Iteration: 256\n",
            "Cost:  0.1943313911108073 Train Accuracy: 33.72666666666667\n",
            "validation cost: 0.19829463088704516 Validation accuracy: 32.379999999999995\n",
            "Iteration: 257\n",
            "Iteration: 258\n",
            "Cost:  0.1941663575351436 Train Accuracy: 33.77333333333333\n",
            "validation cost: 0.1981262118502022 Validation accuracy: 32.34\n",
            "Iteration: 259\n",
            "Iteration: 260\n",
            "Cost:  0.1940115550022797 Train Accuracy: 33.77333333333333\n",
            "validation cost: 0.19797833575190732 Validation accuracy: 32.56\n",
            "Iteration: 261\n",
            "Iteration: 262\n",
            "Cost:  0.1938600174965105 Train Accuracy: 33.85333333333334\n",
            "validation cost: 0.1978284338910004 Validation accuracy: 32.54\n",
            "Iteration: 263\n",
            "Iteration: 264\n",
            "Cost:  0.19369295897088346 Train Accuracy: 33.91111111111111\n",
            "validation cost: 0.1976750977585297 Validation accuracy: 32.5\n",
            "Iteration: 265\n",
            "Iteration: 266\n",
            "Cost:  0.1935685566700678 Train Accuracy: 33.937777777777775\n",
            "validation cost: 0.19754960786372744 Validation accuracy: 32.34\n",
            "Iteration: 267\n",
            "Iteration: 268\n",
            "Cost:  0.19339104936159657 Train Accuracy: 33.99111111111111\n",
            "validation cost: 0.19736358281031896 Validation accuracy: 32.62\n",
            "Iteration: 269\n",
            "Iteration: 270\n",
            "Cost:  0.19323336145406886 Train Accuracy: 34.04222222222222\n",
            "validation cost: 0.19722950086930796 Validation accuracy: 32.64\n",
            "Iteration: 271\n",
            "Iteration: 272\n",
            "Cost:  0.19308501805211897 Train Accuracy: 34.062222222222225\n",
            "validation cost: 0.19708280465971126 Validation accuracy: 32.800000000000004\n",
            "Iteration: 273\n",
            "Iteration: 274\n",
            "Cost:  0.1929380042821579 Train Accuracy: 34.10444444444444\n",
            "validation cost: 0.19694241531803772 Validation accuracy: 32.74\n",
            "Iteration: 275\n",
            "Iteration: 276\n",
            "Cost:  0.19279008558977637 Train Accuracy: 34.14222222222222\n",
            "validation cost: 0.19678807334298024 Validation accuracy: 32.86\n",
            "Iteration: 277\n",
            "Iteration: 278\n",
            "Cost:  0.19265012940629744 Train Accuracy: 34.16222222222222\n",
            "validation cost: 0.19666504189744155 Validation accuracy: 32.98\n",
            "Iteration: 279\n",
            "Iteration: 280\n",
            "Cost:  0.19250015757403602 Train Accuracy: 34.24666666666666\n",
            "validation cost: 0.19652094264688025 Validation accuracy: 33.06\n",
            "Iteration: 281\n",
            "Iteration: 282\n",
            "Cost:  0.19235469449114836 Train Accuracy: 34.31111111111111\n",
            "validation cost: 0.19637337881675204 Validation accuracy: 33.1\n",
            "Iteration: 283\n",
            "Iteration: 284\n",
            "Cost:  0.1922120309888827 Train Accuracy: 34.28\n",
            "validation cost: 0.19623397908424664 Validation accuracy: 33.08\n",
            "Iteration: 285\n",
            "Iteration: 286\n",
            "Cost:  0.192076668901437 Train Accuracy: 34.4\n",
            "validation cost: 0.19613278779452728 Validation accuracy: 33.28\n",
            "Iteration: 287\n",
            "Iteration: 288\n",
            "Cost:  0.1919295567069378 Train Accuracy: 34.48222222222222\n",
            "validation cost: 0.19595769731037865 Validation accuracy: 33.36\n",
            "Iteration: 289\n",
            "Iteration: 290\n",
            "Cost:  0.19179252130686128 Train Accuracy: 34.49111111111111\n",
            "validation cost: 0.19583613347901904 Validation accuracy: 33.32\n",
            "Iteration: 291\n",
            "Iteration: 292\n",
            "Cost:  0.19165936969184613 Train Accuracy: 34.50222222222222\n",
            "validation cost: 0.19569268093235043 Validation accuracy: 33.32\n",
            "Iteration: 293\n",
            "Iteration: 294\n",
            "Cost:  0.19151330804315186 Train Accuracy: 34.553333333333335\n",
            "validation cost: 0.19555512377348117 Validation accuracy: 33.6\n",
            "Iteration: 295\n",
            "Iteration: 296\n",
            "Cost:  0.19138188513926846 Train Accuracy: 34.58222222222222\n",
            "validation cost: 0.19541139898364115 Validation accuracy: 33.56\n",
            "Iteration: 297\n",
            "Iteration: 298\n",
            "Cost:  0.1912428123926971 Train Accuracy: 34.55777777777777\n",
            "validation cost: 0.19530201155823967 Validation accuracy: 33.48\n",
            "Iteration: 299\n",
            "Iteration: 300\n",
            "Cost:  0.19110385246919334 Train Accuracy: 34.65111111111111\n",
            "validation cost: 0.19517668911693759 Validation accuracy: 33.42\n",
            "Iteration: 301\n",
            "Iteration: 302\n",
            "Cost:  0.19097783655820605 Train Accuracy: 34.64222222222222\n",
            "validation cost: 0.19506542957241857 Validation accuracy: 33.58\n",
            "Iteration: 303\n",
            "Iteration: 304\n",
            "Cost:  0.1908458580776902 Train Accuracy: 34.653333333333336\n",
            "validation cost: 0.19494134081482856 Validation accuracy: 33.6\n",
            "Iteration: 305\n",
            "Iteration: 306\n",
            "Cost:  0.1907162129270921 Train Accuracy: 34.72666666666667\n",
            "validation cost: 0.19480275713149903 Validation accuracy: 33.739999999999995\n",
            "Iteration: 307\n",
            "Iteration: 308\n",
            "Cost:  0.19058056665273745 Train Accuracy: 34.76222222222222\n",
            "validation cost: 0.19469041703203108 Validation accuracy: 33.72\n",
            "Iteration: 309\n",
            "Iteration: 310\n",
            "Cost:  0.19044890139889778 Train Accuracy: 34.79333333333333\n",
            "validation cost: 0.19455035442072396 Validation accuracy: 33.68\n",
            "Iteration: 311\n",
            "Iteration: 312\n",
            "Cost:  0.19032580420171796 Train Accuracy: 34.86666666666667\n",
            "validation cost: 0.19442042566397766 Validation accuracy: 33.86\n",
            "Iteration: 313\n",
            "Iteration: 314\n",
            "Cost:  0.19019766230600552 Train Accuracy: 34.87111111111111\n",
            "validation cost: 0.19431785643252933 Validation accuracy: 33.98\n",
            "Iteration: 315\n",
            "Iteration: 316\n",
            "Cost:  0.19008036636931527 Train Accuracy: 34.93333333333333\n",
            "validation cost: 0.19421604299806455 Validation accuracy: 33.879999999999995\n",
            "Iteration: 317\n",
            "Iteration: 318\n",
            "Cost:  0.18995035601574067 Train Accuracy: 34.94\n",
            "validation cost: 0.1940810746480464 Validation accuracy: 34.0\n",
            "Iteration: 319\n",
            "Iteration: 320\n",
            "Cost:  0.18982286935292644 Train Accuracy: 34.96\n",
            "validation cost: 0.19395772119192276 Validation accuracy: 34.06\n",
            "Iteration: 321\n",
            "Iteration: 322\n",
            "Cost:  0.1896982287039569 Train Accuracy: 35.03333333333333\n",
            "validation cost: 0.19384585033273485 Validation accuracy: 33.96\n",
            "Iteration: 323\n",
            "Iteration: 324\n",
            "Cost:  0.18957604450946675 Train Accuracy: 35.01777777777777\n",
            "validation cost: 0.19374129710006663 Validation accuracy: 33.879999999999995\n",
            "Iteration: 325\n",
            "Iteration: 326\n",
            "Cost:  0.1894506231738322 Train Accuracy: 35.05333333333333\n",
            "validation cost: 0.1936148392439758 Validation accuracy: 34.08\n",
            "Iteration: 327\n",
            "Iteration: 328\n",
            "Cost:  0.1893385557939352 Train Accuracy: 35.126666666666665\n",
            "validation cost: 0.1934972997907315 Validation accuracy: 34.239999999999995\n",
            "Iteration: 329\n",
            "Iteration: 330\n",
            "Cost:  0.18921584862862623 Train Accuracy: 35.14666666666667\n",
            "validation cost: 0.19337795751883805 Validation accuracy: 34.14\n",
            "Iteration: 331\n",
            "Iteration: 332\n",
            "Cost:  0.18909019020603804 Train Accuracy: 35.15111111111111\n",
            "validation cost: 0.19327140635712425 Validation accuracy: 34.22\n",
            "Iteration: 333\n",
            "Iteration: 334\n",
            "Cost:  0.1889918652322085 Train Accuracy: 35.21333333333334\n",
            "validation cost: 0.1931686506535039 Validation accuracy: 34.2\n",
            "Iteration: 335\n",
            "Iteration: 336\n",
            "Cost:  0.18886904723107534 Train Accuracy: 35.18666666666667\n",
            "validation cost: 0.1930745569327596 Validation accuracy: 34.22\n",
            "Iteration: 337\n",
            "Iteration: 338\n",
            "Cost:  0.1887396768176667 Train Accuracy: 35.275555555555556\n",
            "validation cost: 0.19295085906163495 Validation accuracy: 34.160000000000004\n",
            "Iteration: 339\n",
            "Iteration: 340\n",
            "Cost:  0.18862459507558502 Train Accuracy: 35.30888888888889\n",
            "validation cost: 0.1928305045454713 Validation accuracy: 34.28\n",
            "Iteration: 341\n",
            "Iteration: 342\n",
            "Cost:  0.18852347013084453 Train Accuracy: 35.37555555555556\n",
            "validation cost: 0.19275830191927093 Validation accuracy: 34.300000000000004\n",
            "Iteration: 343\n",
            "Iteration: 344\n",
            "Cost:  0.18839824687112172 Train Accuracy: 35.35111111111111\n",
            "validation cost: 0.1926124256145363 Validation accuracy: 34.48\n",
            "Iteration: 345\n",
            "Iteration: 346\n",
            "Cost:  0.18828601443186654 Train Accuracy: 35.404444444444444\n",
            "validation cost: 0.1925325699333117 Validation accuracy: 34.36\n",
            "Iteration: 347\n",
            "Iteration: 348\n",
            "Cost:  0.18818088486074114 Train Accuracy: 35.43333333333333\n",
            "validation cost: 0.19242895218883074 Validation accuracy: 34.46\n",
            "Iteration: 349\n",
            "Iteration: 350\n",
            "Cost:  0.18807248168364893 Train Accuracy: 35.40222222222222\n",
            "validation cost: 0.1923237904846657 Validation accuracy: 34.44\n",
            "Iteration: 351\n",
            "Iteration: 352\n",
            "Cost:  0.1879517860498888 Train Accuracy: 35.55777777777778\n",
            "validation cost: 0.19220075102043668 Validation accuracy: 34.56\n",
            "Iteration: 353\n",
            "Iteration: 354\n",
            "Cost:  0.18784445154433052 Train Accuracy: 35.57333333333334\n",
            "validation cost: 0.19211056859557413 Validation accuracy: 34.62\n",
            "Iteration: 355\n",
            "Iteration: 356\n",
            "Cost:  0.18773682033469338 Train Accuracy: 35.55555555555556\n",
            "validation cost: 0.19200599534754997 Validation accuracy: 34.44\n",
            "Iteration: 357\n",
            "Iteration: 358\n",
            "Cost:  0.18762652192122142 Train Accuracy: 35.62222222222222\n",
            "validation cost: 0.19190775058289453 Validation accuracy: 34.56\n",
            "Iteration: 359\n",
            "Iteration: 360\n",
            "Cost:  0.18751359645457935 Train Accuracy: 35.626666666666665\n",
            "validation cost: 0.19179361300922412 Validation accuracy: 34.660000000000004\n",
            "Iteration: 361\n",
            "Iteration: 362\n",
            "Cost:  0.18741227060967852 Train Accuracy: 35.63777777777778\n",
            "validation cost: 0.1917030781869767 Validation accuracy: 34.699999999999996\n",
            "Iteration: 363\n",
            "Iteration: 364\n",
            "Cost:  0.18731192919588047 Train Accuracy: 35.72666666666667\n",
            "validation cost: 0.19159889132542438 Validation accuracy: 34.62\n",
            "Iteration: 365\n",
            "Iteration: 366\n",
            "Cost:  0.18720184767337011 Train Accuracy: 35.751111111111115\n",
            "validation cost: 0.1915146874394593 Validation accuracy: 34.78\n",
            "Iteration: 367\n",
            "Iteration: 368\n",
            "Cost:  0.1870895724707795 Train Accuracy: 35.75555555555556\n",
            "validation cost: 0.19140392471251724 Validation accuracy: 34.72\n",
            "Iteration: 369\n",
            "Iteration: 370\n",
            "Cost:  0.18698546347997677 Train Accuracy: 35.75333333333333\n",
            "validation cost: 0.19129555313229993 Validation accuracy: 34.8\n",
            "Iteration: 371\n",
            "Iteration: 372\n",
            "Cost:  0.18689559968624286 Train Accuracy: 35.82888888888889\n",
            "validation cost: 0.19122069221473298 Validation accuracy: 34.74\n",
            "Iteration: 373\n",
            "Iteration: 374\n",
            "Cost:  0.18678681608401204 Train Accuracy: 35.82\n",
            "validation cost: 0.1911351581838857 Validation accuracy: 34.699999999999996\n",
            "Iteration: 375\n",
            "Iteration: 376\n",
            "Cost:  0.18668605649940903 Train Accuracy: 35.8\n",
            "validation cost: 0.19103164455335442 Validation accuracy: 34.699999999999996\n",
            "Iteration: 377\n",
            "Iteration: 378\n",
            "Cost:  0.18657852159820978 Train Accuracy: 35.864444444444445\n",
            "validation cost: 0.1909317329641906 Validation accuracy: 34.86\n",
            "Iteration: 379\n",
            "Iteration: 380\n",
            "Cost:  0.18647504554492564 Train Accuracy: 35.986666666666665\n",
            "validation cost: 0.19084103979509043 Validation accuracy: 34.86\n",
            "Iteration: 381\n",
            "Iteration: 382\n",
            "Cost:  0.1863736079098227 Train Accuracy: 35.95111111111111\n",
            "validation cost: 0.19073675242942387 Validation accuracy: 34.88\n",
            "Iteration: 383\n",
            "Iteration: 384\n",
            "Cost:  0.18628860484397503 Train Accuracy: 35.92666666666667\n",
            "validation cost: 0.1906665767994902 Validation accuracy: 34.9\n",
            "Iteration: 385\n",
            "Iteration: 386\n",
            "Cost:  0.1861768510469688 Train Accuracy: 35.977777777777774\n",
            "validation cost: 0.19055443853518966 Validation accuracy: 34.92\n",
            "Iteration: 387\n",
            "Iteration: 388\n",
            "Cost:  0.18607940118646873 Train Accuracy: 36.013333333333335\n",
            "validation cost: 0.19047673970110013 Validation accuracy: 35.0\n",
            "Iteration: 389\n",
            "Iteration: 390\n",
            "Cost:  0.18598634297380612 Train Accuracy: 36.02444444444444\n",
            "validation cost: 0.1903795373561644 Validation accuracy: 34.94\n",
            "Iteration: 391\n",
            "Iteration: 392\n",
            "Cost:  0.18587886193389422 Train Accuracy: 36.06666666666667\n",
            "validation cost: 0.19029352398470298 Validation accuracy: 34.94\n",
            "Iteration: 393\n",
            "Iteration: 394\n",
            "Cost:  0.18578066461480727 Train Accuracy: 36.02444444444444\n",
            "validation cost: 0.19018902901757584 Validation accuracy: 35.02\n",
            "Iteration: 395\n",
            "Iteration: 396\n",
            "Cost:  0.18568648718317668 Train Accuracy: 36.13111111111111\n",
            "validation cost: 0.19011788067146004 Validation accuracy: 35.06\n",
            "Iteration: 397\n",
            "Iteration: 398\n",
            "Cost:  0.18559981680311521 Train Accuracy: 36.16444444444444\n",
            "validation cost: 0.19003168493628006 Validation accuracy: 35.099999999999994\n",
            "Iteration: 399\n",
            "Iteration: 400\n",
            "Cost:  0.1855026411350737 Train Accuracy: 36.144444444444446\n",
            "validation cost: 0.18995435293628132 Validation accuracy: 35.120000000000005\n",
            "Iteration: 401\n",
            "Iteration: 402\n",
            "Cost:  0.18540955425294828 Train Accuracy: 36.19555555555555\n",
            "validation cost: 0.18985673781663934 Validation accuracy: 35.18\n",
            "Iteration: 403\n",
            "Iteration: 404\n",
            "Cost:  0.18531674093476885 Train Accuracy: 36.28\n",
            "validation cost: 0.18978049881413445 Validation accuracy: 35.160000000000004\n",
            "Iteration: 405\n",
            "Iteration: 406\n",
            "Cost:  0.18521777175964985 Train Accuracy: 36.28\n",
            "validation cost: 0.18969861181196607 Validation accuracy: 35.28\n",
            "Iteration: 407\n",
            "Iteration: 408\n",
            "Cost:  0.1851353245147518 Train Accuracy: 36.284444444444446\n",
            "validation cost: 0.1895927630156022 Validation accuracy: 35.3\n",
            "Iteration: 409\n",
            "Iteration: 410\n",
            "Cost:  0.18502782650127844 Train Accuracy: 36.28\n",
            "validation cost: 0.18950550160021362 Validation accuracy: 35.24\n",
            "Iteration: 411\n",
            "Iteration: 412\n",
            "Cost:  0.18493798196295042 Train Accuracy: 36.32666666666667\n",
            "validation cost: 0.18942640725198548 Validation accuracy: 35.32\n",
            "Iteration: 413\n",
            "Iteration: 414\n",
            "Cost:  0.18485920935953876 Train Accuracy: 36.36222222222222\n",
            "validation cost: 0.1893571215294897 Validation accuracy: 35.24\n",
            "Iteration: 415\n",
            "Iteration: 416\n",
            "Cost:  0.18475135183380434 Train Accuracy: 36.373333333333335\n",
            "validation cost: 0.18923498707679315 Validation accuracy: 35.339999999999996\n",
            "Iteration: 417\n",
            "Iteration: 418\n",
            "Cost:  0.18466157280907708 Train Accuracy: 36.41111111111111\n",
            "validation cost: 0.18917186810680517 Validation accuracy: 35.36\n",
            "Iteration: 419\n",
            "Iteration: 420\n",
            "Cost:  0.18456879949718819 Train Accuracy: 36.48888888888889\n",
            "validation cost: 0.1890723894797804 Validation accuracy: 35.28\n",
            "Iteration: 421\n",
            "Iteration: 422\n",
            "Cost:  0.18448245037700767 Train Accuracy: 36.504444444444445\n",
            "validation cost: 0.18900751840593907 Validation accuracy: 35.38\n",
            "Iteration: 423\n",
            "Iteration: 424\n",
            "Cost:  0.18438958879313855 Train Accuracy: 36.43777777777778\n",
            "validation cost: 0.18892246730835882 Validation accuracy: 35.4\n",
            "Iteration: 425\n",
            "Iteration: 426\n",
            "Cost:  0.184308465187912 Train Accuracy: 36.602222222222224\n",
            "validation cost: 0.18882496615945682 Validation accuracy: 35.46\n",
            "Iteration: 427\n",
            "Iteration: 428\n",
            "Cost:  0.1842144045509449 Train Accuracy: 36.51555555555556\n",
            "validation cost: 0.18875504360021314 Validation accuracy: 35.44\n",
            "Iteration: 429\n",
            "Iteration: 430\n",
            "Cost:  0.18412628172012419 Train Accuracy: 36.56444444444445\n",
            "validation cost: 0.1886513920529602 Validation accuracy: 35.38\n",
            "Iteration: 431\n",
            "Iteration: 432\n",
            "Cost:  0.1840323286111696 Train Accuracy: 36.66444444444444\n",
            "validation cost: 0.18857248058542733 Validation accuracy: 35.32\n",
            "Iteration: 433\n",
            "Iteration: 434\n",
            "Cost:  0.18394903352176808 Train Accuracy: 36.66444444444444\n",
            "validation cost: 0.18849238934774218 Validation accuracy: 35.44\n",
            "Iteration: 435\n",
            "Iteration: 436\n",
            "Cost:  0.18387032663194453 Train Accuracy: 36.64222222222222\n",
            "validation cost: 0.18840492737750353 Validation accuracy: 35.6\n",
            "Iteration: 437\n",
            "Iteration: 438\n",
            "Cost:  0.18378211388858864 Train Accuracy: 36.666666666666664\n",
            "validation cost: 0.18835504136557138 Validation accuracy: 35.480000000000004\n",
            "Iteration: 439\n",
            "Iteration: 440\n",
            "Cost:  0.18368451387356358 Train Accuracy: 36.67333333333333\n",
            "validation cost: 0.18824334941675333 Validation accuracy: 35.6\n",
            "Iteration: 441\n",
            "Iteration: 442\n",
            "Cost:  0.18360622551782393 Train Accuracy: 36.76888888888889\n",
            "validation cost: 0.18816465142103203 Validation accuracy: 35.64\n",
            "Iteration: 443\n",
            "Iteration: 444\n",
            "Cost:  0.18351548619022984 Train Accuracy: 36.733333333333334\n",
            "validation cost: 0.18808624392620032 Validation accuracy: 35.620000000000005\n",
            "Iteration: 445\n",
            "Iteration: 446\n",
            "Cost:  0.18343298218751525 Train Accuracy: 36.775555555555556\n",
            "validation cost: 0.18800865939004943 Validation accuracy: 35.66\n",
            "Iteration: 447\n",
            "Iteration: 448\n",
            "Cost:  0.1833452787430205 Train Accuracy: 36.806666666666665\n",
            "validation cost: 0.18791682905428958 Validation accuracy: 35.620000000000005\n",
            "Iteration: 449\n",
            "Iteration: 450\n",
            "Cost:  0.18326476863226424 Train Accuracy: 36.74444444444445\n",
            "validation cost: 0.1878547853935943 Validation accuracy: 35.64\n",
            "Iteration: 451\n",
            "Iteration: 452\n",
            "Cost:  0.183183840492285 Train Accuracy: 36.831111111111106\n",
            "validation cost: 0.18778220783936078 Validation accuracy: 35.64\n",
            "Iteration: 453\n",
            "Iteration: 454\n",
            "Cost:  0.18309432897484867 Train Accuracy: 36.85111111111111\n",
            "validation cost: 0.1876848733993166 Validation accuracy: 35.72\n",
            "Iteration: 455\n",
            "Iteration: 456\n",
            "Cost:  0.18301252960211797 Train Accuracy: 36.91111111111111\n",
            "validation cost: 0.18760558664966606 Validation accuracy: 35.72\n",
            "Iteration: 457\n",
            "Iteration: 458\n",
            "Cost:  0.18293689100299038 Train Accuracy: 36.94\n",
            "validation cost: 0.18753821356205727 Validation accuracy: 35.839999999999996\n",
            "Iteration: 459\n",
            "Iteration: 460\n",
            "Cost:  0.18285631890984902 Train Accuracy: 36.88\n",
            "validation cost: 0.18747043981445982 Validation accuracy: 35.82\n",
            "Iteration: 461\n",
            "Iteration: 462\n",
            "Cost:  0.1827701103291344 Train Accuracy: 36.980000000000004\n",
            "validation cost: 0.18738257926004112 Validation accuracy: 35.82\n",
            "Iteration: 463\n",
            "Iteration: 464\n",
            "Cost:  0.1826861429922772 Train Accuracy: 36.99777777777778\n",
            "validation cost: 0.18729855579495772 Validation accuracy: 35.88\n",
            "Iteration: 465\n",
            "Iteration: 466\n",
            "Cost:  0.1826053690862516 Train Accuracy: 37.06888888888889\n",
            "validation cost: 0.18723107985566273 Validation accuracy: 35.9\n",
            "Iteration: 467\n",
            "Iteration: 468\n",
            "Cost:  0.18252937665775154 Train Accuracy: 37.07333333333334\n",
            "validation cost: 0.1871570111427205 Validation accuracy: 35.86\n",
            "Iteration: 469\n",
            "Iteration: 470\n",
            "Cost:  0.18244721845679968 Train Accuracy: 37.12\n",
            "validation cost: 0.18708889453323616 Validation accuracy: 35.96\n",
            "Iteration: 471\n",
            "Iteration: 472\n",
            "Cost:  0.18237152937755244 Train Accuracy: 37.05555555555556\n",
            "validation cost: 0.1870018142108584 Validation accuracy: 35.78\n",
            "Iteration: 473\n",
            "Iteration: 474\n",
            "Cost:  0.18228771606311472 Train Accuracy: 37.11555555555556\n",
            "validation cost: 0.18692353888833416 Validation accuracy: 35.82\n",
            "Iteration: 475\n",
            "Iteration: 476\n",
            "Cost:  0.18221227540435175 Train Accuracy: 37.135555555555555\n",
            "validation cost: 0.1868719841494872 Validation accuracy: 35.96\n",
            "Iteration: 477\n",
            "Iteration: 478\n",
            "Cost:  0.18213700493785082 Train Accuracy: 37.18\n",
            "validation cost: 0.186780929058031 Validation accuracy: 35.96\n",
            "Iteration: 479\n",
            "Iteration: 480\n",
            "Cost:  0.18205430060733285 Train Accuracy: 37.11555555555556\n",
            "validation cost: 0.18670235577246266 Validation accuracy: 35.94\n",
            "Iteration: 481\n",
            "Iteration: 482\n",
            "Cost:  0.18197030013378102 Train Accuracy: 37.14222222222222\n",
            "validation cost: 0.18664435178062272 Validation accuracy: 35.9\n",
            "Iteration: 483\n",
            "Iteration: 484\n",
            "Cost:  0.181898485906601 Train Accuracy: 37.251111111111115\n",
            "validation cost: 0.1865551378524086 Validation accuracy: 35.92\n",
            "Iteration: 485\n",
            "Iteration: 486\n",
            "Cost:  0.1818140043612492 Train Accuracy: 37.18\n",
            "validation cost: 0.18648978941357203 Validation accuracy: 36.059999999999995\n",
            "Iteration: 487\n",
            "Iteration: 488\n",
            "Cost:  0.18173993280064865 Train Accuracy: 37.27777777777778\n",
            "validation cost: 0.1864253880397126 Validation accuracy: 36.0\n",
            "Iteration: 489\n",
            "Iteration: 490\n",
            "Cost:  0.18165657497792764 Train Accuracy: 37.28888888888889\n",
            "validation cost: 0.18634295663053813 Validation accuracy: 35.980000000000004\n",
            "Iteration: 491\n",
            "Iteration: 492\n",
            "Cost:  0.1815885391309433 Train Accuracy: 37.31111111111111\n",
            "validation cost: 0.18628040126595474 Validation accuracy: 36.059999999999995\n",
            "Iteration: 493\n",
            "Iteration: 494\n",
            "Cost:  0.1815112632644497 Train Accuracy: 37.37333333333333\n",
            "validation cost: 0.18620765577454299 Validation accuracy: 35.96\n",
            "Iteration: 495\n",
            "Iteration: 496\n",
            "Cost:  0.1814540212335574 Train Accuracy: 37.36222222222222\n",
            "validation cost: 0.1861839250940303 Validation accuracy: 36.199999999999996\n",
            "Iteration: 497\n",
            "Iteration: 498\n",
            "Cost:  0.1813607147407405 Train Accuracy: 37.41555555555556\n",
            "validation cost: 0.18606948234807213 Validation accuracy: 36.16\n",
            "Iteration: 499\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "mlp_1.fit_btch(lr=0.01, nitr= 500, alpha=0, beta=0, tol=5, epsilon=1e-5)\n",
        "t2 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfy5UsiFoKn3",
        "outputId": "29d34f5d-81d3-4713-a655-6f0842242165"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(36.480000000000004, 0.1851969758531202)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_1.evaluate_acc(x_test_vector, test_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG_PoXSt2OeM"
      },
      "outputs": [],
      "source": [
        "mlp_1_perf = {'test_perf': mlp_1.evaluate_acc(x_test_vector, test_y), 'train_time': t2-t1,\n",
        "            'train_cost': mlp_1.costs, 'val_cost': mlp_1.val_costs}\n",
        "with open('mlp_1.pickle', 'wb') as h:\n",
        "    pickle.dump(mlp_1_perf, h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5ofKQGQ2OeM"
      },
      "outputs": [],
      "source": [
        "del file\n",
        "file = drive.CreateFile()\n",
        "file.SetContentFile('mlp_1.pickle')\n",
        "file.Upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sM7P6Y_ooQEm"
      },
      "outputs": [],
      "source": [
        "# 256, 256\n",
        "mlp_ful = MLP(activation_func = relu, activation_deriv= relu_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 256, 256, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjPBBaxroQEr",
        "outputId": "01dda899-aadd-4699-8f0a-8ab8dfbed854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Cost:  0.29507096317272286 Train Accuracy: 11.051111111111112\n",
            "validation cost: 0.29298404633417735 Validation accuracy: 11.68\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Cost:  0.27105956430639755 Train Accuracy: 13.042222222222222\n",
            "validation cost: 0.26830836769261757 Validation accuracy: 13.74\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Cost:  0.25793732067996217 Train Accuracy: 15.07777777777778\n",
            "validation cost: 0.2549503913102515 Validation accuracy: 15.659999999999998\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Cost:  0.24917643395828012 Train Accuracy: 16.877777777777776\n",
            "validation cost: 0.2461773720075265 Validation accuracy: 17.119999999999997\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Cost:  0.24260408053894797 Train Accuracy: 17.95111111111111\n",
            "validation cost: 0.2396576754708049 Validation accuracy: 18.02\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Cost:  0.23740507315414489 Train Accuracy: 19.295555555555556\n",
            "validation cost: 0.23464666537007747 Validation accuracy: 19.1\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Cost:  0.23315318657547285 Train Accuracy: 20.148888888888887\n",
            "validation cost: 0.23052668356395975 Validation accuracy: 20.200000000000003\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Cost:  0.22955646887961334 Train Accuracy: 21.177777777777777\n",
            "validation cost: 0.2271392554054813 Validation accuracy: 21.3\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Cost:  0.22644210138738236 Train Accuracy: 22.024444444444445\n",
            "validation cost: 0.22412352188607257 Validation accuracy: 22.34\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Cost:  0.22379715925434365 Train Accuracy: 22.74888888888889\n",
            "validation cost: 0.22158261823419678 Validation accuracy: 23.02\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Cost:  0.22147031273210466 Train Accuracy: 23.364444444444445\n",
            "validation cost: 0.21938031265200097 Validation accuracy: 23.380000000000003\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Cost:  0.21945062824510742 Train Accuracy: 23.813333333333333\n",
            "validation cost: 0.21745695096164738 Validation accuracy: 24.060000000000002\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Cost:  0.2176348352648411 Train Accuracy: 24.364444444444445\n",
            "validation cost: 0.21579442268151935 Validation accuracy: 24.42\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Cost:  0.216019065137581 Train Accuracy: 24.75111111111111\n",
            "validation cost: 0.2142306194437625 Validation accuracy: 24.8\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Cost:  0.21453495858289937 Train Accuracy: 25.144444444444446\n",
            "validation cost: 0.21286871029606358 Validation accuracy: 25.14\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Cost:  0.21317647298548048 Train Accuracy: 25.493333333333336\n",
            "validation cost: 0.21154550095112443 Validation accuracy: 25.34\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Cost:  0.2119191556214071 Train Accuracy: 25.81555555555556\n",
            "validation cost: 0.21036477494348754 Validation accuracy: 25.8\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Cost:  0.21076903363561073 Train Accuracy: 26.106666666666666\n",
            "validation cost: 0.20933523292729578 Validation accuracy: 25.840000000000003\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Cost:  0.20967852864319592 Train Accuracy: 26.471111111111114\n",
            "validation cost: 0.2083357209762337 Validation accuracy: 26.200000000000003\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Cost:  0.20864815178759258 Train Accuracy: 26.764444444444447\n",
            "validation cost: 0.20736260557519035 Validation accuracy: 26.419999999999998\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Cost:  0.20770280535228403 Train Accuracy: 26.977777777777778\n",
            "validation cost: 0.20648851855567416 Validation accuracy: 26.6\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Cost:  0.20679950401616906 Train Accuracy: 27.242222222222225\n",
            "validation cost: 0.2057009884620152 Validation accuracy: 26.86\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Cost:  0.20596385111383464 Train Accuracy: 27.46222222222222\n",
            "validation cost: 0.20492707032616395 Validation accuracy: 26.8\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Cost:  0.20515057727279268 Train Accuracy: 27.70444444444444\n",
            "validation cost: 0.20417840736228693 Validation accuracy: 27.139999999999997\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Cost:  0.20440739651015785 Train Accuracy: 27.900000000000002\n",
            "validation cost: 0.20348541511284743 Validation accuracy: 27.36\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Cost:  0.2036626437078088 Train Accuracy: 28.115555555555556\n",
            "validation cost: 0.2028143671379299 Validation accuracy: 27.46\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Cost:  0.20298230225998817 Train Accuracy: 28.397777777777776\n",
            "validation cost: 0.20217154828139658 Validation accuracy: 27.52\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Cost:  0.20232093002810986 Train Accuracy: 28.51111111111111\n",
            "validation cost: 0.20156175184765773 Validation accuracy: 28.02\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Cost:  0.20169492833334737 Train Accuracy: 28.786666666666665\n",
            "validation cost: 0.20098717903288182 Validation accuracy: 28.18\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Cost:  0.20110562602743323 Train Accuracy: 28.897777777777776\n",
            "validation cost: 0.2004590299449182 Validation accuracy: 28.4\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Cost:  0.2005410186689745 Train Accuracy: 29.051111111111112\n",
            "validation cost: 0.19990024940562762 Validation accuracy: 28.54\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Cost:  0.1999919273173128 Train Accuracy: 29.20888888888889\n",
            "validation cost: 0.19942109949970566 Validation accuracy: 28.58\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Cost:  0.1994565420295427 Train Accuracy: 29.326666666666668\n",
            "validation cost: 0.19889634058457487 Validation accuracy: 28.92\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Cost:  0.19893861151648898 Train Accuracy: 29.56666666666667\n",
            "validation cost: 0.1984525886654266 Validation accuracy: 29.2\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Cost:  0.19844277121976123 Train Accuracy: 29.691111111111113\n",
            "validation cost: 0.19798342941692343 Validation accuracy: 29.459999999999997\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Cost:  0.19797757766913926 Train Accuracy: 29.828888888888887\n",
            "validation cost: 0.19753662938330566 Validation accuracy: 29.78\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Cost:  0.19751724732043813 Train Accuracy: 30.06888888888889\n",
            "validation cost: 0.19716982091576418 Validation accuracy: 29.84\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Cost:  0.19705433384157298 Train Accuracy: 30.188888888888886\n",
            "validation cost: 0.19672445221807272 Validation accuracy: 29.94\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Cost:  0.1966223803081504 Train Accuracy: 30.313333333333333\n",
            "validation cost: 0.19633918385759225 Validation accuracy: 30.14\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Cost:  0.19619695149871222 Train Accuracy: 30.52444444444444\n",
            "validation cost: 0.19597080114152793 Validation accuracy: 30.240000000000002\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Cost:  0.19577622568556113 Train Accuracy: 30.644444444444446\n",
            "validation cost: 0.1955285586540015 Validation accuracy: 30.56\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Cost:  0.1953811339683959 Train Accuracy: 30.851111111111113\n",
            "validation cost: 0.19515632069682887 Validation accuracy: 30.759999999999998\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Cost:  0.19499990935636116 Train Accuracy: 30.915555555555557\n",
            "validation cost: 0.19480137647155213 Validation accuracy: 30.740000000000002\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Cost:  0.1946128851754303 Train Accuracy: 31.11111111111111\n",
            "validation cost: 0.19448484946407454 Validation accuracy: 30.84\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Cost:  0.19424957927859676 Train Accuracy: 31.240000000000002\n",
            "validation cost: 0.19414224234353428 Validation accuracy: 31.06\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Cost:  0.19389634491422578 Train Accuracy: 31.32888888888889\n",
            "validation cost: 0.19376741300898656 Validation accuracy: 31.240000000000002\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Cost:  0.19353802790268038 Train Accuracy: 31.477777777777778\n",
            "validation cost: 0.19349045137769466 Validation accuracy: 31.419999999999998\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Cost:  0.1931996219847483 Train Accuracy: 31.626666666666665\n",
            "validation cost: 0.19316135025134015 Validation accuracy: 31.5\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Cost:  0.19287270712434107 Train Accuracy: 31.693333333333335\n",
            "validation cost: 0.19285452517507415 Validation accuracy: 31.680000000000003\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Cost:  0.192543945507507 Train Accuracy: 31.817777777777778\n",
            "validation cost: 0.19255311701255032 Validation accuracy: 31.86\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Cost:  0.1922369722160684 Train Accuracy: 31.955555555555552\n",
            "validation cost: 0.19228733729386585 Validation accuracy: 31.96\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Cost:  0.19192964459406073 Train Accuracy: 32.03111111111111\n",
            "validation cost: 0.1919917982748473 Validation accuracy: 32.300000000000004\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Cost:  0.19162125768423457 Train Accuracy: 32.211111111111116\n",
            "validation cost: 0.1916794078041711 Validation accuracy: 32.32\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Cost:  0.19134305631547263 Train Accuracy: 32.28\n",
            "validation cost: 0.1914472285139703 Validation accuracy: 32.4\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Cost:  0.19105379252438107 Train Accuracy: 32.33333333333333\n",
            "validation cost: 0.19111749035935627 Validation accuracy: 32.7\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Cost:  0.19076241714437972 Train Accuracy: 32.46888888888889\n",
            "validation cost: 0.19086739884513051 Validation accuracy: 32.92\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Cost:  0.19050091045461465 Train Accuracy: 32.53111111111111\n",
            "validation cost: 0.19062317190505856 Validation accuracy: 32.84\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Cost:  0.19021311028287063 Train Accuracy: 32.68666666666667\n",
            "validation cost: 0.19036161821772551 Validation accuracy: 33.019999999999996\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Cost:  0.18997264443802328 Train Accuracy: 32.70222222222222\n",
            "validation cost: 0.19011167806213192 Validation accuracy: 33.1\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Cost:  0.18969956506739816 Train Accuracy: 32.81333333333333\n",
            "validation cost: 0.1898888760084993 Validation accuracy: 33.2\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Cost:  0.18944932453392876 Train Accuracy: 32.95777777777778\n",
            "validation cost: 0.18967645544337317 Validation accuracy: 33.040000000000006\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Cost:  0.18920474512798516 Train Accuracy: 33.00222222222222\n",
            "validation cost: 0.18944609834074366 Validation accuracy: 33.339999999999996\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Cost:  0.18897304311107468 Train Accuracy: 33.13777777777778\n",
            "validation cost: 0.18925270517635653 Validation accuracy: 33.52\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Cost:  0.18875055533832072 Train Accuracy: 33.06666666666666\n",
            "validation cost: 0.18897477038407964 Validation accuracy: 33.68\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Cost:  0.18850128293879562 Train Accuracy: 33.29333333333334\n",
            "validation cost: 0.18877520266072362 Validation accuracy: 33.44\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Cost:  0.18828552358832462 Train Accuracy: 33.300000000000004\n",
            "validation cost: 0.18857397623013106 Validation accuracy: 33.68\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Cost:  0.18807184453203704 Train Accuracy: 33.39555555555555\n",
            "validation cost: 0.18836492315231143 Validation accuracy: 33.660000000000004\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Cost:  0.18784268782963187 Train Accuracy: 33.48\n",
            "validation cost: 0.18815752038538006 Validation accuracy: 33.76\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Cost:  0.187610096213136 Train Accuracy: 33.608888888888885\n",
            "validation cost: 0.18795642915252156 Validation accuracy: 33.879999999999995\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Cost:  0.18742310415585586 Train Accuracy: 33.757777777777775\n",
            "validation cost: 0.18782355767346973 Validation accuracy: 33.739999999999995\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Cost:  0.1871925641180026 Train Accuracy: 33.85777777777778\n",
            "validation cost: 0.18758681218486273 Validation accuracy: 34.02\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Cost:  0.18699164947942137 Train Accuracy: 33.92222222222222\n",
            "validation cost: 0.18738060195455525 Validation accuracy: 34.06\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Cost:  0.18678294873843101 Train Accuracy: 33.973333333333336\n",
            "validation cost: 0.18721531108280612 Validation accuracy: 34.06\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Cost:  0.18658788510164853 Train Accuracy: 34.028888888888886\n",
            "validation cost: 0.18703061421498834 Validation accuracy: 34.0\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Cost:  0.18639375664218152 Train Accuracy: 34.13333333333333\n",
            "validation cost: 0.18686611980540194 Validation accuracy: 34.12\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Cost:  0.18619704310327315 Train Accuracy: 34.233333333333334\n",
            "validation cost: 0.18665254387437574 Validation accuracy: 34.2\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Cost:  0.1860174756370577 Train Accuracy: 34.28888888888889\n",
            "validation cost: 0.18648128127151703 Validation accuracy: 34.28\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Cost:  0.1858206916943561 Train Accuracy: 34.37111111111111\n",
            "validation cost: 0.1863229540727225 Validation accuracy: 34.4\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "Cost:  0.1856360889860468 Train Accuracy: 34.45777777777778\n",
            "validation cost: 0.18616058701806262 Validation accuracy: 34.160000000000004\n",
            "Iteration: 157\n",
            "Iteration: 158\n",
            "Cost:  0.18545284126293637 Train Accuracy: 34.63333333333333\n",
            "validation cost: 0.18600229008021268 Validation accuracy: 34.300000000000004\n",
            "Iteration: 159\n",
            "Iteration: 160\n",
            "Cost:  0.18527852943952566 Train Accuracy: 34.64666666666666\n",
            "validation cost: 0.18584943749257188 Validation accuracy: 34.2\n",
            "Iteration: 161\n",
            "Iteration: 162\n",
            "Cost:  0.18510496020828054 Train Accuracy: 34.702222222222225\n",
            "validation cost: 0.1856962574316538 Validation accuracy: 34.38\n",
            "Iteration: 163\n",
            "Iteration: 164\n",
            "Cost:  0.18493443241477786 Train Accuracy: 34.70444444444444\n",
            "validation cost: 0.18551252580002717 Validation accuracy: 34.5\n",
            "Iteration: 165\n",
            "Iteration: 166\n",
            "Cost:  0.18475578924930305 Train Accuracy: 34.82\n",
            "validation cost: 0.1853441443297334 Validation accuracy: 34.839999999999996\n",
            "Iteration: 167\n",
            "Iteration: 168\n",
            "Cost:  0.18457575923431188 Train Accuracy: 34.88888888888889\n",
            "validation cost: 0.18518231424406917 Validation accuracy: 34.94\n",
            "Iteration: 169\n",
            "Iteration: 170\n",
            "Cost:  0.18441230181632937 Train Accuracy: 34.95777777777778\n",
            "validation cost: 0.18505513194952747 Validation accuracy: 34.74\n",
            "Iteration: 171\n",
            "Iteration: 172\n",
            "Cost:  0.18425135442460672 Train Accuracy: 35.05333333333333\n",
            "validation cost: 0.18488242628810153 Validation accuracy: 35.06\n",
            "Iteration: 173\n",
            "Iteration: 174\n",
            "Cost:  0.18408308371548718 Train Accuracy: 35.004444444444445\n",
            "validation cost: 0.18473312535132413 Validation accuracy: 35.02\n",
            "Iteration: 175\n",
            "Iteration: 176\n",
            "Cost:  0.18394037194607546 Train Accuracy: 35.144444444444446\n",
            "validation cost: 0.18459771654726193 Validation accuracy: 35.04\n",
            "Iteration: 177\n",
            "Iteration: 178\n",
            "Cost:  0.18376031063027526 Train Accuracy: 35.202222222222225\n",
            "validation cost: 0.18446869912970923 Validation accuracy: 35.120000000000005\n",
            "Iteration: 179\n",
            "Iteration: 180\n",
            "Cost:  0.1836118091658749 Train Accuracy: 35.26222222222222\n",
            "validation cost: 0.18432752999021457 Validation accuracy: 35.08\n",
            "Iteration: 181\n",
            "Iteration: 182\n",
            "Cost:  0.18343944005967278 Train Accuracy: 35.33111111111111\n",
            "validation cost: 0.18416663515608256 Validation accuracy: 35.22\n",
            "Iteration: 183\n",
            "Iteration: 184\n",
            "Cost:  0.18328390754139917 Train Accuracy: 35.44888888888889\n",
            "validation cost: 0.18401611711794758 Validation accuracy: 35.5\n",
            "Iteration: 185\n",
            "Iteration: 186\n",
            "Cost:  0.18315023002030148 Train Accuracy: 35.45777777777778\n",
            "validation cost: 0.18391714655542393 Validation accuracy: 35.24\n",
            "Iteration: 187\n",
            "Iteration: 188\n",
            "Cost:  0.18299235968439811 Train Accuracy: 35.562222222222225\n",
            "validation cost: 0.18374861359050632 Validation accuracy: 35.58\n",
            "Iteration: 189\n",
            "Iteration: 190\n",
            "Cost:  0.18283582097400536 Train Accuracy: 35.60444444444445\n",
            "validation cost: 0.1835938169111448 Validation accuracy: 35.68\n",
            "Iteration: 191\n",
            "Iteration: 192\n",
            "Cost:  0.18269059879720215 Train Accuracy: 35.66\n",
            "validation cost: 0.18346539030102307 Validation accuracy: 35.74\n",
            "Iteration: 193\n",
            "Iteration: 194\n",
            "Cost:  0.18254572926006102 Train Accuracy: 35.702222222222225\n",
            "validation cost: 0.1833270277615985 Validation accuracy: 35.6\n",
            "Iteration: 195\n",
            "Iteration: 196\n",
            "Cost:  0.18239613743815017 Train Accuracy: 35.83111111111111\n",
            "validation cost: 0.1831934462807289 Validation accuracy: 35.980000000000004\n",
            "Iteration: 197\n",
            "Iteration: 198\n",
            "Cost:  0.18224917945092145 Train Accuracy: 35.824444444444445\n",
            "validation cost: 0.18305283617315904 Validation accuracy: 36.04\n",
            "Iteration: 199\n",
            "Iteration: 200\n",
            "Cost:  0.1821144437113901 Train Accuracy: 35.839999999999996\n",
            "validation cost: 0.18297382842096743 Validation accuracy: 35.82\n",
            "Iteration: 201\n",
            "Iteration: 202\n",
            "Cost:  0.18196232557092928 Train Accuracy: 35.897777777777776\n",
            "validation cost: 0.18282101041902524 Validation accuracy: 36.1\n",
            "Iteration: 203\n",
            "Iteration: 204\n",
            "Cost:  0.18182862416771342 Train Accuracy: 35.94444444444444\n",
            "validation cost: 0.18268905148587436 Validation accuracy: 35.96\n",
            "Iteration: 205\n",
            "Iteration: 206\n",
            "Cost:  0.1816900832840225 Train Accuracy: 36.00222222222222\n",
            "validation cost: 0.18254997322151056 Validation accuracy: 36.22\n",
            "Iteration: 207\n",
            "Iteration: 208\n",
            "Cost:  0.181554759426113 Train Accuracy: 36.077777777777776\n",
            "validation cost: 0.18244926096932876 Validation accuracy: 36.24\n",
            "Iteration: 209\n",
            "Iteration: 210\n",
            "Cost:  0.18141387981593504 Train Accuracy: 36.10888888888889\n",
            "validation cost: 0.18233867285329095 Validation accuracy: 36.199999999999996\n",
            "Iteration: 211\n",
            "Iteration: 212\n",
            "Cost:  0.18129074077929716 Train Accuracy: 36.18666666666667\n",
            "validation cost: 0.18222255091290193 Validation accuracy: 36.22\n",
            "Iteration: 213\n",
            "Iteration: 214\n",
            "Cost:  0.1811508356634865 Train Accuracy: 36.18\n",
            "validation cost: 0.18206810108717644 Validation accuracy: 36.4\n",
            "Iteration: 215\n",
            "Iteration: 216\n",
            "Cost:  0.18103073579723938 Train Accuracy: 36.202222222222225\n",
            "validation cost: 0.18196372003077646 Validation accuracy: 36.199999999999996\n",
            "Iteration: 217\n",
            "Iteration: 218\n",
            "Cost:  0.1808946936519044 Train Accuracy: 36.26888888888889\n",
            "validation cost: 0.1818470481716617 Validation accuracy: 36.24\n",
            "Iteration: 219\n",
            "Iteration: 220\n",
            "Cost:  0.18078747611010887 Train Accuracy: 36.35111111111111\n",
            "validation cost: 0.18176593931811852 Validation accuracy: 36.5\n",
            "Iteration: 221\n",
            "Iteration: 222\n",
            "Cost:  0.18064039066950574 Train Accuracy: 36.46222222222222\n",
            "validation cost: 0.18163021424744238 Validation accuracy: 36.4\n",
            "Iteration: 223\n",
            "Iteration: 224\n",
            "Cost:  0.18052107485509705 Train Accuracy: 36.522222222222226\n",
            "validation cost: 0.18152776919778976 Validation accuracy: 36.3\n",
            "Iteration: 225\n",
            "Iteration: 226\n",
            "Cost:  0.1804055018309414 Train Accuracy: 36.495555555555555\n",
            "validation cost: 0.18141301260217155 Validation accuracy: 36.52\n",
            "Iteration: 227\n",
            "Iteration: 228\n",
            "Cost:  0.18027543552645514 Train Accuracy: 36.6\n",
            "validation cost: 0.1812908173876004 Validation accuracy: 36.54\n",
            "Iteration: 229\n",
            "Iteration: 230\n",
            "Cost:  0.1801465874058005 Train Accuracy: 36.64222222222222\n",
            "validation cost: 0.18119943929240867 Validation accuracy: 36.52\n",
            "Iteration: 231\n",
            "Iteration: 232\n",
            "Cost:  0.1800281739810505 Train Accuracy: 36.71333333333333\n",
            "validation cost: 0.1810828552217578 Validation accuracy: 36.559999999999995\n",
            "Iteration: 233\n",
            "Iteration: 234\n",
            "Cost:  0.17990830395032706 Train Accuracy: 36.66888888888889\n",
            "validation cost: 0.1809520015026185 Validation accuracy: 36.559999999999995\n",
            "Iteration: 235\n",
            "Iteration: 236\n",
            "Cost:  0.17978989933196227 Train Accuracy: 36.72666666666667\n",
            "validation cost: 0.18084042568497222 Validation accuracy: 36.66\n",
            "Iteration: 237\n",
            "Iteration: 238\n",
            "Cost:  0.17967536499422276 Train Accuracy: 36.791111111111114\n",
            "validation cost: 0.18074139614187001 Validation accuracy: 36.66\n",
            "Iteration: 239\n",
            "Iteration: 240\n",
            "Cost:  0.1795490361364797 Train Accuracy: 36.86\n",
            "validation cost: 0.1806540020060662 Validation accuracy: 36.7\n",
            "Iteration: 241\n",
            "Iteration: 242\n",
            "Cost:  0.1794509665006537 Train Accuracy: 36.922222222222224\n",
            "validation cost: 0.1805791122386167 Validation accuracy: 36.74\n",
            "Iteration: 243\n",
            "Iteration: 244\n",
            "Cost:  0.1793338972843036 Train Accuracy: 36.93333333333334\n",
            "validation cost: 0.1804375091581222 Validation accuracy: 36.7\n",
            "Iteration: 245\n",
            "Iteration: 246\n",
            "Cost:  0.17921811720575392 Train Accuracy: 36.9\n",
            "validation cost: 0.1803076527211462 Validation accuracy: 36.74\n",
            "Iteration: 247\n",
            "Iteration: 248\n",
            "Cost:  0.17909867868412502 Train Accuracy: 37.08\n",
            "validation cost: 0.18023688922990908 Validation accuracy: 36.8\n",
            "Iteration: 249\n",
            "Iteration: 250\n",
            "Cost:  0.1789900033559415 Train Accuracy: 36.980000000000004\n",
            "validation cost: 0.1801041067636143 Validation accuracy: 36.88\n",
            "Iteration: 251\n",
            "Iteration: 252\n",
            "Cost:  0.1788806507027446 Train Accuracy: 37.12444444444444\n",
            "validation cost: 0.18001915344954325 Validation accuracy: 36.88\n",
            "Iteration: 253\n",
            "Iteration: 254\n",
            "Cost:  0.17876080230302666 Train Accuracy: 37.14222222222222\n",
            "validation cost: 0.17989978615342653 Validation accuracy: 36.980000000000004\n",
            "Iteration: 255\n",
            "Iteration: 256\n",
            "Cost:  0.17866868619213264 Train Accuracy: 37.153333333333336\n",
            "validation cost: 0.17980057204008792 Validation accuracy: 36.86\n",
            "Iteration: 257\n",
            "Iteration: 258\n",
            "Cost:  0.17855416481865674 Train Accuracy: 37.19555555555555\n",
            "validation cost: 0.17970956624755988 Validation accuracy: 37.14\n",
            "Iteration: 259\n",
            "Iteration: 260\n",
            "Cost:  0.1784488190913862 Train Accuracy: 37.266666666666666\n",
            "validation cost: 0.17961739396990162 Validation accuracy: 37.2\n",
            "Iteration: 261\n",
            "Iteration: 262\n",
            "Cost:  0.1783369336139742 Train Accuracy: 37.32\n",
            "validation cost: 0.17950378143338813 Validation accuracy: 37.16\n",
            "Iteration: 263\n",
            "Iteration: 264\n",
            "Cost:  0.1782331916086787 Train Accuracy: 37.275555555555556\n",
            "validation cost: 0.17939691923715068 Validation accuracy: 37.22\n",
            "Iteration: 265\n",
            "Iteration: 266\n",
            "Cost:  0.17812985995703898 Train Accuracy: 37.35777777777778\n",
            "validation cost: 0.17934520156297273 Validation accuracy: 37.18\n",
            "Iteration: 267\n",
            "Iteration: 268\n",
            "Cost:  0.17804053820508992 Train Accuracy: 37.391111111111115\n",
            "validation cost: 0.1792391280558528 Validation accuracy: 37.3\n",
            "Iteration: 269\n",
            "Iteration: 270\n",
            "Cost:  0.17792670797686708 Train Accuracy: 37.39777777777778\n",
            "validation cost: 0.17912851868050989 Validation accuracy: 37.34\n",
            "Iteration: 271\n",
            "Iteration: 272\n",
            "Cost:  0.17782911307200672 Train Accuracy: 37.45111111111111\n",
            "validation cost: 0.17907732547907887 Validation accuracy: 37.44\n",
            "Iteration: 273\n",
            "Iteration: 274\n",
            "Cost:  0.17772006318459507 Train Accuracy: 37.553333333333335\n",
            "validation cost: 0.17896660621047028 Validation accuracy: 37.32\n",
            "Iteration: 275\n",
            "Iteration: 276\n",
            "Cost:  0.17761950238876342 Train Accuracy: 37.56\n",
            "validation cost: 0.17886768742131276 Validation accuracy: 37.4\n",
            "Iteration: 277\n",
            "Iteration: 278\n",
            "Cost:  0.17752994447738074 Train Accuracy: 37.59777777777778\n",
            "validation cost: 0.17879426691405736 Validation accuracy: 37.419999999999995\n",
            "Iteration: 279\n",
            "Iteration: 280\n",
            "Cost:  0.1774205406276212 Train Accuracy: 37.684444444444445\n",
            "validation cost: 0.17868482956035597 Validation accuracy: 37.519999999999996\n",
            "Iteration: 281\n",
            "Iteration: 282\n",
            "Cost:  0.17733765669607104 Train Accuracy: 37.66\n",
            "validation cost: 0.17862404672377402 Validation accuracy: 37.62\n",
            "Iteration: 283\n",
            "Iteration: 284\n",
            "Cost:  0.1772386435898469 Train Accuracy: 37.59111111111111\n",
            "validation cost: 0.17851991863803113 Validation accuracy: 37.6\n",
            "Iteration: 285\n",
            "Iteration: 286\n",
            "Cost:  0.17715365577235612 Train Accuracy: 37.68888888888889\n",
            "validation cost: 0.17847734352651257 Validation accuracy: 37.580000000000005\n",
            "Iteration: 287\n",
            "Iteration: 288\n",
            "Cost:  0.17704107165017668 Train Accuracy: 37.78888888888889\n",
            "validation cost: 0.1783434898275788 Validation accuracy: 37.66\n",
            "Iteration: 289\n",
            "Iteration: 290\n",
            "Cost:  0.17696539163931846 Train Accuracy: 37.77777777777778\n",
            "validation cost: 0.17830256355949933 Validation accuracy: 37.82\n",
            "Iteration: 291\n",
            "Iteration: 292\n",
            "Cost:  0.17684807463239105 Train Accuracy: 37.90222222222222\n",
            "validation cost: 0.17817339231821927 Validation accuracy: 37.78\n",
            "Iteration: 293\n",
            "Iteration: 294\n",
            "Cost:  0.17675572815747861 Train Accuracy: 37.92666666666666\n",
            "validation cost: 0.17811560356068815 Validation accuracy: 37.88\n",
            "Iteration: 295\n",
            "Iteration: 296\n",
            "Cost:  0.17666980228424212 Train Accuracy: 37.96888888888889\n",
            "validation cost: 0.17800432219174203 Validation accuracy: 37.64\n",
            "Iteration: 297\n",
            "Iteration: 298\n",
            "Cost:  0.176567850723068 Train Accuracy: 37.906666666666666\n",
            "validation cost: 0.17791886555663783 Validation accuracy: 37.86\n",
            "Iteration: 299\n",
            "Iteration: 300\n",
            "Cost:  0.17647323591409178 Train Accuracy: 38.05777777777778\n",
            "validation cost: 0.17784128135982152 Validation accuracy: 37.940000000000005\n",
            "Iteration: 301\n",
            "Iteration: 302\n",
            "Cost:  0.17639452661747848 Train Accuracy: 38.04666666666667\n",
            "validation cost: 0.177770893894698 Validation accuracy: 37.88\n",
            "Iteration: 303\n",
            "Iteration: 304\n",
            "Cost:  0.17629881874867798 Train Accuracy: 38.05777777777778\n",
            "validation cost: 0.17767160192262746 Validation accuracy: 37.940000000000005\n",
            "Iteration: 305\n",
            "Iteration: 306\n",
            "Cost:  0.17620557012596244 Train Accuracy: 38.108888888888885\n",
            "validation cost: 0.17760524066142802 Validation accuracy: 37.86\n",
            "Iteration: 307\n",
            "Iteration: 308\n",
            "Cost:  0.17613017463022393 Train Accuracy: 38.20222222222222\n",
            "validation cost: 0.17754935711796285 Validation accuracy: 37.8\n",
            "Iteration: 309\n",
            "Iteration: 310\n",
            "Cost:  0.1760326452046824 Train Accuracy: 38.18888888888889\n",
            "validation cost: 0.17744737338781605 Validation accuracy: 37.9\n",
            "Iteration: 311\n",
            "Iteration: 312\n",
            "Cost:  0.1759442118568049 Train Accuracy: 38.25333333333333\n",
            "validation cost: 0.1773642669202807 Validation accuracy: 38.0\n",
            "Iteration: 313\n",
            "Iteration: 314\n",
            "Cost:  0.17585641351801426 Train Accuracy: 38.279999999999994\n",
            "validation cost: 0.17728259397862753 Validation accuracy: 38.080000000000005\n",
            "Iteration: 315\n",
            "Iteration: 316\n",
            "Cost:  0.17577313944426023 Train Accuracy: 38.29555555555555\n",
            "validation cost: 0.17718866041266118 Validation accuracy: 38.12\n",
            "Iteration: 317\n",
            "Iteration: 318\n",
            "Cost:  0.17567989378264076 Train Accuracy: 38.32666666666667\n",
            "validation cost: 0.1771311857725739 Validation accuracy: 38.22\n",
            "Iteration: 319\n",
            "Iteration: 320\n",
            "Cost:  0.17559335306968815 Train Accuracy: 38.39555555555555\n",
            "validation cost: 0.1770460777909318 Validation accuracy: 38.18\n",
            "Iteration: 321\n",
            "Iteration: 322\n",
            "Cost:  0.17551343342357514 Train Accuracy: 38.41555555555555\n",
            "validation cost: 0.17699010660284628 Validation accuracy: 37.96\n",
            "Iteration: 323\n",
            "Iteration: 324\n",
            "Cost:  0.17542279786048007 Train Accuracy: 38.40888888888889\n",
            "validation cost: 0.17689582388958472 Validation accuracy: 38.16\n",
            "Iteration: 325\n",
            "Iteration: 326\n",
            "Cost:  0.17534240386599348 Train Accuracy: 38.52444444444444\n",
            "validation cost: 0.17683568031213193 Validation accuracy: 38.24\n",
            "Iteration: 327\n",
            "Iteration: 328\n",
            "Cost:  0.17525439870446138 Train Accuracy: 38.48888888888889\n",
            "validation cost: 0.17675494268525996 Validation accuracy: 38.18\n",
            "Iteration: 329\n",
            "Iteration: 330\n",
            "Cost:  0.1751781288303002 Train Accuracy: 38.526666666666664\n",
            "validation cost: 0.17668289556396993 Validation accuracy: 38.2\n",
            "Iteration: 331\n",
            "Iteration: 332\n",
            "Cost:  0.17509171006898647 Train Accuracy: 38.522222222222226\n",
            "validation cost: 0.17661446157144936 Validation accuracy: 38.26\n",
            "Iteration: 333\n",
            "Iteration: 334\n",
            "Cost:  0.17500928588275436 Train Accuracy: 38.61333333333333\n",
            "validation cost: 0.1765408894401211 Validation accuracy: 38.2\n",
            "Iteration: 335\n",
            "Iteration: 336\n",
            "Cost:  0.17493720932720305 Train Accuracy: 38.56444444444445\n",
            "validation cost: 0.17645599212173438 Validation accuracy: 38.26\n",
            "Iteration: 337\n",
            "Iteration: 338\n",
            "Cost:  0.17485316789530891 Train Accuracy: 38.61333333333333\n",
            "validation cost: 0.1764031040728731 Validation accuracy: 38.34\n",
            "Iteration: 339\n",
            "Iteration: 340\n",
            "Cost:  0.17476714935781712 Train Accuracy: 38.73777777777778\n",
            "validation cost: 0.17632981874182357 Validation accuracy: 38.379999999999995\n",
            "Iteration: 341\n",
            "Iteration: 342\n",
            "Cost:  0.17469487373869558 Train Accuracy: 38.626666666666665\n",
            "validation cost: 0.176266535373958 Validation accuracy: 38.3\n",
            "Iteration: 343\n",
            "Iteration: 344\n",
            "Cost:  0.17460552735187093 Train Accuracy: 38.71333333333333\n",
            "validation cost: 0.1761657831607111 Validation accuracy: 38.440000000000005\n",
            "Iteration: 345\n",
            "Iteration: 346\n",
            "Cost:  0.17453142296139784 Train Accuracy: 38.733333333333334\n",
            "validation cost: 0.17613086925197552 Validation accuracy: 38.36\n",
            "Iteration: 347\n",
            "Iteration: 348\n",
            "Cost:  0.17444210877205343 Train Accuracy: 38.79333333333334\n",
            "validation cost: 0.1760235559532003 Validation accuracy: 38.440000000000005\n",
            "Iteration: 349\n",
            "Iteration: 350\n",
            "Cost:  0.17437850960924928 Train Accuracy: 38.81333333333333\n",
            "validation cost: 0.1759839337848372 Validation accuracy: 38.36\n",
            "Iteration: 351\n",
            "Iteration: 352\n",
            "Cost:  0.1742926526478324 Train Accuracy: 38.81777777777778\n",
            "validation cost: 0.17588348614334764 Validation accuracy: 38.5\n",
            "Iteration: 353\n",
            "Iteration: 354\n",
            "Cost:  0.17420899337420115 Train Accuracy: 38.89333333333334\n",
            "validation cost: 0.1758341724625834 Validation accuracy: 38.48\n",
            "Iteration: 355\n",
            "Iteration: 356\n",
            "Cost:  0.17414212112531044 Train Accuracy: 38.80444444444445\n",
            "validation cost: 0.1757618710602552 Validation accuracy: 38.379999999999995\n",
            "Iteration: 357\n",
            "Iteration: 358\n",
            "Cost:  0.17405542326822657 Train Accuracy: 38.904444444444444\n",
            "validation cost: 0.17569717710639898 Validation accuracy: 38.56\n",
            "Iteration: 359\n",
            "Iteration: 360\n",
            "Cost:  0.17398676292503756 Train Accuracy: 38.92444444444445\n",
            "validation cost: 0.17564036795292223 Validation accuracy: 38.34\n",
            "Iteration: 361\n",
            "Iteration: 362\n",
            "Cost:  0.17390698603792465 Train Accuracy: 38.98222222222223\n",
            "validation cost: 0.1755559944925243 Validation accuracy: 38.74\n",
            "Iteration: 363\n",
            "Iteration: 364\n",
            "Cost:  0.1738379508688369 Train Accuracy: 39.071111111111115\n",
            "validation cost: 0.17550094422404303 Validation accuracy: 38.5\n",
            "Iteration: 365\n",
            "Iteration: 366\n",
            "Cost:  0.1737547014770944 Train Accuracy: 39.013333333333335\n",
            "validation cost: 0.17542546094246558 Validation accuracy: 38.46\n",
            "Iteration: 367\n",
            "Iteration: 368\n",
            "Cost:  0.17369124266708846 Train Accuracy: 39.03111111111111\n",
            "validation cost: 0.17537076218565228 Validation accuracy: 38.64\n",
            "Iteration: 369\n",
            "Iteration: 370\n",
            "Cost:  0.17360588922167802 Train Accuracy: 39.12\n",
            "validation cost: 0.17530514365748906 Validation accuracy: 38.78\n",
            "Iteration: 371\n",
            "Iteration: 372\n",
            "Cost:  0.17353284775344852 Train Accuracy: 39.11555555555555\n",
            "validation cost: 0.17524907058333947 Validation accuracy: 38.6\n",
            "Iteration: 373\n",
            "Iteration: 374\n",
            "Cost:  0.1734599256408194 Train Accuracy: 39.19777777777777\n",
            "validation cost: 0.17515448280926915 Validation accuracy: 38.74\n",
            "Iteration: 375\n",
            "Iteration: 376\n",
            "Cost:  0.17338498628607352 Train Accuracy: 39.15555555555555\n",
            "validation cost: 0.17508901142139685 Validation accuracy: 38.66\n",
            "Iteration: 377\n",
            "Iteration: 378\n",
            "Cost:  0.17333411597521645 Train Accuracy: 39.24666666666667\n",
            "validation cost: 0.17502794726722573 Validation accuracy: 38.72\n",
            "Iteration: 379\n",
            "Iteration: 380\n",
            "Cost:  0.1732476705989655 Train Accuracy: 39.208888888888886\n",
            "validation cost: 0.17495253894976748 Validation accuracy: 38.74\n",
            "Iteration: 381\n",
            "Iteration: 382\n",
            "Cost:  0.17316415758417736 Train Accuracy: 39.28666666666666\n",
            "validation cost: 0.17490358292802674 Validation accuracy: 38.940000000000005\n",
            "Iteration: 383\n",
            "Iteration: 384\n",
            "Cost:  0.17309925958544453 Train Accuracy: 39.32\n",
            "validation cost: 0.17485868483600758 Validation accuracy: 39.019999999999996\n",
            "Iteration: 385\n",
            "Iteration: 386\n",
            "Cost:  0.17302301521791016 Train Accuracy: 39.355555555555554\n",
            "validation cost: 0.1747731445610113 Validation accuracy: 38.940000000000005\n",
            "Iteration: 387\n",
            "Iteration: 388\n",
            "Cost:  0.17295546126182693 Train Accuracy: 39.36222222222222\n",
            "validation cost: 0.1747385399668158 Validation accuracy: 38.92\n",
            "Iteration: 389\n",
            "Iteration: 390\n",
            "Cost:  0.1728907638782285 Train Accuracy: 39.34444444444444\n",
            "validation cost: 0.17464165746387914 Validation accuracy: 38.74\n",
            "Iteration: 391\n",
            "Iteration: 392\n",
            "Cost:  0.17281701636394023 Train Accuracy: 39.373333333333335\n",
            "validation cost: 0.17461224859851787 Validation accuracy: 38.92\n",
            "Iteration: 393\n",
            "Iteration: 394\n",
            "Cost:  0.1727398299063505 Train Accuracy: 39.43555555555556\n",
            "validation cost: 0.17452221571174792 Validation accuracy: 39.019999999999996\n",
            "Iteration: 395\n",
            "Iteration: 396\n",
            "Cost:  0.17268120469812615 Train Accuracy: 39.431111111111115\n",
            "validation cost: 0.1744853285019509 Validation accuracy: 38.82\n",
            "Iteration: 397\n",
            "Iteration: 398\n",
            "Cost:  0.17261736290213034 Train Accuracy: 39.50666666666667\n",
            "validation cost: 0.17441218365662778 Validation accuracy: 39.18\n",
            "Iteration: 399\n",
            "Iteration: 400\n",
            "Cost:  0.17253370526481687 Train Accuracy: 39.486666666666665\n",
            "validation cost: 0.17436173816716422 Validation accuracy: 38.76\n",
            "Iteration: 401\n",
            "Iteration: 402\n",
            "Cost:  0.17247153325862902 Train Accuracy: 39.53111111111111\n",
            "validation cost: 0.17428722426415427 Validation accuracy: 39.08\n",
            "Iteration: 403\n",
            "Iteration: 404\n",
            "Cost:  0.17239438448985125 Train Accuracy: 39.53777777777778\n",
            "validation cost: 0.17422558858558004 Validation accuracy: 38.96\n",
            "Iteration: 405\n",
            "Iteration: 406\n",
            "Cost:  0.17235608827564808 Train Accuracy: 39.54666666666667\n",
            "validation cost: 0.17418054045146467 Validation accuracy: 39.160000000000004\n",
            "Iteration: 407\n",
            "Iteration: 408\n",
            "Cost:  0.17226435386964525 Train Accuracy: 39.58888888888889\n",
            "validation cost: 0.1741001847844103 Validation accuracy: 38.940000000000005\n",
            "Iteration: 409\n",
            "Iteration: 410\n",
            "Cost:  0.17220683646970228 Train Accuracy: 39.651111111111106\n",
            "validation cost: 0.17406954742452518 Validation accuracy: 39.1\n",
            "Iteration: 411\n",
            "Iteration: 412\n",
            "Cost:  0.17213122021073463 Train Accuracy: 39.67111111111111\n",
            "validation cost: 0.17398950334551463 Validation accuracy: 39.14\n",
            "Iteration: 413\n",
            "Iteration: 414\n",
            "Cost:  0.17206574787279608 Train Accuracy: 39.65555555555555\n",
            "validation cost: 0.17393331990961036 Validation accuracy: 39.160000000000004\n",
            "Iteration: 415\n",
            "Iteration: 416\n",
            "Cost:  0.17199078116866306 Train Accuracy: 39.68666666666667\n",
            "validation cost: 0.17389317342336996 Validation accuracy: 39.18\n",
            "Iteration: 417\n",
            "Iteration: 418\n",
            "Cost:  0.17193030278729285 Train Accuracy: 39.708888888888886\n",
            "validation cost: 0.17385337993765182 Validation accuracy: 39.1\n",
            "Iteration: 419\n",
            "Iteration: 420\n",
            "Cost:  0.17185720732943 Train Accuracy: 39.71333333333333\n",
            "validation cost: 0.17375997806856117 Validation accuracy: 39.1\n",
            "Iteration: 421\n",
            "Iteration: 422\n",
            "Cost:  0.17179795133076384 Train Accuracy: 39.675555555555555\n",
            "validation cost: 0.17369896108692126 Validation accuracy: 39.22\n",
            "Iteration: 423\n",
            "Iteration: 424\n",
            "Cost:  0.1717551327129033 Train Accuracy: 39.739999999999995\n",
            "validation cost: 0.17368972452326764 Validation accuracy: 38.92\n",
            "Iteration: 425\n",
            "Iteration: 426\n",
            "Cost:  0.1716732997216119 Train Accuracy: 39.80222222222222\n",
            "validation cost: 0.1736134275930943 Validation accuracy: 39.04\n",
            "Iteration: 427\n",
            "Iteration: 428\n",
            "Cost:  0.17160042167015893 Train Accuracy: 39.82\n",
            "validation cost: 0.173553950981171 Validation accuracy: 39.12\n",
            "Iteration: 429\n",
            "Iteration: 430\n",
            "Cost:  0.17153744825022033 Train Accuracy: 39.82666666666667\n",
            "validation cost: 0.1734740078667874 Validation accuracy: 39.36\n",
            "Iteration: 431\n",
            "Iteration: 432\n",
            "Cost:  0.17147409474627212 Train Accuracy: 39.84666666666667\n",
            "validation cost: 0.17343455037215802 Validation accuracy: 39.0\n",
            "Iteration: 433\n",
            "Iteration: 434\n",
            "Cost:  0.1714068929506116 Train Accuracy: 39.839999999999996\n",
            "validation cost: 0.1733745567498415 Validation accuracy: 39.2\n",
            "Iteration: 435\n",
            "Iteration: 436\n",
            "Cost:  0.17134733786996073 Train Accuracy: 39.931111111111115\n",
            "validation cost: 0.17332289247939414 Validation accuracy: 39.379999999999995\n",
            "Iteration: 437\n",
            "Iteration: 438\n",
            "Cost:  0.17129688344896987 Train Accuracy: 39.94888888888889\n",
            "validation cost: 0.17327268487549752 Validation accuracy: 39.28\n",
            "Iteration: 439\n",
            "Iteration: 440\n",
            "Cost:  0.17122034143969994 Train Accuracy: 39.94888888888889\n",
            "validation cost: 0.17320809684977212 Validation accuracy: 39.44\n",
            "Iteration: 441\n",
            "Iteration: 442\n",
            "Cost:  0.1711507946870608 Train Accuracy: 39.97777777777778\n",
            "validation cost: 0.173146240137368 Validation accuracy: 39.36\n",
            "Iteration: 443\n",
            "Iteration: 444\n",
            "Cost:  0.1710890277826288 Train Accuracy: 40.03333333333333\n",
            "validation cost: 0.17309771050355185 Validation accuracy: 39.36\n",
            "Iteration: 445\n",
            "Iteration: 446\n",
            "Cost:  0.1710308186709428 Train Accuracy: 39.99777777777778\n",
            "validation cost: 0.1730439591276271 Validation accuracy: 39.5\n",
            "Iteration: 447\n",
            "Iteration: 448\n",
            "Cost:  0.17096225324139142 Train Accuracy: 40.026666666666664\n",
            "validation cost: 0.17299009959690576 Validation accuracy: 39.26\n",
            "Iteration: 449\n",
            "Iteration: 450\n",
            "Cost:  0.1709150519836644 Train Accuracy: 40.06444444444445\n",
            "validation cost: 0.17295761291291084 Validation accuracy: 39.5\n",
            "Iteration: 451\n",
            "Iteration: 452\n",
            "Cost:  0.17084622430667207 Train Accuracy: 39.99777777777778\n",
            "validation cost: 0.1728901777887121 Validation accuracy: 39.32\n",
            "Iteration: 453\n",
            "Iteration: 454\n",
            "Cost:  0.17079659397446936 Train Accuracy: 40.00222222222222\n",
            "validation cost: 0.17285094136434873 Validation accuracy: 39.44\n",
            "Iteration: 455\n",
            "Iteration: 456\n",
            "Cost:  0.17075034702612624 Train Accuracy: 40.13111111111111\n",
            "validation cost: 0.17282477954101363 Validation accuracy: 39.26\n",
            "Iteration: 457\n",
            "Iteration: 458\n",
            "Cost:  0.17066240547818354 Train Accuracy: 40.17111111111112\n",
            "validation cost: 0.17272664990164452 Validation accuracy: 39.32\n",
            "Iteration: 459\n",
            "Iteration: 460\n",
            "Cost:  0.17060872127695664 Train Accuracy: 40.10444444444444\n",
            "validation cost: 0.17266572452567253 Validation accuracy: 39.48\n",
            "Iteration: 461\n",
            "Iteration: 462\n",
            "Cost:  0.17055435742331762 Train Accuracy: 40.144444444444446\n",
            "validation cost: 0.1726203958977804 Validation accuracy: 39.44\n",
            "Iteration: 463\n",
            "Iteration: 464\n",
            "Cost:  0.17048906935497435 Train Accuracy: 40.18\n",
            "validation cost: 0.17257886372547465 Validation accuracy: 39.4\n",
            "Iteration: 465\n",
            "Iteration: 466\n",
            "Cost:  0.1704271620442757 Train Accuracy: 40.19777777777777\n",
            "validation cost: 0.17252933130307938 Validation accuracy: 39.54\n",
            "Iteration: 467\n",
            "Iteration: 468\n",
            "Cost:  0.17037447234746436 Train Accuracy: 40.27111111111111\n",
            "validation cost: 0.1724878232986542 Validation accuracy: 39.379999999999995\n",
            "Iteration: 469\n",
            "Iteration: 470\n",
            "Cost:  0.17030571596154237 Train Accuracy: 40.24666666666666\n",
            "validation cost: 0.17239738671661745 Validation accuracy: 39.54\n",
            "Iteration: 471\n",
            "Iteration: 472\n",
            "Cost:  0.17025469935904874 Train Accuracy: 40.28\n",
            "validation cost: 0.17236396044211713 Validation accuracy: 39.42\n",
            "Iteration: 473\n",
            "Iteration: 474\n",
            "Cost:  0.1702020905833004 Train Accuracy: 40.26\n",
            "validation cost: 0.1723425115225654 Validation accuracy: 39.36\n",
            "Iteration: 475\n",
            "Iteration: 476\n",
            "Cost:  0.17013864155672256 Train Accuracy: 40.25555555555555\n",
            "validation cost: 0.17228006024075276 Validation accuracy: 39.519999999999996\n",
            "Iteration: 477\n",
            "Iteration: 478\n",
            "Cost:  0.17008205267570453 Train Accuracy: 40.32\n",
            "validation cost: 0.17225836098937725 Validation accuracy: 39.379999999999995\n",
            "Iteration: 479\n",
            "Iteration: 480\n",
            "Cost:  0.17001669768920682 Train Accuracy: 40.324444444444445\n",
            "validation cost: 0.17217831215139046 Validation accuracy: 39.34\n",
            "Iteration: 481\n",
            "Iteration: 482\n",
            "Cost:  0.1699618020500928 Train Accuracy: 40.32888888888888\n",
            "validation cost: 0.17210556564393897 Validation accuracy: 39.519999999999996\n",
            "Iteration: 483\n",
            "Iteration: 484\n",
            "Cost:  0.16990564468613975 Train Accuracy: 40.33333333333333\n",
            "validation cost: 0.17206855597896206 Validation accuracy: 39.4\n",
            "Iteration: 485\n",
            "Iteration: 486\n",
            "Cost:  0.16985180091914698 Train Accuracy: 40.33333333333333\n",
            "validation cost: 0.1720006281453248 Validation accuracy: 39.54\n",
            "Iteration: 487\n",
            "Iteration: 488\n",
            "Cost:  0.16979020362907143 Train Accuracy: 40.41555555555556\n",
            "validation cost: 0.17198450422238723 Validation accuracy: 39.4\n",
            "Iteration: 489\n",
            "Iteration: 490\n",
            "Cost:  0.16976027891175077 Train Accuracy: 40.36\n",
            "validation cost: 0.17190997307925918 Validation accuracy: 39.739999999999995\n",
            "Iteration: 491\n",
            "Iteration: 492\n",
            "Cost:  0.1696813022726027 Train Accuracy: 40.40222222222222\n",
            "validation cost: 0.17186010405089783 Validation accuracy: 39.660000000000004\n",
            "Iteration: 493\n",
            "Iteration: 494\n",
            "Cost:  0.16961603128462893 Train Accuracy: 40.486666666666665\n",
            "validation cost: 0.17182854642548315 Validation accuracy: 39.68\n",
            "Iteration: 495\n",
            "Iteration: 496\n",
            "Cost:  0.169561391811647 Train Accuracy: 40.41777777777778\n",
            "validation cost: 0.1717661746590407 Validation accuracy: 39.62\n",
            "Iteration: 497\n",
            "Iteration: 498\n",
            "Cost:  0.1695104924930106 Train Accuracy: 40.53111111111111\n",
            "validation cost: 0.1717415073111889 Validation accuracy: 39.519999999999996\n",
            "Iteration: 499\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "mlp_ful.fit_btch(lr=0.01, nitr= 500, alpha=0, beta=0, tol=5, epsilon=1e-5)\n",
        "t2 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzLo4-efoVUb",
        "outputId": "619195cc-f044-40f2-e705-b49106434e6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(39.160000000000004, 0.17175061848872528)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_ful.evaluate_acc(x_test_vector, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7qY1w8652VW"
      },
      "outputs": [],
      "source": [
        "mlp_ful_perf = {'test_perf': mlp_ful.evaluate_acc(x_test_vector, test_y), 'train_time': t2-t1,\n",
        "            'train_cost': mlp_ful.costs, 'val_cost': mlp_ful.val_costs}\n",
        "with open('mlp_ful.pickle', 'wb') as h:\n",
        "    pickle.dump(mlp_ful_perf, h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWXmKuyS54bs"
      },
      "outputs": [],
      "source": [
        "del file\n",
        "file = drive.CreateFile()\n",
        "file.SetContentFile('mlp_ful.pickle')\n",
        "file.Upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_fOEIufSi43"
      },
      "source": [
        "# Leaky Relu and Tanh models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrAxAurG9vcc"
      },
      "outputs": [],
      "source": [
        "#Leaky relu\n",
        "\n",
        "mlp_lrelu = MLP(activation_func = leaky_relu, activation_deriv= leaky_relu_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 256, 256, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APQshVicSqK2",
        "outputId": "d384442b-5fba-4256-d6e9-98224b9a823f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Cost:  0.3067052377476267 Train Accuracy: 10.27111111111111\n",
            "validation cost: 0.30621126501504703 Validation accuracy: 9.78\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Cost:  0.2734916212679462 Train Accuracy: 13.528888888888888\n",
            "validation cost: 0.2729618900497163 Validation accuracy: 13.719999999999999\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Cost:  0.2568727634800174 Train Accuracy: 16.084444444444447\n",
            "validation cost: 0.2563485594293538 Validation accuracy: 16.6\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Cost:  0.2463112227627132 Train Accuracy: 18.177777777777777\n",
            "validation cost: 0.24585356168527286 Validation accuracy: 18.8\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Cost:  0.23897934549547134 Train Accuracy: 19.606666666666666\n",
            "validation cost: 0.2385217742195856 Validation accuracy: 19.900000000000002\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Cost:  0.23346258817876098 Train Accuracy: 20.82\n",
            "validation cost: 0.23305060216996798 Validation accuracy: 21.08\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Cost:  0.22916573970692933 Train Accuracy: 21.74888888888889\n",
            "validation cost: 0.2287746443026649 Validation accuracy: 22.220000000000002\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Cost:  0.2256834380860856 Train Accuracy: 22.56\n",
            "validation cost: 0.22531638812239765 Validation accuracy: 23.080000000000002\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Cost:  0.22281642812015812 Train Accuracy: 23.24888888888889\n",
            "validation cost: 0.22250509483467046 Validation accuracy: 23.78\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Cost:  0.22035130766247457 Train Accuracy: 23.875555555555554\n",
            "validation cost: 0.2200845813171293 Validation accuracy: 24.48\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Cost:  0.21821065723925134 Train Accuracy: 24.37333333333333\n",
            "validation cost: 0.21802946263497405 Validation accuracy: 24.68\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Cost:  0.21633340096917897 Train Accuracy: 24.906666666666666\n",
            "validation cost: 0.2162144070564839 Validation accuracy: 25.22\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Cost:  0.21465705089708179 Train Accuracy: 25.34\n",
            "validation cost: 0.21461335888163266 Validation accuracy: 25.580000000000002\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Cost:  0.21314340140803137 Train Accuracy: 25.77111111111111\n",
            "validation cost: 0.2131897889800763 Validation accuracy: 25.8\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Cost:  0.21175917190091204 Train Accuracy: 26.206666666666667\n",
            "validation cost: 0.21187504512178537 Validation accuracy: 26.240000000000002\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Cost:  0.2104879786008969 Train Accuracy: 26.537777777777777\n",
            "validation cost: 0.21066484075062067 Validation accuracy: 26.82\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Cost:  0.20931849142481346 Train Accuracy: 26.87333333333333\n",
            "validation cost: 0.2095620135997404 Validation accuracy: 27.04\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Cost:  0.20823363273845655 Train Accuracy: 27.14666666666667\n",
            "validation cost: 0.20853201231674648 Validation accuracy: 27.400000000000002\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Cost:  0.2072250499184875 Train Accuracy: 27.502222222222223\n",
            "validation cost: 0.20758219494418315 Validation accuracy: 27.66\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Cost:  0.20626411662040284 Train Accuracy: 27.779999999999998\n",
            "validation cost: 0.20668160814947426 Validation accuracy: 27.88\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Cost:  0.2053742379259695 Train Accuracy: 28.102222222222224\n",
            "validation cost: 0.20582825691571507 Validation accuracy: 27.98\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Cost:  0.2045275207268323 Train Accuracy: 28.346666666666664\n",
            "validation cost: 0.2050329776158071 Validation accuracy: 28.34\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Cost:  0.2037099351278259 Train Accuracy: 28.515555555555554\n",
            "validation cost: 0.2042739216835885 Validation accuracy: 28.64\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Cost:  0.2029494688861462 Train Accuracy: 28.757777777777775\n",
            "validation cost: 0.20354679138171025 Validation accuracy: 28.560000000000002\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Cost:  0.20222977027680084 Train Accuracy: 28.988888888888887\n",
            "validation cost: 0.20286610514622566 Validation accuracy: 28.799999999999997\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Cost:  0.20153646306166492 Train Accuracy: 29.26\n",
            "validation cost: 0.20222115835848953 Validation accuracy: 29.160000000000004\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Cost:  0.20087521826161503 Train Accuracy: 29.45111111111111\n",
            "validation cost: 0.2016090311530193 Validation accuracy: 29.18\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Cost:  0.20024516953043028 Train Accuracy: 29.706666666666663\n",
            "validation cost: 0.20101060930804004 Validation accuracy: 29.299999999999997\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Cost:  0.19965940409338925 Train Accuracy: 29.824444444444442\n",
            "validation cost: 0.20049868527015405 Validation accuracy: 29.42\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Cost:  0.19906522428814316 Train Accuracy: 30.084444444444447\n",
            "validation cost: 0.1999522371595567 Validation accuracy: 29.82\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Cost:  0.19849951139490876 Train Accuracy: 30.288888888888888\n",
            "validation cost: 0.19944290343659563 Validation accuracy: 29.9\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Cost:  0.19795604686068133 Train Accuracy: 30.52888888888889\n",
            "validation cost: 0.19895975127330304 Validation accuracy: 29.98\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Cost:  0.19744814962540436 Train Accuracy: 30.64\n",
            "validation cost: 0.19851361970144407 Validation accuracy: 30.099999999999998\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Cost:  0.1969378016344356 Train Accuracy: 30.855555555555558\n",
            "validation cost: 0.19805375861590385 Validation accuracy: 30.12\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Cost:  0.19645774924536163 Train Accuracy: 30.995555555555555\n",
            "validation cost: 0.19764293089333623 Validation accuracy: 30.28\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Cost:  0.1959943686394343 Train Accuracy: 31.115555555555556\n",
            "validation cost: 0.19722658096701562 Validation accuracy: 30.380000000000003\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Cost:  0.195548830629124 Train Accuracy: 31.266666666666666\n",
            "validation cost: 0.1968322577845765 Validation accuracy: 30.28\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Cost:  0.1951180522560625 Train Accuracy: 31.4\n",
            "validation cost: 0.19645573953717202 Validation accuracy: 30.54\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Cost:  0.19469210564497988 Train Accuracy: 31.54222222222222\n",
            "validation cost: 0.19606834215190436 Validation accuracy: 30.680000000000003\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Cost:  0.19428774003760857 Train Accuracy: 31.568888888888893\n",
            "validation cost: 0.19571847747375584 Validation accuracy: 30.7\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Cost:  0.19388198013888755 Train Accuracy: 31.782222222222224\n",
            "validation cost: 0.19536321543739574 Validation accuracy: 30.84\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Cost:  0.19349388871731057 Train Accuracy: 31.851111111111113\n",
            "validation cost: 0.19501763691989393 Validation accuracy: 31.080000000000002\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Cost:  0.19311778835077217 Train Accuracy: 31.94666666666667\n",
            "validation cost: 0.19468733961999932 Validation accuracy: 31.1\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Cost:  0.1927654406997865 Train Accuracy: 32.07333333333333\n",
            "validation cost: 0.19439544269422032 Validation accuracy: 31.259999999999998\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Cost:  0.1924011974136494 Train Accuracy: 32.193333333333335\n",
            "validation cost: 0.19405839975050915 Validation accuracy: 31.5\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Cost:  0.19204436964708496 Train Accuracy: 32.27333333333333\n",
            "validation cost: 0.19372757461024212 Validation accuracy: 31.64\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Cost:  0.19170834330541 Train Accuracy: 32.42888888888889\n",
            "validation cost: 0.19342205151871553 Validation accuracy: 31.56\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Cost:  0.19138662534385456 Train Accuracy: 32.60666666666667\n",
            "validation cost: 0.19311855391626018 Validation accuracy: 31.7\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Cost:  0.19105786314282366 Train Accuracy: 32.63111111111111\n",
            "validation cost: 0.19283991651532015 Validation accuracy: 31.86\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Cost:  0.19075040695981324 Train Accuracy: 32.78\n",
            "validation cost: 0.19255025755713712 Validation accuracy: 32.0\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Cost:  0.1904529917595822 Train Accuracy: 32.9\n",
            "validation cost: 0.19229226737078958 Validation accuracy: 32.16\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Cost:  0.19015063949429112 Train Accuracy: 33.01111111111111\n",
            "validation cost: 0.1920033045314034 Validation accuracy: 32.14\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Cost:  0.18985269642541736 Train Accuracy: 33.09777777777778\n",
            "validation cost: 0.19174587814137467 Validation accuracy: 32.04\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Cost:  0.18957078299440663 Train Accuracy: 33.26444444444444\n",
            "validation cost: 0.19147313721025952 Validation accuracy: 32.32\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Cost:  0.18930209242865903 Train Accuracy: 33.40222222222222\n",
            "validation cost: 0.19120377232095365 Validation accuracy: 32.54\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Cost:  0.18902721293598684 Train Accuracy: 33.46666666666667\n",
            "validation cost: 0.1909722278855827 Validation accuracy: 32.519999999999996\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Cost:  0.18875978579702607 Train Accuracy: 33.593333333333334\n",
            "validation cost: 0.1907067100964245 Validation accuracy: 32.54\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Cost:  0.18850221741983114 Train Accuracy: 33.61555555555555\n",
            "validation cost: 0.1904892059936086 Validation accuracy: 32.68\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Cost:  0.18825334412850223 Train Accuracy: 33.69111111111111\n",
            "validation cost: 0.19025180161140004 Validation accuracy: 32.74\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Cost:  0.1880044663365978 Train Accuracy: 33.83555555555556\n",
            "validation cost: 0.1900279229486706 Validation accuracy: 32.72\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Cost:  0.18776372330109423 Train Accuracy: 33.864444444444445\n",
            "validation cost: 0.1898135900768794 Validation accuracy: 32.66\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Cost:  0.1875276359183972 Train Accuracy: 34.08888888888889\n",
            "validation cost: 0.1895756468684217 Validation accuracy: 32.6\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Cost:  0.18729129248344342 Train Accuracy: 34.135555555555555\n",
            "validation cost: 0.18934797028668277 Validation accuracy: 32.84\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Cost:  0.18705603933679849 Train Accuracy: 34.19333333333333\n",
            "validation cost: 0.18914943628364167 Validation accuracy: 32.9\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Cost:  0.1868335862258414 Train Accuracy: 34.33555555555556\n",
            "validation cost: 0.18894064984239706 Validation accuracy: 32.76\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Cost:  0.18661549706179137 Train Accuracy: 34.36888888888889\n",
            "validation cost: 0.18873087027909435 Validation accuracy: 33.1\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Cost:  0.18640471980879691 Train Accuracy: 34.36222222222222\n",
            "validation cost: 0.1885421476467871 Validation accuracy: 33.32\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Cost:  0.18618465845802892 Train Accuracy: 34.504444444444445\n",
            "validation cost: 0.18833827376821904 Validation accuracy: 33.18\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Cost:  0.18598997559282268 Train Accuracy: 34.50888888888889\n",
            "validation cost: 0.18816990286894802 Validation accuracy: 33.18\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Cost:  0.185779087207699 Train Accuracy: 34.644444444444446\n",
            "validation cost: 0.187979747003888 Validation accuracy: 33.339999999999996\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Cost:  0.18558188357131258 Train Accuracy: 34.715555555555554\n",
            "validation cost: 0.18774614895464195 Validation accuracy: 33.42\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Cost:  0.1853738398950469 Train Accuracy: 34.76888888888889\n",
            "validation cost: 0.18759318828081853 Validation accuracy: 33.379999999999995\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Cost:  0.1851781920694792 Train Accuracy: 34.86\n",
            "validation cost: 0.18740805874908928 Validation accuracy: 33.300000000000004\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Cost:  0.18498160127349192 Train Accuracy: 34.986666666666665\n",
            "validation cost: 0.1872096988645147 Validation accuracy: 33.46\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Cost:  0.18479430295214694 Train Accuracy: 34.97555555555555\n",
            "validation cost: 0.18704938634804943 Validation accuracy: 33.660000000000004\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Cost:  0.18460089739933222 Train Accuracy: 35.10666666666667\n",
            "validation cost: 0.18688013410461146 Validation accuracy: 33.800000000000004\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Cost:  0.18442038238640746 Train Accuracy: 35.202222222222225\n",
            "validation cost: 0.18671177342312056 Validation accuracy: 33.82\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Cost:  0.18423960055531327 Train Accuracy: 35.202222222222225\n",
            "validation cost: 0.18653909732982454 Validation accuracy: 33.98\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "Cost:  0.18404853118774792 Train Accuracy: 35.33555555555555\n",
            "validation cost: 0.1863797611439177 Validation accuracy: 33.839999999999996\n",
            "Iteration: 157\n",
            "Iteration: 158\n",
            "Cost:  0.18387678620856684 Train Accuracy: 35.422222222222224\n",
            "validation cost: 0.18620894618269068 Validation accuracy: 34.28\n",
            "Iteration: 159\n",
            "Iteration: 160\n",
            "Cost:  0.1836862514717265 Train Accuracy: 35.41555555555556\n",
            "validation cost: 0.18604734616737248 Validation accuracy: 34.06\n",
            "Iteration: 161\n",
            "Iteration: 162\n",
            "Cost:  0.18351408145589185 Train Accuracy: 35.48222222222222\n",
            "validation cost: 0.18589573251287228 Validation accuracy: 34.14\n",
            "Iteration: 163\n",
            "Iteration: 164\n",
            "Cost:  0.18334195538675946 Train Accuracy: 35.5\n",
            "validation cost: 0.18575172796243816 Validation accuracy: 34.18\n",
            "Iteration: 165\n",
            "Iteration: 166\n",
            "Cost:  0.18316920316877267 Train Accuracy: 35.675555555555555\n",
            "validation cost: 0.18557761543779783 Validation accuracy: 34.44\n",
            "Iteration: 167\n",
            "Iteration: 168\n",
            "Cost:  0.18300006067156388 Train Accuracy: 35.662222222222226\n",
            "validation cost: 0.18542931771055565 Validation accuracy: 34.44\n",
            "Iteration: 169\n",
            "Iteration: 170\n",
            "Cost:  0.1828414140511596 Train Accuracy: 35.69777777777778\n",
            "validation cost: 0.1852803446354617 Validation accuracy: 34.48\n",
            "Iteration: 171\n",
            "Iteration: 172\n",
            "Cost:  0.18267492702612018 Train Accuracy: 35.79333333333333\n",
            "validation cost: 0.18513938277035763 Validation accuracy: 34.46\n",
            "Iteration: 173\n",
            "Iteration: 174\n",
            "Cost:  0.18251613476001957 Train Accuracy: 35.88444444444445\n",
            "validation cost: 0.18498138130484026 Validation accuracy: 34.58\n",
            "Iteration: 175\n",
            "Iteration: 176\n",
            "Cost:  0.18235513114098742 Train Accuracy: 35.928888888888885\n",
            "validation cost: 0.18484527863918374 Validation accuracy: 34.5\n",
            "Iteration: 177\n",
            "Iteration: 178\n",
            "Cost:  0.1821927991048378 Train Accuracy: 35.93555555555555\n",
            "validation cost: 0.18469961583316713 Validation accuracy: 34.599999999999994\n",
            "Iteration: 179\n",
            "Iteration: 180\n",
            "Cost:  0.18204313625604793 Train Accuracy: 36.02666666666667\n",
            "validation cost: 0.18456517766462116 Validation accuracy: 34.599999999999994\n",
            "Iteration: 181\n",
            "Iteration: 182\n",
            "Cost:  0.18188394055174054 Train Accuracy: 36.031111111111116\n",
            "validation cost: 0.18441811613276127 Validation accuracy: 34.74\n",
            "Iteration: 183\n",
            "Iteration: 184\n",
            "Cost:  0.1817464213253908 Train Accuracy: 36.07333333333334\n",
            "validation cost: 0.18429321346511843 Validation accuracy: 34.760000000000005\n",
            "Iteration: 185\n",
            "Iteration: 186\n",
            "Cost:  0.18158404260156014 Train Accuracy: 36.224444444444444\n",
            "validation cost: 0.1841468085606445 Validation accuracy: 34.94\n",
            "Iteration: 187\n",
            "Iteration: 188\n",
            "Cost:  0.18143928514896454 Train Accuracy: 36.217777777777776\n",
            "validation cost: 0.18401102207010098 Validation accuracy: 34.92\n",
            "Iteration: 189\n",
            "Iteration: 190\n",
            "Cost:  0.18128880981573392 Train Accuracy: 36.33777777777778\n",
            "validation cost: 0.18387749176517715 Validation accuracy: 35.02\n",
            "Iteration: 191\n",
            "Iteration: 192\n",
            "Cost:  0.18114469428384647 Train Accuracy: 36.29333333333334\n",
            "validation cost: 0.18375741624551312 Validation accuracy: 34.92\n",
            "Iteration: 193\n",
            "Iteration: 194\n",
            "Cost:  0.1809967402895415 Train Accuracy: 36.41777777777778\n",
            "validation cost: 0.18362034667582489 Validation accuracy: 35.3\n",
            "Iteration: 195\n",
            "Iteration: 196\n",
            "Cost:  0.18086605682551932 Train Accuracy: 36.37555555555556\n",
            "validation cost: 0.18351047624252012 Validation accuracy: 35.14\n",
            "Iteration: 197\n",
            "Iteration: 198\n",
            "Cost:  0.18071809064045333 Train Accuracy: 36.464444444444446\n",
            "validation cost: 0.18337615225161136 Validation accuracy: 35.199999999999996\n",
            "Iteration: 199\n",
            "Iteration: 200\n",
            "Cost:  0.1805784703769406 Train Accuracy: 36.544444444444444\n",
            "validation cost: 0.18325041393877786 Validation accuracy: 35.42\n",
            "Iteration: 201\n",
            "Iteration: 202\n",
            "Cost:  0.18043693085944926 Train Accuracy: 36.617777777777775\n",
            "validation cost: 0.18313181919379312 Validation accuracy: 35.24\n",
            "Iteration: 203\n",
            "Iteration: 204\n",
            "Cost:  0.18029713577611003 Train Accuracy: 36.644444444444446\n",
            "validation cost: 0.18300887933538426 Validation accuracy: 35.38\n",
            "Iteration: 205\n",
            "Iteration: 206\n",
            "Cost:  0.1801632637183923 Train Accuracy: 36.620000000000005\n",
            "validation cost: 0.1829016209245571 Validation accuracy: 35.42\n",
            "Iteration: 207\n",
            "Iteration: 208\n",
            "Cost:  0.18002579109976996 Train Accuracy: 36.74666666666667\n",
            "validation cost: 0.18276223448027887 Validation accuracy: 35.32\n",
            "Iteration: 209\n",
            "Iteration: 210\n",
            "Cost:  0.17990128891154855 Train Accuracy: 36.74\n",
            "validation cost: 0.18266854981061809 Validation accuracy: 35.14\n",
            "Iteration: 211\n",
            "Iteration: 212\n",
            "Cost:  0.17975746144942137 Train Accuracy: 36.8\n",
            "validation cost: 0.1825501515185355 Validation accuracy: 35.28\n",
            "Iteration: 213\n",
            "Iteration: 214\n",
            "Cost:  0.179628377132295 Train Accuracy: 36.92666666666667\n",
            "validation cost: 0.18242491646060807 Validation accuracy: 35.38\n",
            "Iteration: 215\n",
            "Iteration: 216\n",
            "Cost:  0.1794979679019226 Train Accuracy: 36.922222222222224\n",
            "validation cost: 0.18231963241162125 Validation accuracy: 35.4\n",
            "Iteration: 217\n",
            "Iteration: 218\n",
            "Cost:  0.17937889847990207 Train Accuracy: 36.95111111111111\n",
            "validation cost: 0.1822137724760534 Validation accuracy: 35.3\n",
            "Iteration: 219\n",
            "Iteration: 220\n",
            "Cost:  0.17924421753532205 Train Accuracy: 37.04666666666667\n",
            "validation cost: 0.18209612386552232 Validation accuracy: 35.46\n",
            "Iteration: 221\n",
            "Iteration: 222\n",
            "Cost:  0.17912333215433296 Train Accuracy: 37.035555555555554\n",
            "validation cost: 0.18200673293145628 Validation accuracy: 35.5\n",
            "Iteration: 223\n",
            "Iteration: 224\n",
            "Cost:  0.17899531999025226 Train Accuracy: 37.06666666666666\n",
            "validation cost: 0.1818908342498112 Validation accuracy: 35.36\n",
            "Iteration: 225\n",
            "Iteration: 226\n",
            "Cost:  0.17886961334370846 Train Accuracy: 37.175555555555555\n",
            "validation cost: 0.1817719837199782 Validation accuracy: 35.6\n",
            "Iteration: 227\n",
            "Iteration: 228\n",
            "Cost:  0.17874027065626566 Train Accuracy: 37.22222222222222\n",
            "validation cost: 0.18165639492321073 Validation accuracy: 35.64\n",
            "Iteration: 229\n",
            "Iteration: 230\n",
            "Cost:  0.17862600740750678 Train Accuracy: 37.28\n",
            "validation cost: 0.18156006641633965 Validation accuracy: 35.36\n",
            "Iteration: 231\n",
            "Iteration: 232\n",
            "Cost:  0.1785040488317951 Train Accuracy: 37.29777777777778\n",
            "validation cost: 0.18144489570708994 Validation accuracy: 35.68\n",
            "Iteration: 233\n",
            "Iteration: 234\n",
            "Cost:  0.17837752597709447 Train Accuracy: 37.35777777777778\n",
            "validation cost: 0.1813377477843892 Validation accuracy: 35.86\n",
            "Iteration: 235\n",
            "Iteration: 236\n",
            "Cost:  0.1782605512639044 Train Accuracy: 37.364444444444445\n",
            "validation cost: 0.18125022682180042 Validation accuracy: 35.74\n",
            "Iteration: 237\n",
            "Iteration: 238\n",
            "Cost:  0.17814163465960434 Train Accuracy: 37.49777777777778\n",
            "validation cost: 0.1811325539581281 Validation accuracy: 35.980000000000004\n",
            "Iteration: 239\n",
            "Iteration: 240\n",
            "Cost:  0.1780317596748121 Train Accuracy: 37.437777777777775\n",
            "validation cost: 0.18103988985533626 Validation accuracy: 35.86\n",
            "Iteration: 241\n",
            "Iteration: 242\n",
            "Cost:  0.17791077570924946 Train Accuracy: 37.522222222222226\n",
            "validation cost: 0.1809471970211978 Validation accuracy: 35.94\n",
            "Iteration: 243\n",
            "Iteration: 244\n",
            "Cost:  0.17780124823474874 Train Accuracy: 37.53333333333334\n",
            "validation cost: 0.1808436073608634 Validation accuracy: 35.839999999999996\n",
            "Iteration: 245\n",
            "Iteration: 246\n",
            "Cost:  0.17768526847100402 Train Accuracy: 37.62222222222222\n",
            "validation cost: 0.18075927076893364 Validation accuracy: 35.88\n",
            "Iteration: 247\n",
            "Iteration: 248\n",
            "Cost:  0.17756631122741684 Train Accuracy: 37.662222222222226\n",
            "validation cost: 0.18063527930618745 Validation accuracy: 35.94\n",
            "Iteration: 249\n",
            "Iteration: 250\n",
            "Cost:  0.17745551673194335 Train Accuracy: 37.72\n",
            "validation cost: 0.1805425275504924 Validation accuracy: 36.16\n",
            "Iteration: 251\n",
            "Iteration: 252\n",
            "Cost:  0.1773415353261885 Train Accuracy: 37.79777777777778\n",
            "validation cost: 0.18043465252671398 Validation accuracy: 36.08\n",
            "Iteration: 253\n",
            "Iteration: 254\n",
            "Cost:  0.17724609870865357 Train Accuracy: 37.74666666666667\n",
            "validation cost: 0.18037584325718992 Validation accuracy: 36.08\n",
            "Iteration: 255\n",
            "Iteration: 256\n",
            "Cost:  0.1771275227298488 Train Accuracy: 37.77777777777778\n",
            "validation cost: 0.1802741318315131 Validation accuracy: 35.94\n",
            "Iteration: 257\n",
            "Iteration: 258\n",
            "Cost:  0.17701292817329958 Train Accuracy: 37.833333333333336\n",
            "validation cost: 0.1801685582861871 Validation accuracy: 36.120000000000005\n",
            "Iteration: 259\n",
            "Iteration: 260\n",
            "Cost:  0.17690769152059432 Train Accuracy: 37.922222222222224\n",
            "validation cost: 0.18008610821883564 Validation accuracy: 36.32\n",
            "Iteration: 261\n",
            "Iteration: 262\n",
            "Cost:  0.17679817097152403 Train Accuracy: 37.88444444444444\n",
            "validation cost: 0.17998284177886664 Validation accuracy: 36.3\n",
            "Iteration: 263\n",
            "Iteration: 264\n",
            "Cost:  0.17669097153706964 Train Accuracy: 37.98444444444444\n",
            "validation cost: 0.17988336429455742 Validation accuracy: 36.24\n",
            "Iteration: 265\n",
            "Iteration: 266\n",
            "Cost:  0.1765815806383762 Train Accuracy: 38.03333333333334\n",
            "validation cost: 0.17979096907958556 Validation accuracy: 36.36\n",
            "Iteration: 267\n",
            "Iteration: 268\n",
            "Cost:  0.17647936405361578 Train Accuracy: 38.06444444444445\n",
            "validation cost: 0.1797038877031118 Validation accuracy: 36.4\n",
            "Iteration: 269\n",
            "Iteration: 270\n",
            "Cost:  0.1763814400353109 Train Accuracy: 38.080000000000005\n",
            "validation cost: 0.1796289419906462 Validation accuracy: 36.34\n",
            "Iteration: 271\n",
            "Iteration: 272\n",
            "Cost:  0.17627432095101175 Train Accuracy: 38.13111111111111\n",
            "validation cost: 0.1795274411593518 Validation accuracy: 36.46\n",
            "Iteration: 273\n",
            "Iteration: 274\n",
            "Cost:  0.17617919930615517 Train Accuracy: 38.17111111111111\n",
            "validation cost: 0.17944542983442774 Validation accuracy: 36.34\n",
            "Iteration: 275\n",
            "Iteration: 276\n",
            "Cost:  0.1760744507905535 Train Accuracy: 38.27777777777778\n",
            "validation cost: 0.17933723907392077 Validation accuracy: 36.64\n",
            "Iteration: 277\n",
            "Iteration: 278\n",
            "Cost:  0.1759731694012819 Train Accuracy: 38.233333333333334\n",
            "validation cost: 0.17927478062731833 Validation accuracy: 36.7\n",
            "Iteration: 279\n",
            "Iteration: 280\n",
            "Cost:  0.17586215476747039 Train Accuracy: 38.30444444444445\n",
            "validation cost: 0.17917254056049903 Validation accuracy: 36.52\n",
            "Iteration: 281\n",
            "Iteration: 282\n",
            "Cost:  0.17577418950375806 Train Accuracy: 38.34222222222222\n",
            "validation cost: 0.17910801920550873 Validation accuracy: 36.76\n",
            "Iteration: 283\n",
            "Iteration: 284\n",
            "Cost:  0.17568105717150442 Train Accuracy: 38.46888888888889\n",
            "validation cost: 0.17902053951959823 Validation accuracy: 36.720000000000006\n",
            "Iteration: 285\n",
            "Iteration: 286\n",
            "Cost:  0.17556778204443413 Train Accuracy: 38.48666666666667\n",
            "validation cost: 0.1789082270988236 Validation accuracy: 36.78\n",
            "Iteration: 287\n",
            "Iteration: 288\n",
            "Cost:  0.17546718484656793 Train Accuracy: 38.48444444444444\n",
            "validation cost: 0.17883244554146338 Validation accuracy: 36.74\n",
            "Iteration: 289\n",
            "Iteration: 290\n",
            "Cost:  0.1753787907360976 Train Accuracy: 38.54666666666667\n",
            "validation cost: 0.1787509929416902 Validation accuracy: 36.8\n",
            "Iteration: 291\n",
            "Iteration: 292\n",
            "Cost:  0.17527354458775385 Train Accuracy: 38.57555555555556\n",
            "validation cost: 0.17866140579822717 Validation accuracy: 36.78\n",
            "Iteration: 293\n",
            "Iteration: 294\n",
            "Cost:  0.17518365871343283 Train Accuracy: 38.56666666666666\n",
            "validation cost: 0.17860016055259378 Validation accuracy: 36.919999999999995\n",
            "Iteration: 295\n",
            "Iteration: 296\n",
            "Cost:  0.17508832098362165 Train Accuracy: 38.60666666666667\n",
            "validation cost: 0.17851935938607116 Validation accuracy: 37.019999999999996\n",
            "Iteration: 297\n",
            "Iteration: 298\n",
            "Cost:  0.17498561502541451 Train Accuracy: 38.67777777777778\n",
            "validation cost: 0.17841941589311747 Validation accuracy: 37.0\n",
            "Iteration: 299\n",
            "Iteration: 300\n",
            "Cost:  0.17489633172540095 Train Accuracy: 38.69555555555556\n",
            "validation cost: 0.1783611279820686 Validation accuracy: 37.059999999999995\n",
            "Iteration: 301\n",
            "Iteration: 302\n",
            "Cost:  0.17480045252861096 Train Accuracy: 38.77777777777778\n",
            "validation cost: 0.17826190475660045 Validation accuracy: 36.980000000000004\n",
            "Iteration: 303\n",
            "Iteration: 304\n",
            "Cost:  0.17471204047878972 Train Accuracy: 38.75777777777778\n",
            "validation cost: 0.1781921699111932 Validation accuracy: 36.96\n",
            "Iteration: 305\n",
            "Iteration: 306\n",
            "Cost:  0.1746173756712692 Train Accuracy: 38.78666666666667\n",
            "validation cost: 0.1780952780792196 Validation accuracy: 37.04\n",
            "Iteration: 307\n",
            "Iteration: 308\n",
            "Cost:  0.1745321801998211 Train Accuracy: 38.85111111111111\n",
            "validation cost: 0.17802837474662025 Validation accuracy: 36.919999999999995\n",
            "Iteration: 309\n",
            "Iteration: 310\n",
            "Cost:  0.1744408542796952 Train Accuracy: 38.84444444444444\n",
            "validation cost: 0.17795029769853957 Validation accuracy: 36.919999999999995\n",
            "Iteration: 311\n",
            "Iteration: 312\n",
            "Cost:  0.17435705186207306 Train Accuracy: 38.92\n",
            "validation cost: 0.17788634703942535 Validation accuracy: 37.18\n",
            "Iteration: 313\n",
            "Iteration: 314\n",
            "Cost:  0.17425486386092406 Train Accuracy: 38.937777777777775\n",
            "validation cost: 0.17779765416158116 Validation accuracy: 37.16\n",
            "Iteration: 315\n",
            "Iteration: 316\n",
            "Cost:  0.17416605453723538 Train Accuracy: 38.977777777777774\n",
            "validation cost: 0.17771550258946128 Validation accuracy: 37.04\n",
            "Iteration: 317\n",
            "Iteration: 318\n",
            "Cost:  0.1740789325326235 Train Accuracy: 38.986666666666665\n",
            "validation cost: 0.17765120084382438 Validation accuracy: 37.4\n",
            "Iteration: 319\n",
            "Iteration: 320\n",
            "Cost:  0.17399382650756168 Train Accuracy: 39.022222222222226\n",
            "validation cost: 0.17757991135481424 Validation accuracy: 37.5\n",
            "Iteration: 321\n",
            "Iteration: 322\n",
            "Cost:  0.1739087274951697 Train Accuracy: 39.03777777777778\n",
            "validation cost: 0.17750639581808592 Validation accuracy: 37.36\n",
            "Iteration: 323\n",
            "Iteration: 324\n",
            "Cost:  0.1738168127962257 Train Accuracy: 39.02888888888889\n",
            "validation cost: 0.1774247640222226 Validation accuracy: 37.22\n",
            "Iteration: 325\n",
            "Iteration: 326\n",
            "Cost:  0.1737357130240876 Train Accuracy: 39.071111111111115\n",
            "validation cost: 0.17735363127056103 Validation accuracy: 37.2\n",
            "Iteration: 327\n",
            "Iteration: 328\n",
            "Cost:  0.1736457165319168 Train Accuracy: 39.077777777777776\n",
            "validation cost: 0.17728955799286106 Validation accuracy: 37.480000000000004\n",
            "Iteration: 329\n",
            "Iteration: 330\n",
            "Cost:  0.17356697517006114 Train Accuracy: 39.15555555555555\n",
            "validation cost: 0.1772154174527729 Validation accuracy: 37.36\n",
            "Iteration: 331\n",
            "Iteration: 332\n",
            "Cost:  0.1734756258348421 Train Accuracy: 39.12444444444444\n",
            "validation cost: 0.17714228734594945 Validation accuracy: 37.5\n",
            "Iteration: 333\n",
            "Iteration: 334\n",
            "Cost:  0.1733890282953975 Train Accuracy: 39.14666666666667\n",
            "validation cost: 0.17706945021149312 Validation accuracy: 37.54\n",
            "Iteration: 335\n",
            "Iteration: 336\n",
            "Cost:  0.17330291281934584 Train Accuracy: 39.22888888888889\n",
            "validation cost: 0.17700017853168018 Validation accuracy: 37.36\n",
            "Iteration: 337\n",
            "Iteration: 338\n",
            "Cost:  0.1732271488691704 Train Accuracy: 39.2\n",
            "validation cost: 0.17695166431387607 Validation accuracy: 37.44\n",
            "Iteration: 339\n",
            "Iteration: 340\n",
            "Cost:  0.1731434151655447 Train Accuracy: 39.282222222222224\n",
            "validation cost: 0.1768775176163323 Validation accuracy: 37.44\n",
            "Iteration: 341\n",
            "Iteration: 342\n",
            "Cost:  0.17306076286850205 Train Accuracy: 39.21333333333333\n",
            "validation cost: 0.176808608631383 Validation accuracy: 37.56\n",
            "Iteration: 343\n",
            "Iteration: 344\n",
            "Cost:  0.17298515057234903 Train Accuracy: 39.306666666666665\n",
            "validation cost: 0.17674072534929025 Validation accuracy: 37.62\n",
            "Iteration: 345\n",
            "Iteration: 346\n",
            "Cost:  0.17290831182838473 Train Accuracy: 39.34444444444444\n",
            "validation cost: 0.17666535031530758 Validation accuracy: 37.5\n",
            "Iteration: 347\n",
            "Iteration: 348\n",
            "Cost:  0.17282557183454683 Train Accuracy: 39.32888888888889\n",
            "validation cost: 0.17659861936776677 Validation accuracy: 37.74\n",
            "Iteration: 349\n",
            "Iteration: 350\n",
            "Cost:  0.17274145755238135 Train Accuracy: 39.4\n",
            "validation cost: 0.1765456310775664 Validation accuracy: 37.82\n",
            "Iteration: 351\n",
            "Iteration: 352\n",
            "Cost:  0.1726568755607172 Train Accuracy: 39.42666666666666\n",
            "validation cost: 0.17645832782787718 Validation accuracy: 37.6\n",
            "Iteration: 353\n",
            "Iteration: 354\n",
            "Cost:  0.1725809440614392 Train Accuracy: 39.43333333333333\n",
            "validation cost: 0.17641069280030192 Validation accuracy: 37.74\n",
            "Iteration: 355\n",
            "Iteration: 356\n",
            "Cost:  0.1724975182685377 Train Accuracy: 39.44222222222222\n",
            "validation cost: 0.1763345776721887 Validation accuracy: 37.74\n",
            "Iteration: 357\n",
            "Iteration: 358\n",
            "Cost:  0.17241768307904623 Train Accuracy: 39.468888888888884\n",
            "validation cost: 0.17626799732963852 Validation accuracy: 37.78\n",
            "Iteration: 359\n",
            "Iteration: 360\n",
            "Cost:  0.17236961336596743 Train Accuracy: 39.571111111111115\n",
            "validation cost: 0.17621253028900064 Validation accuracy: 37.88\n",
            "Iteration: 361\n",
            "Iteration: 362\n",
            "Cost:  0.17226636650362023 Train Accuracy: 39.535555555555554\n",
            "validation cost: 0.17614482013756078 Validation accuracy: 37.980000000000004\n",
            "Iteration: 363\n",
            "Iteration: 364\n",
            "Cost:  0.17218752079733424 Train Accuracy: 39.577777777777776\n",
            "validation cost: 0.1760687815705583 Validation accuracy: 38.019999999999996\n",
            "Iteration: 365\n",
            "Iteration: 366\n",
            "Cost:  0.1721151497580831 Train Accuracy: 39.54666666666667\n",
            "validation cost: 0.17601697198281352 Validation accuracy: 38.019999999999996\n",
            "Iteration: 367\n",
            "Iteration: 368\n",
            "Cost:  0.17203644118423467 Train Accuracy: 39.61777777777778\n",
            "validation cost: 0.17594434984977173 Validation accuracy: 38.0\n",
            "Iteration: 369\n",
            "Iteration: 370\n",
            "Cost:  0.17196155347472425 Train Accuracy: 39.635555555555555\n",
            "validation cost: 0.17587911252707203 Validation accuracy: 38.019999999999996\n",
            "Iteration: 371\n",
            "Iteration: 372\n",
            "Cost:  0.17189485030780768 Train Accuracy: 39.66888888888889\n",
            "validation cost: 0.17582783694502258 Validation accuracy: 38.18\n",
            "Iteration: 373\n",
            "Iteration: 374\n",
            "Cost:  0.17181275543539307 Train Accuracy: 39.68222222222222\n",
            "validation cost: 0.17576301708515787 Validation accuracy: 38.14\n",
            "Iteration: 375\n",
            "Iteration: 376\n",
            "Cost:  0.17174180834004316 Train Accuracy: 39.72666666666667\n",
            "validation cost: 0.1757207719002943 Validation accuracy: 38.16\n",
            "Iteration: 377\n",
            "Iteration: 378\n",
            "Cost:  0.17167153102885047 Train Accuracy: 39.76888888888889\n",
            "validation cost: 0.17565123613035968 Validation accuracy: 38.06\n",
            "Iteration: 379\n",
            "Iteration: 380\n",
            "Cost:  0.1715899157679301 Train Accuracy: 39.80444444444444\n",
            "validation cost: 0.1755732811590916 Validation accuracy: 38.14\n",
            "Iteration: 381\n",
            "Iteration: 382\n",
            "Cost:  0.17151040624732983 Train Accuracy: 39.775555555555556\n",
            "validation cost: 0.1755181222159958 Validation accuracy: 38.440000000000005\n",
            "Iteration: 383\n",
            "Iteration: 384\n",
            "Cost:  0.17144237330997567 Train Accuracy: 39.80444444444444\n",
            "validation cost: 0.17545117862824652 Validation accuracy: 38.34\n",
            "Iteration: 385\n",
            "Iteration: 386\n",
            "Cost:  0.1713791128416809 Train Accuracy: 39.87111111111111\n",
            "validation cost: 0.17541760417790675 Validation accuracy: 38.279999999999994\n",
            "Iteration: 387\n",
            "Iteration: 388\n",
            "Cost:  0.17129372076285618 Train Accuracy: 39.855555555555554\n",
            "validation cost: 0.175331982147769 Validation accuracy: 38.32\n",
            "Iteration: 389\n",
            "Iteration: 390\n",
            "Cost:  0.17123168532634778 Train Accuracy: 39.92\n",
            "validation cost: 0.1752838874918877 Validation accuracy: 38.42\n",
            "Iteration: 391\n",
            "Iteration: 392\n",
            "Cost:  0.1711518687104913 Train Accuracy: 39.93333333333333\n",
            "validation cost: 0.17521278437787877 Validation accuracy: 38.3\n",
            "Iteration: 393\n",
            "Iteration: 394\n",
            "Cost:  0.17108222253083785 Train Accuracy: 40.00222222222222\n",
            "validation cost: 0.17515403555054387 Validation accuracy: 38.34\n",
            "Iteration: 395\n",
            "Iteration: 396\n",
            "Cost:  0.1710123944751626 Train Accuracy: 40.04222222222222\n",
            "validation cost: 0.17509967470248639 Validation accuracy: 38.440000000000005\n",
            "Iteration: 397\n",
            "Iteration: 398\n",
            "Cost:  0.17094347834694296 Train Accuracy: 40.04222222222222\n",
            "validation cost: 0.17504305838865586 Validation accuracy: 38.440000000000005\n",
            "Iteration: 399\n",
            "Iteration: 400\n",
            "Cost:  0.17087521137921713 Train Accuracy: 40.03111111111111\n",
            "validation cost: 0.17499201124154354 Validation accuracy: 38.42\n",
            "Iteration: 401\n",
            "Iteration: 402\n",
            "Cost:  0.1708031551940505 Train Accuracy: 40.05111111111111\n",
            "validation cost: 0.17493924202384686 Validation accuracy: 38.64\n",
            "Iteration: 403\n",
            "Iteration: 404\n",
            "Cost:  0.17073771826802034 Train Accuracy: 40.11333333333334\n",
            "validation cost: 0.17487267918283153 Validation accuracy: 38.5\n",
            "Iteration: 405\n",
            "Iteration: 406\n",
            "Cost:  0.17066291059010458 Train Accuracy: 40.13777777777778\n",
            "validation cost: 0.17481332252464069 Validation accuracy: 38.72\n",
            "Iteration: 407\n",
            "Iteration: 408\n",
            "Cost:  0.17059312730751278 Train Accuracy: 40.126666666666665\n",
            "validation cost: 0.17475650914496874 Validation accuracy: 38.46\n",
            "Iteration: 409\n",
            "Iteration: 410\n",
            "Cost:  0.17052769538354468 Train Accuracy: 40.160000000000004\n",
            "validation cost: 0.17471420405225074 Validation accuracy: 38.72\n",
            "Iteration: 411\n",
            "Iteration: 412\n",
            "Cost:  0.1704692802830236 Train Accuracy: 40.20666666666667\n",
            "validation cost: 0.17467459898906137 Validation accuracy: 38.879999999999995\n",
            "Iteration: 413\n",
            "Iteration: 414\n",
            "Cost:  0.17039024424973334 Train Accuracy: 40.21777777777778\n",
            "validation cost: 0.1746012231539969 Validation accuracy: 38.72\n",
            "Iteration: 415\n",
            "Iteration: 416\n",
            "Cost:  0.17031973287225857 Train Accuracy: 40.30888888888889\n",
            "validation cost: 0.17451501765751415 Validation accuracy: 38.58\n",
            "Iteration: 417\n",
            "Iteration: 418\n",
            "Cost:  0.17026842122102248 Train Accuracy: 40.19333333333333\n",
            "validation cost: 0.17450015344596106 Validation accuracy: 38.7\n",
            "Iteration: 419\n",
            "Iteration: 420\n",
            "Cost:  0.17018848741066248 Train Accuracy: 40.33777777777778\n",
            "validation cost: 0.17442288255546864 Validation accuracy: 38.92\n",
            "Iteration: 421\n",
            "Iteration: 422\n",
            "Cost:  0.17012159811794478 Train Accuracy: 40.31777777777778\n",
            "validation cost: 0.1743585463725121 Validation accuracy: 38.800000000000004\n",
            "Iteration: 423\n",
            "Iteration: 424\n",
            "Cost:  0.17005679137742935 Train Accuracy: 40.31111111111111\n",
            "validation cost: 0.1743161029701766 Validation accuracy: 38.879999999999995\n",
            "Iteration: 425\n",
            "Iteration: 426\n",
            "Cost:  0.16998769308273134 Train Accuracy: 40.37111111111111\n",
            "validation cost: 0.17426511593083166 Validation accuracy: 38.98\n",
            "Iteration: 427\n",
            "Iteration: 428\n",
            "Cost:  0.16991571852589893 Train Accuracy: 40.45777777777778\n",
            "validation cost: 0.17419959800226673 Validation accuracy: 38.98\n",
            "Iteration: 429\n",
            "Iteration: 430\n",
            "Cost:  0.1698556310907836 Train Accuracy: 40.38\n",
            "validation cost: 0.1741476985664418 Validation accuracy: 38.96\n",
            "Iteration: 431\n",
            "Iteration: 432\n",
            "Cost:  0.1697998721875694 Train Accuracy: 40.48222222222223\n",
            "validation cost: 0.17411358761374812 Validation accuracy: 38.82\n",
            "Iteration: 433\n",
            "Iteration: 434\n",
            "Cost:  0.16972211850244057 Train Accuracy: 40.5\n",
            "validation cost: 0.17404682231695756 Validation accuracy: 39.0\n",
            "Iteration: 435\n",
            "Iteration: 436\n",
            "Cost:  0.16966595700010884 Train Accuracy: 40.48222222222223\n",
            "validation cost: 0.17400367009980952 Validation accuracy: 38.879999999999995\n",
            "Iteration: 437\n",
            "Iteration: 438\n",
            "Cost:  0.16959639325353743 Train Accuracy: 40.5\n",
            "validation cost: 0.17394628682325772 Validation accuracy: 38.92\n",
            "Iteration: 439\n",
            "Iteration: 440\n",
            "Cost:  0.16953960058929168 Train Accuracy: 40.528888888888886\n",
            "validation cost: 0.1738903048019438 Validation accuracy: 38.98\n",
            "Iteration: 441\n",
            "Iteration: 442\n",
            "Cost:  0.16947484181173925 Train Accuracy: 40.54888888888889\n",
            "validation cost: 0.1738460842914845 Validation accuracy: 38.940000000000005\n",
            "Iteration: 443\n",
            "Iteration: 444\n",
            "Cost:  0.1694036631373118 Train Accuracy: 40.63777777777778\n",
            "validation cost: 0.17378476911295365 Validation accuracy: 39.06\n",
            "Iteration: 445\n",
            "Iteration: 446\n",
            "Cost:  0.16934134129174777 Train Accuracy: 40.62\n",
            "validation cost: 0.173728587739097 Validation accuracy: 39.0\n",
            "Iteration: 447\n",
            "Iteration: 448\n",
            "Cost:  0.16928506377269267 Train Accuracy: 40.635555555555555\n",
            "validation cost: 0.17369729472302414 Validation accuracy: 39.18\n",
            "Iteration: 449\n",
            "Iteration: 450\n",
            "Cost:  0.16921960591115146 Train Accuracy: 40.675555555555555\n",
            "validation cost: 0.17363453497753056 Validation accuracy: 39.019999999999996\n",
            "Iteration: 451\n",
            "Iteration: 452\n",
            "Cost:  0.16915581631398846 Train Accuracy: 40.660000000000004\n",
            "validation cost: 0.1735904068372318 Validation accuracy: 39.2\n",
            "Iteration: 453\n",
            "Iteration: 454\n",
            "Cost:  0.16909477757904387 Train Accuracy: 40.684444444444445\n",
            "validation cost: 0.17354005293017558 Validation accuracy: 39.04\n",
            "Iteration: 455\n",
            "Iteration: 456\n",
            "Cost:  0.16902743032550396 Train Accuracy: 40.72666666666667\n",
            "validation cost: 0.17347467884865017 Validation accuracy: 39.22\n",
            "Iteration: 457\n",
            "Iteration: 458\n",
            "Cost:  0.1689723164733639 Train Accuracy: 40.69555555555556\n",
            "validation cost: 0.173443887686825 Validation accuracy: 39.18\n",
            "Iteration: 459\n",
            "Iteration: 460\n",
            "Cost:  0.1689059903792035 Train Accuracy: 40.85333333333334\n",
            "validation cost: 0.17336635636463266 Validation accuracy: 39.06\n",
            "Iteration: 461\n",
            "Iteration: 462\n",
            "Cost:  0.16884541323006091 Train Accuracy: 40.81333333333333\n",
            "validation cost: 0.17333044198664116 Validation accuracy: 39.08\n",
            "Iteration: 463\n",
            "Iteration: 464\n",
            "Cost:  0.16877862953614303 Train Accuracy: 40.81333333333333\n",
            "validation cost: 0.17327413680015238 Validation accuracy: 39.22\n",
            "Iteration: 465\n",
            "Iteration: 466\n",
            "Cost:  0.16872942717839734 Train Accuracy: 40.846666666666664\n",
            "validation cost: 0.17322787108511392 Validation accuracy: 39.46\n",
            "Iteration: 467\n",
            "Iteration: 468\n",
            "Cost:  0.16867147263900625 Train Accuracy: 40.89555555555556\n",
            "validation cost: 0.1731912214688833 Validation accuracy: 39.42\n",
            "Iteration: 469\n",
            "Iteration: 470\n",
            "Cost:  0.16859573223020924 Train Accuracy: 40.931111111111115\n",
            "validation cost: 0.17312973721719419 Validation accuracy: 39.36\n",
            "Iteration: 471\n",
            "Iteration: 472\n",
            "Cost:  0.16854172000448236 Train Accuracy: 40.9\n",
            "validation cost: 0.17308876457405223 Validation accuracy: 39.42\n",
            "Iteration: 473\n",
            "Iteration: 474\n",
            "Cost:  0.1684782241272308 Train Accuracy: 40.88222222222222\n",
            "validation cost: 0.1730256686515652 Validation accuracy: 39.22\n",
            "Iteration: 475\n",
            "Iteration: 476\n",
            "Cost:  0.16842796990387054 Train Accuracy: 40.971111111111114\n",
            "validation cost: 0.17298558302583408 Validation accuracy: 39.300000000000004\n",
            "Iteration: 477\n",
            "Iteration: 478\n",
            "Cost:  0.16836815129073976 Train Accuracy: 40.98222222222222\n",
            "validation cost: 0.1729402281919515 Validation accuracy: 39.28\n",
            "Iteration: 479\n",
            "Iteration: 480\n",
            "Cost:  0.1682980563767309 Train Accuracy: 41.062222222222225\n",
            "validation cost: 0.17289012770661752 Validation accuracy: 39.42\n",
            "Iteration: 481\n",
            "Iteration: 482\n",
            "Cost:  0.16824899144682187 Train Accuracy: 41.03333333333333\n",
            "validation cost: 0.172856623143426 Validation accuracy: 39.660000000000004\n",
            "Iteration: 483\n",
            "Iteration: 484\n",
            "Cost:  0.16818358362058947 Train Accuracy: 41.031111111111116\n",
            "validation cost: 0.1727881171516413 Validation accuracy: 39.28\n",
            "Iteration: 485\n",
            "Iteration: 486\n",
            "Cost:  0.16812254009771038 Train Accuracy: 41.07777777777778\n",
            "validation cost: 0.1727376179843918 Validation accuracy: 39.28\n",
            "Iteration: 487\n",
            "Iteration: 488\n",
            "Cost:  0.1680698978391169 Train Accuracy: 41.13333333333333\n",
            "validation cost: 0.1726860084665204 Validation accuracy: 39.379999999999995\n",
            "Iteration: 489\n",
            "Iteration: 490\n",
            "Cost:  0.16801009495510735 Train Accuracy: 41.117777777777775\n",
            "validation cost: 0.17265376883617592 Validation accuracy: 39.519999999999996\n",
            "Iteration: 491\n",
            "Iteration: 492\n",
            "Cost:  0.16795602529816314 Train Accuracy: 41.14\n",
            "validation cost: 0.17259326343428893 Validation accuracy: 39.300000000000004\n",
            "Iteration: 493\n",
            "Iteration: 494\n",
            "Cost:  0.16789514234261999 Train Accuracy: 41.19555555555556\n",
            "validation cost: 0.17254934064137872 Validation accuracy: 39.519999999999996\n",
            "Iteration: 495\n",
            "Iteration: 496\n",
            "Cost:  0.16784101503305202 Train Accuracy: 41.18222222222222\n",
            "validation cost: 0.17250850501919765 Validation accuracy: 39.26\n",
            "Iteration: 497\n",
            "Iteration: 498\n",
            "Cost:  0.16777696569437556 Train Accuracy: 41.215555555555554\n",
            "validation cost: 0.17246295746221058 Validation accuracy: 39.7\n",
            "Iteration: 499\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "mlp_lrelu.fit_btch(lr=0.01, nitr= 500, alpha=0, beta=0, tol=5, epsilon=1e-5)\n",
        "t2 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-tCGDdNosMF",
        "outputId": "7efb3e89-3669-4199-c4eb-a09763e7d397"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(39.82, 0.17175530266298739)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_lrelu.evaluate_acc(x_test_vector, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtJDAEZn6fWA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3vltfHd6fno"
      },
      "outputs": [],
      "source": [
        "mlp_lrelu_perf = {'test_perf': mlp_lrelu.evaluate_acc(x_test_vector, test_y), 'train_time': t2-t1,\n",
        "            'train_cost': mlp_lrelu.costs, 'val_cost': mlp_lrelu.val_costs}\n",
        "with open('mlp_lrelu.pickle', 'wb') as h:\n",
        "    pickle.dump(mlp_lrelu_perf, h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D77POWi6fnp"
      },
      "outputs": [],
      "source": [
        "file = drive.CreateFile()\n",
        "file.SetContentFile('mlp_lrelu.pickle')\n",
        "file.Upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYby7OwATNdu"
      },
      "outputs": [],
      "source": [
        "#Tanh\n",
        "mlp_tanh = MLP(activation_func = tanh, activation_deriv= tanh_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 256, 256, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4AzoSSZTOk3",
        "outputId": "c4020370-6fa1-4a90-ea45-a26cccbe7759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Cost:  0.29590320927824565 Train Accuracy: 12.246666666666666\n",
            "validation cost: 0.2915995024482967 Validation accuracy: 12.920000000000002\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Cost:  0.26677146185412387 Train Accuracy: 14.264444444444443\n",
            "validation cost: 0.26268412340801134 Validation accuracy: 15.68\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Cost:  0.2543033466539155 Train Accuracy: 16.36888888888889\n",
            "validation cost: 0.25060349095288276 Validation accuracy: 17.72\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Cost:  0.24579101885237864 Train Accuracy: 17.93777777777778\n",
            "validation cost: 0.24250344910223118 Validation accuracy: 19.32\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Cost:  0.23954216685270735 Train Accuracy: 19.126666666666665\n",
            "validation cost: 0.23663354191151054 Validation accuracy: 20.3\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Cost:  0.23466638327620468 Train Accuracy: 20.213333333333335\n",
            "validation cost: 0.2320759975758768 Validation accuracy: 21.099999999999998\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Cost:  0.23070261056550503 Train Accuracy: 21.240000000000002\n",
            "validation cost: 0.22839622267221074 Validation accuracy: 21.959999999999997\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Cost:  0.22738719628516005 Train Accuracy: 21.846666666666668\n",
            "validation cost: 0.22534597296669737 Validation accuracy: 22.34\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Cost:  0.224544528857617 Train Accuracy: 22.486666666666665\n",
            "validation cost: 0.22272905400681461 Validation accuracy: 23.0\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Cost:  0.22206885724226924 Train Accuracy: 23.13111111111111\n",
            "validation cost: 0.2204509330776786 Validation accuracy: 23.52\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Cost:  0.21988145463278097 Train Accuracy: 23.580000000000002\n",
            "validation cost: 0.21844997557514007 Validation accuracy: 24.060000000000002\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Cost:  0.21793388520123647 Train Accuracy: 24.11777777777778\n",
            "validation cost: 0.21667206326312588 Validation accuracy: 24.68\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Cost:  0.21617790806499196 Train Accuracy: 24.453333333333333\n",
            "validation cost: 0.2150749292472228 Validation accuracy: 25.259999999999998\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Cost:  0.21458906649193255 Train Accuracy: 24.81111111111111\n",
            "validation cost: 0.21362089719066898 Validation accuracy: 25.480000000000004\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Cost:  0.21314043423424117 Train Accuracy: 25.293333333333333\n",
            "validation cost: 0.2123026113631827 Validation accuracy: 25.840000000000003\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Cost:  0.2118104444870748 Train Accuracy: 25.624444444444443\n",
            "validation cost: 0.2110857175935181 Validation accuracy: 26.46\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Cost:  0.21058598470390702 Train Accuracy: 26.046666666666667\n",
            "validation cost: 0.2099771032322459 Validation accuracy: 26.68\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Cost:  0.20945318459042125 Train Accuracy: 26.375555555555557\n",
            "validation cost: 0.20894187973703454 Validation accuracy: 26.88\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Cost:  0.20840479171639745 Train Accuracy: 26.597777777777775\n",
            "validation cost: 0.20797957363721117 Validation accuracy: 27.08\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Cost:  0.2074245464686426 Train Accuracy: 26.866666666666667\n",
            "validation cost: 0.20708542411498584 Validation accuracy: 27.38\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Cost:  0.20651495076017512 Train Accuracy: 27.10222222222222\n",
            "validation cost: 0.2062584286505413 Validation accuracy: 27.500000000000004\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Cost:  0.20565457326391817 Train Accuracy: 27.342222222222222\n",
            "validation cost: 0.2054782969192181 Validation accuracy: 27.639999999999997\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Cost:  0.20485317877697123 Train Accuracy: 27.575555555555553\n",
            "validation cost: 0.20474141096792434 Validation accuracy: 27.92\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Cost:  0.20409015311702625 Train Accuracy: 27.828888888888887\n",
            "validation cost: 0.2040395340056243 Validation accuracy: 28.08\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Cost:  0.20337155720263467 Train Accuracy: 28.09111111111111\n",
            "validation cost: 0.2033884211888753 Validation accuracy: 28.12\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Cost:  0.20269506725010142 Train Accuracy: 28.299999999999997\n",
            "validation cost: 0.20276870306841843 Validation accuracy: 28.38\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Cost:  0.20204955894876475 Train Accuracy: 28.457777777777775\n",
            "validation cost: 0.20217699898091326 Validation accuracy: 28.46\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Cost:  0.20144086033927455 Train Accuracy: 28.686666666666667\n",
            "validation cost: 0.2016175112431454 Validation accuracy: 28.48\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Cost:  0.20085089735013753 Train Accuracy: 28.815555555555555\n",
            "validation cost: 0.20108000845632956 Validation accuracy: 28.660000000000004\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Cost:  0.2002955949828432 Train Accuracy: 28.984444444444446\n",
            "validation cost: 0.20057161782480376 Validation accuracy: 28.82\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Cost:  0.19976335075281695 Train Accuracy: 29.248888888888892\n",
            "validation cost: 0.20008231775138935 Validation accuracy: 28.9\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Cost:  0.19924931559481146 Train Accuracy: 29.39333333333333\n",
            "validation cost: 0.19961195686954225 Validation accuracy: 29.18\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Cost:  0.19875922027941664 Train Accuracy: 29.497777777777777\n",
            "validation cost: 0.19917048336334217 Validation accuracy: 29.42\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Cost:  0.19828795138031854 Train Accuracy: 29.695555555555554\n",
            "validation cost: 0.1987354885221423 Validation accuracy: 29.38\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Cost:  0.19783691793320987 Train Accuracy: 29.804444444444446\n",
            "validation cost: 0.1983207832659685 Validation accuracy: 29.799999999999997\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Cost:  0.1973986390048437 Train Accuracy: 29.964444444444442\n",
            "validation cost: 0.1979279722494495 Validation accuracy: 29.9\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Cost:  0.19697755479072732 Train Accuracy: 30.102222222222224\n",
            "validation cost: 0.19753875488290906 Validation accuracy: 29.959999999999997\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Cost:  0.19657387518188657 Train Accuracy: 30.19333333333333\n",
            "validation cost: 0.19716994991205788 Validation accuracy: 30.18\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Cost:  0.1961767995948364 Train Accuracy: 30.36888888888889\n",
            "validation cost: 0.19680952361774517 Validation accuracy: 30.36\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Cost:  0.1957972440950063 Train Accuracy: 30.54\n",
            "validation cost: 0.1964637827747892 Validation accuracy: 30.380000000000003\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Cost:  0.19542830636956862 Train Accuracy: 30.620000000000005\n",
            "validation cost: 0.19612586080016317 Validation accuracy: 30.56\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Cost:  0.19507097229262366 Train Accuracy: 30.740000000000002\n",
            "validation cost: 0.19579436708096687 Validation accuracy: 30.7\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Cost:  0.19472461800133287 Train Accuracy: 30.875555555555557\n",
            "validation cost: 0.1954809216656343 Validation accuracy: 30.84\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Cost:  0.1943862366132417 Train Accuracy: 30.948888888888888\n",
            "validation cost: 0.1951732526101824 Validation accuracy: 30.880000000000003\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Cost:  0.1940588582599724 Train Accuracy: 31.093333333333334\n",
            "validation cost: 0.19487444066112963 Validation accuracy: 31.04\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Cost:  0.19374013328928508 Train Accuracy: 31.20222222222222\n",
            "validation cost: 0.19458639129626978 Validation accuracy: 31.119999999999997\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Cost:  0.19343079218416998 Train Accuracy: 31.293333333333333\n",
            "validation cost: 0.19430296145895423 Validation accuracy: 31.28\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Cost:  0.19312644031942264 Train Accuracy: 31.424444444444443\n",
            "validation cost: 0.19402210748119797 Validation accuracy: 31.480000000000004\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Cost:  0.19283207390408733 Train Accuracy: 31.506666666666668\n",
            "validation cost: 0.19375284463184406 Validation accuracy: 31.46\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Cost:  0.19254487547198815 Train Accuracy: 31.56\n",
            "validation cost: 0.19350082413440003 Validation accuracy: 31.8\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Cost:  0.1922639267951599 Train Accuracy: 31.666666666666664\n",
            "validation cost: 0.19323594268178407 Validation accuracy: 31.72\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Cost:  0.19199041837645936 Train Accuracy: 31.813333333333333\n",
            "validation cost: 0.19299340970081794 Validation accuracy: 31.8\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Cost:  0.19172168117846966 Train Accuracy: 31.904444444444447\n",
            "validation cost: 0.1927451414653546 Validation accuracy: 31.879999999999995\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Cost:  0.19145989236568095 Train Accuracy: 32.022222222222226\n",
            "validation cost: 0.19250804671714136 Validation accuracy: 32.0\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Cost:  0.1912027255497626 Train Accuracy: 32.053333333333335\n",
            "validation cost: 0.19227016650341916 Validation accuracy: 32.14\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Cost:  0.1909544205833807 Train Accuracy: 32.14888888888889\n",
            "validation cost: 0.1920460796724708 Validation accuracy: 32.2\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Cost:  0.19071024767152486 Train Accuracy: 32.211111111111116\n",
            "validation cost: 0.19183088319120292 Validation accuracy: 32.24\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Cost:  0.19046683990957683 Train Accuracy: 32.28666666666667\n",
            "validation cost: 0.19160223845788318 Validation accuracy: 32.2\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Cost:  0.19023540135001 Train Accuracy: 32.42\n",
            "validation cost: 0.1913967415096982 Validation accuracy: 32.4\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Cost:  0.19000088495181267 Train Accuracy: 32.46666666666667\n",
            "validation cost: 0.19118155196894016 Validation accuracy: 32.2\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Cost:  0.18977768357516459 Train Accuracy: 32.63333333333333\n",
            "validation cost: 0.19098161598364674 Validation accuracy: 32.42\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Cost:  0.189552695521981 Train Accuracy: 32.69555555555556\n",
            "validation cost: 0.19077175202702223 Validation accuracy: 32.54\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Cost:  0.1893406175924663 Train Accuracy: 32.77111111111111\n",
            "validation cost: 0.19057556603824832 Validation accuracy: 32.68\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Cost:  0.18912381835529857 Train Accuracy: 32.86888888888889\n",
            "validation cost: 0.19038875346623974 Validation accuracy: 32.86\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Cost:  0.1889138413936074 Train Accuracy: 32.93111111111111\n",
            "validation cost: 0.19018966695527692 Validation accuracy: 32.92\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Cost:  0.1887072662737575 Train Accuracy: 32.97777777777778\n",
            "validation cost: 0.1900024258061554 Validation accuracy: 33.019999999999996\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Cost:  0.1885057010057212 Train Accuracy: 33.044444444444444\n",
            "validation cost: 0.18982810114286972 Validation accuracy: 33.0\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Cost:  0.18830707873481872 Train Accuracy: 33.135555555555555\n",
            "validation cost: 0.18964310187899278 Validation accuracy: 32.940000000000005\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Cost:  0.18811064512419184 Train Accuracy: 33.24666666666667\n",
            "validation cost: 0.18946027135282748 Validation accuracy: 33.14\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Cost:  0.18792227189713304 Train Accuracy: 33.29555555555556\n",
            "validation cost: 0.18929064748961152 Validation accuracy: 33.26\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Cost:  0.1877288176499023 Train Accuracy: 33.36888888888889\n",
            "validation cost: 0.18911656891625206 Validation accuracy: 33.14\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Cost:  0.18754603546086696 Train Accuracy: 33.45111111111111\n",
            "validation cost: 0.18894544660700485 Validation accuracy: 33.300000000000004\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Cost:  0.1873663534575001 Train Accuracy: 33.51777777777778\n",
            "validation cost: 0.18879660018281044 Validation accuracy: 33.54\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Cost:  0.18717946613995784 Train Accuracy: 33.59111111111111\n",
            "validation cost: 0.18861903531108815 Validation accuracy: 33.22\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Cost:  0.18700368299836057 Train Accuracy: 33.675555555555555\n",
            "validation cost: 0.18846111190550896 Validation accuracy: 33.36\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Cost:  0.18683136180498547 Train Accuracy: 33.73555555555556\n",
            "validation cost: 0.1883058070951087 Validation accuracy: 33.48\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Cost:  0.186655443235263 Train Accuracy: 33.82222222222222\n",
            "validation cost: 0.18814762747335995 Validation accuracy: 33.52\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Cost:  0.18648759727194686 Train Accuracy: 33.83555555555556\n",
            "validation cost: 0.18798445118562737 Validation accuracy: 33.4\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "Cost:  0.1863182042739713 Train Accuracy: 33.928888888888885\n",
            "validation cost: 0.18783871519883086 Validation accuracy: 33.58\n",
            "Iteration: 157\n",
            "Iteration: 158\n",
            "Cost:  0.18615400466326992 Train Accuracy: 34.02444444444445\n",
            "validation cost: 0.1876894933393501 Validation accuracy: 33.6\n",
            "Iteration: 159\n",
            "Iteration: 160\n",
            "Cost:  0.18599138033885362 Train Accuracy: 34.05777777777777\n",
            "validation cost: 0.18754301201191326 Validation accuracy: 33.52\n",
            "Iteration: 161\n",
            "Iteration: 162\n",
            "Cost:  0.18583210608609646 Train Accuracy: 34.15555555555556\n",
            "validation cost: 0.18739670378568468 Validation accuracy: 33.64\n",
            "Iteration: 163\n",
            "Iteration: 164\n",
            "Cost:  0.1856731798786402 Train Accuracy: 34.202222222222225\n",
            "validation cost: 0.1872570537922672 Validation accuracy: 33.7\n",
            "Iteration: 165\n",
            "Iteration: 166\n",
            "Cost:  0.18551781067307396 Train Accuracy: 34.291111111111114\n",
            "validation cost: 0.18711672643649915 Validation accuracy: 33.78\n",
            "Iteration: 167\n",
            "Iteration: 168\n",
            "Cost:  0.18536339094639362 Train Accuracy: 34.34444444444444\n",
            "validation cost: 0.18696825169737039 Validation accuracy: 33.839999999999996\n",
            "Iteration: 169\n",
            "Iteration: 170\n",
            "Cost:  0.1852108798438473 Train Accuracy: 34.404444444444444\n",
            "validation cost: 0.18683293972439435 Validation accuracy: 33.96\n",
            "Iteration: 171\n",
            "Iteration: 172\n",
            "Cost:  0.18506143597455735 Train Accuracy: 34.42\n",
            "validation cost: 0.18670203854421363 Validation accuracy: 34.08\n",
            "Iteration: 173\n",
            "Iteration: 174\n",
            "Cost:  0.1849160734406311 Train Accuracy: 34.52\n",
            "validation cost: 0.18656344632685512 Validation accuracy: 34.1\n",
            "Iteration: 175\n",
            "Iteration: 176\n",
            "Cost:  0.18477209874222214 Train Accuracy: 34.56666666666667\n",
            "validation cost: 0.18644009518706223 Validation accuracy: 34.12\n",
            "Iteration: 177\n",
            "Iteration: 178\n",
            "Cost:  0.18462376053222845 Train Accuracy: 34.67777777777778\n",
            "validation cost: 0.1863000622818855 Validation accuracy: 34.2\n",
            "Iteration: 179\n",
            "Iteration: 180\n",
            "Cost:  0.18448175148126686 Train Accuracy: 34.72222222222222\n",
            "validation cost: 0.18617539760099805 Validation accuracy: 34.22\n",
            "Iteration: 181\n",
            "Iteration: 182\n",
            "Cost:  0.1843469539003604 Train Accuracy: 34.73111111111111\n",
            "validation cost: 0.18605826184782628 Validation accuracy: 34.239999999999995\n",
            "Iteration: 183\n",
            "Iteration: 184\n",
            "Cost:  0.18420151852180938 Train Accuracy: 34.81333333333333\n",
            "validation cost: 0.18592231740713563 Validation accuracy: 34.22\n",
            "Iteration: 185\n",
            "Iteration: 186\n",
            "Cost:  0.18406504064330229 Train Accuracy: 34.89333333333333\n",
            "validation cost: 0.18579318673909057 Validation accuracy: 34.38\n",
            "Iteration: 187\n",
            "Iteration: 188\n",
            "Cost:  0.18392725101981378 Train Accuracy: 34.91111111111111\n",
            "validation cost: 0.1856732810953215 Validation accuracy: 34.4\n",
            "Iteration: 189\n",
            "Iteration: 190\n",
            "Cost:  0.1837939026996542 Train Accuracy: 35.0\n",
            "validation cost: 0.18555367474757317 Validation accuracy: 34.48\n",
            "Iteration: 191\n",
            "Iteration: 192\n",
            "Cost:  0.18366032574518645 Train Accuracy: 35.00888888888889\n",
            "validation cost: 0.18543865419141684 Validation accuracy: 34.599999999999994\n",
            "Iteration: 193\n",
            "Iteration: 194\n",
            "Cost:  0.18352677396964706 Train Accuracy: 35.07555555555555\n",
            "validation cost: 0.1853115392792194 Validation accuracy: 34.62\n",
            "Iteration: 195\n",
            "Iteration: 196\n",
            "Cost:  0.18340231087603703 Train Accuracy: 35.175555555555555\n",
            "validation cost: 0.18519102921219405 Validation accuracy: 34.58\n",
            "Iteration: 197\n",
            "Iteration: 198\n",
            "Cost:  0.18326822568134576 Train Accuracy: 35.22\n",
            "validation cost: 0.18507725769200428 Validation accuracy: 34.660000000000004\n",
            "Iteration: 199\n",
            "Iteration: 200\n",
            "Cost:  0.18314069289482265 Train Accuracy: 35.25333333333333\n",
            "validation cost: 0.1849684108371752 Validation accuracy: 34.74\n",
            "Iteration: 201\n",
            "Iteration: 202\n",
            "Cost:  0.18301539130944197 Train Accuracy: 35.28666666666667\n",
            "validation cost: 0.18485261940425912 Validation accuracy: 34.74\n",
            "Iteration: 203\n",
            "Iteration: 204\n",
            "Cost:  0.18288928855982156 Train Accuracy: 35.35111111111111\n",
            "validation cost: 0.18473575822949703 Validation accuracy: 34.68\n",
            "Iteration: 205\n",
            "Iteration: 206\n",
            "Cost:  0.18276615393388435 Train Accuracy: 35.36666666666667\n",
            "validation cost: 0.1846262033761119 Validation accuracy: 34.72\n",
            "Iteration: 207\n",
            "Iteration: 208\n",
            "Cost:  0.1826440011241286 Train Accuracy: 35.43333333333333\n",
            "validation cost: 0.18452013548206048 Validation accuracy: 34.78\n",
            "Iteration: 209\n",
            "Iteration: 210\n",
            "Cost:  0.18252258763525642 Train Accuracy: 35.53333333333333\n",
            "validation cost: 0.18440068773911708 Validation accuracy: 34.82\n",
            "Iteration: 211\n",
            "Iteration: 212\n",
            "Cost:  0.18240274507045948 Train Accuracy: 35.56444444444444\n",
            "validation cost: 0.18430458264715088 Validation accuracy: 34.9\n",
            "Iteration: 213\n",
            "Iteration: 214\n",
            "Cost:  0.18228386083570017 Train Accuracy: 35.62444444444444\n",
            "validation cost: 0.18418580545652177 Validation accuracy: 34.82\n",
            "Iteration: 215\n",
            "Iteration: 216\n",
            "Cost:  0.18217026132693576 Train Accuracy: 35.64\n",
            "validation cost: 0.18409551188409298 Validation accuracy: 35.02\n",
            "Iteration: 217\n",
            "Iteration: 218\n",
            "Cost:  0.18205186207247093 Train Accuracy: 35.635555555555555\n",
            "validation cost: 0.18398181678896708 Validation accuracy: 34.9\n",
            "Iteration: 219\n",
            "Iteration: 220\n",
            "Cost:  0.1819336527940874 Train Accuracy: 35.74888888888889\n",
            "validation cost: 0.18388009280629608 Validation accuracy: 34.98\n",
            "Iteration: 221\n",
            "Iteration: 222\n",
            "Cost:  0.18182002185703705 Train Accuracy: 35.766666666666666\n",
            "validation cost: 0.18377115690930695 Validation accuracy: 35.02\n",
            "Iteration: 223\n",
            "Iteration: 224\n",
            "Cost:  0.18170712479036263 Train Accuracy: 35.839999999999996\n",
            "validation cost: 0.1836698341435936 Validation accuracy: 35.06\n",
            "Iteration: 225\n",
            "Iteration: 226\n",
            "Cost:  0.18159477927047551 Train Accuracy: 35.87111111111111\n",
            "validation cost: 0.18357319848077697 Validation accuracy: 35.02\n",
            "Iteration: 227\n",
            "Iteration: 228\n",
            "Cost:  0.18148239733254534 Train Accuracy: 35.91111111111111\n",
            "validation cost: 0.18346970792192918 Validation accuracy: 35.120000000000005\n",
            "Iteration: 229\n",
            "Iteration: 230\n",
            "Cost:  0.18137223707841635 Train Accuracy: 35.928888888888885\n",
            "validation cost: 0.18336919767244583 Validation accuracy: 35.099999999999994\n",
            "Iteration: 231\n",
            "Iteration: 232\n",
            "Cost:  0.18126283824382325 Train Accuracy: 35.97111111111111\n",
            "validation cost: 0.18327120395182261 Validation accuracy: 35.260000000000005\n",
            "Iteration: 233\n",
            "Iteration: 234\n",
            "Cost:  0.18115425694469492 Train Accuracy: 35.99777777777778\n",
            "validation cost: 0.18316682385662167 Validation accuracy: 35.18\n",
            "Iteration: 235\n",
            "Iteration: 236\n",
            "Cost:  0.18104935612193823 Train Accuracy: 36.04666666666667\n",
            "validation cost: 0.18308797351086056 Validation accuracy: 35.22\n",
            "Iteration: 237\n",
            "Iteration: 238\n",
            "Cost:  0.18093980529464054 Train Accuracy: 36.12222222222222\n",
            "validation cost: 0.18297778084033994 Validation accuracy: 35.339999999999996\n",
            "Iteration: 239\n",
            "Iteration: 240\n",
            "Cost:  0.18083419692408398 Train Accuracy: 36.13333333333333\n",
            "validation cost: 0.18288458415110437 Validation accuracy: 35.22\n",
            "Iteration: 241\n",
            "Iteration: 242\n",
            "Cost:  0.180731146681598 Train Accuracy: 36.120000000000005\n",
            "validation cost: 0.18279186021919755 Validation accuracy: 35.339999999999996\n",
            "Iteration: 243\n",
            "Iteration: 244\n",
            "Cost:  0.18062719493808296 Train Accuracy: 36.26222222222222\n",
            "validation cost: 0.18270143443076725 Validation accuracy: 35.44\n",
            "Iteration: 245\n",
            "Iteration: 246\n",
            "Cost:  0.1805214044836294 Train Accuracy: 36.27333333333333\n",
            "validation cost: 0.1826036962198209 Validation accuracy: 35.52\n",
            "Iteration: 247\n",
            "Iteration: 248\n",
            "Cost:  0.18042273537792491 Train Accuracy: 36.26888888888889\n",
            "validation cost: 0.18252564291011972 Validation accuracy: 35.5\n",
            "Iteration: 249\n",
            "Iteration: 250\n",
            "Cost:  0.18032120677270258 Train Accuracy: 36.31333333333333\n",
            "validation cost: 0.18243540178950643 Validation accuracy: 35.5\n",
            "Iteration: 251\n",
            "Iteration: 252\n",
            "Cost:  0.1802163796853988 Train Accuracy: 36.41555555555556\n",
            "validation cost: 0.18232965255918526 Validation accuracy: 35.6\n",
            "Iteration: 253\n",
            "Iteration: 254\n",
            "Cost:  0.18011879605628978 Train Accuracy: 36.40222222222222\n",
            "validation cost: 0.18224669009074806 Validation accuracy: 35.82\n",
            "Iteration: 255\n",
            "Iteration: 256\n",
            "Cost:  0.18001805428396495 Train Accuracy: 36.46\n",
            "validation cost: 0.18214953312736631 Validation accuracy: 35.72\n",
            "Iteration: 257\n",
            "Iteration: 258\n",
            "Cost:  0.17991884679560238 Train Accuracy: 36.522222222222226\n",
            "validation cost: 0.182062824619442 Validation accuracy: 35.86\n",
            "Iteration: 259\n",
            "Iteration: 260\n",
            "Cost:  0.1798227020384716 Train Accuracy: 36.54\n",
            "validation cost: 0.18197988087081504 Validation accuracy: 35.82\n",
            "Iteration: 261\n",
            "Iteration: 262\n",
            "Cost:  0.17972433416386027 Train Accuracy: 36.59777777777778\n",
            "validation cost: 0.18189641307940954 Validation accuracy: 35.86\n",
            "Iteration: 263\n",
            "Iteration: 264\n",
            "Cost:  0.17962754567083994 Train Accuracy: 36.61555555555556\n",
            "validation cost: 0.18179908830776417 Validation accuracy: 36.0\n",
            "Iteration: 265\n",
            "Iteration: 266\n",
            "Cost:  0.17953346498820494 Train Accuracy: 36.65111111111111\n",
            "validation cost: 0.1817193733881154 Validation accuracy: 36.08\n",
            "Iteration: 267\n",
            "Iteration: 268\n",
            "Cost:  0.17943685065644938 Train Accuracy: 36.67777777777778\n",
            "validation cost: 0.18163040684931162 Validation accuracy: 36.059999999999995\n",
            "Iteration: 269\n",
            "Iteration: 270\n",
            "Cost:  0.17934428743892508 Train Accuracy: 36.75333333333333\n",
            "validation cost: 0.1815493319524439 Validation accuracy: 35.9\n",
            "Iteration: 271\n",
            "Iteration: 272\n",
            "Cost:  0.17925123300526763 Train Accuracy: 36.79555555555555\n",
            "validation cost: 0.18146275413002863 Validation accuracy: 35.980000000000004\n",
            "Iteration: 273\n",
            "Iteration: 274\n",
            "Cost:  0.17915993962904803 Train Accuracy: 36.80222222222222\n",
            "validation cost: 0.1813825473159746 Validation accuracy: 36.14\n",
            "Iteration: 275\n",
            "Iteration: 276\n",
            "Cost:  0.17906381127056867 Train Accuracy: 36.84444444444445\n",
            "validation cost: 0.18129402497190486 Validation accuracy: 36.199999999999996\n",
            "Iteration: 277\n",
            "Iteration: 278\n",
            "Cost:  0.17897376880097643 Train Accuracy: 36.90222222222222\n",
            "validation cost: 0.18122291558175246 Validation accuracy: 36.3\n",
            "Iteration: 279\n",
            "Iteration: 280\n",
            "Cost:  0.17888060412733017 Train Accuracy: 36.90222222222222\n",
            "validation cost: 0.18113534199104878 Validation accuracy: 36.199999999999996\n",
            "Iteration: 281\n",
            "Iteration: 282\n",
            "Cost:  0.1787996699934218 Train Accuracy: 36.94888888888889\n",
            "validation cost: 0.1810585066702841 Validation accuracy: 36.1\n",
            "Iteration: 283\n",
            "Iteration: 284\n",
            "Cost:  0.17870212658291731 Train Accuracy: 36.971111111111114\n",
            "validation cost: 0.1809835666543469 Validation accuracy: 36.28\n",
            "Iteration: 285\n",
            "Iteration: 286\n",
            "Cost:  0.17861381927052986 Train Accuracy: 37.04222222222222\n",
            "validation cost: 0.18088793059752237 Validation accuracy: 36.4\n",
            "Iteration: 287\n",
            "Iteration: 288\n",
            "Cost:  0.17852422182959188 Train Accuracy: 37.04666666666667\n",
            "validation cost: 0.18082362595013413 Validation accuracy: 36.42\n",
            "Iteration: 289\n",
            "Iteration: 290\n",
            "Cost:  0.17843594288760395 Train Accuracy: 37.095555555555556\n",
            "validation cost: 0.18074081350317311 Validation accuracy: 36.42\n",
            "Iteration: 291\n",
            "Iteration: 292\n",
            "Cost:  0.17834973893643657 Train Accuracy: 37.17777777777778\n",
            "validation cost: 0.18065291422319865 Validation accuracy: 36.36\n",
            "Iteration: 293\n",
            "Iteration: 294\n",
            "Cost:  0.17826607854320806 Train Accuracy: 37.175555555555555\n",
            "validation cost: 0.18057469732122666 Validation accuracy: 36.32\n",
            "Iteration: 295\n",
            "Iteration: 296\n",
            "Cost:  0.17817821323846111 Train Accuracy: 37.215555555555554\n",
            "validation cost: 0.180501252581628 Validation accuracy: 36.44\n",
            "Iteration: 297\n",
            "Iteration: 298\n",
            "Cost:  0.1780917499844716 Train Accuracy: 37.28444444444444\n",
            "validation cost: 0.18043196184703247 Validation accuracy: 36.52\n",
            "Iteration: 299\n",
            "Iteration: 300\n",
            "Cost:  0.1780041019235979 Train Accuracy: 37.29555555555555\n",
            "validation cost: 0.18035166266875524 Validation accuracy: 36.42\n",
            "Iteration: 301\n",
            "Iteration: 302\n",
            "Cost:  0.17792012175545704 Train Accuracy: 37.337777777777774\n",
            "validation cost: 0.18027293086056373 Validation accuracy: 36.559999999999995\n",
            "Iteration: 303\n",
            "Iteration: 304\n",
            "Cost:  0.1778355238243964 Train Accuracy: 37.32666666666667\n",
            "validation cost: 0.18019717890189987 Validation accuracy: 36.58\n",
            "Iteration: 305\n",
            "Iteration: 306\n",
            "Cost:  0.17775219396740832 Train Accuracy: 37.40222222222222\n",
            "validation cost: 0.18012327067405778 Validation accuracy: 36.52\n",
            "Iteration: 307\n",
            "Iteration: 308\n",
            "Cost:  0.1776718626655173 Train Accuracy: 37.41777777777778\n",
            "validation cost: 0.18004509897547635 Validation accuracy: 36.68\n",
            "Iteration: 309\n",
            "Iteration: 310\n",
            "Cost:  0.17758704028833833 Train Accuracy: 37.44\n",
            "validation cost: 0.1799760266434331 Validation accuracy: 36.68\n",
            "Iteration: 311\n",
            "Iteration: 312\n",
            "Cost:  0.17750407025201276 Train Accuracy: 37.47333333333333\n",
            "validation cost: 0.1799034325999509 Validation accuracy: 36.720000000000006\n",
            "Iteration: 313\n",
            "Iteration: 314\n",
            "Cost:  0.1774226229720235 Train Accuracy: 37.49777777777778\n",
            "validation cost: 0.17982569497923015 Validation accuracy: 36.86\n",
            "Iteration: 315\n",
            "Iteration: 316\n",
            "Cost:  0.1773421782791262 Train Accuracy: 37.53111111111111\n",
            "validation cost: 0.17975536484713703 Validation accuracy: 36.86\n",
            "Iteration: 317\n",
            "Iteration: 318\n",
            "Cost:  0.1772625131001929 Train Accuracy: 37.57555555555555\n",
            "validation cost: 0.17968940558937926 Validation accuracy: 36.9\n",
            "Iteration: 319\n",
            "Iteration: 320\n",
            "Cost:  0.17718164895065236 Train Accuracy: 37.577777777777776\n",
            "validation cost: 0.1796107011160714 Validation accuracy: 36.74\n",
            "Iteration: 321\n",
            "Iteration: 322\n",
            "Cost:  0.1771023132722976 Train Accuracy: 37.63777777777778\n",
            "validation cost: 0.1795488995182516 Validation accuracy: 36.76\n",
            "Iteration: 323\n",
            "Iteration: 324\n",
            "Cost:  0.1770225286831971 Train Accuracy: 37.64666666666667\n",
            "validation cost: 0.1794731397299842 Validation accuracy: 36.74\n",
            "Iteration: 325\n",
            "Iteration: 326\n",
            "Cost:  0.17694405825747256 Train Accuracy: 37.71555555555556\n",
            "validation cost: 0.1794007543945697 Validation accuracy: 36.84\n",
            "Iteration: 327\n",
            "Iteration: 328\n",
            "Cost:  0.17686465202860163 Train Accuracy: 37.73777777777777\n",
            "validation cost: 0.17933414747145637 Validation accuracy: 37.0\n",
            "Iteration: 329\n",
            "Iteration: 330\n",
            "Cost:  0.1767883493917839 Train Accuracy: 37.77777777777778\n",
            "validation cost: 0.17926105747483148 Validation accuracy: 36.94\n",
            "Iteration: 331\n",
            "Iteration: 332\n",
            "Cost:  0.17671044439633998 Train Accuracy: 37.78\n",
            "validation cost: 0.17919838137999405 Validation accuracy: 36.9\n",
            "Iteration: 333\n",
            "Iteration: 334\n",
            "Cost:  0.1766343541434899 Train Accuracy: 37.79777777777778\n",
            "validation cost: 0.17912968174851354 Validation accuracy: 36.86\n",
            "Iteration: 335\n",
            "Iteration: 336\n",
            "Cost:  0.1765590842100177 Train Accuracy: 37.806666666666665\n",
            "validation cost: 0.17906329931470802 Validation accuracy: 37.04\n",
            "Iteration: 337\n",
            "Iteration: 338\n",
            "Cost:  0.17648109125518713 Train Accuracy: 37.86222222222222\n",
            "validation cost: 0.17898560624295395 Validation accuracy: 37.04\n",
            "Iteration: 339\n",
            "Iteration: 340\n",
            "Cost:  0.1764057540058687 Train Accuracy: 37.913333333333334\n",
            "validation cost: 0.1789230148835944 Validation accuracy: 36.96\n",
            "Iteration: 341\n",
            "Iteration: 342\n",
            "Cost:  0.17632982958880486 Train Accuracy: 37.90888888888889\n",
            "validation cost: 0.1788527630380053 Validation accuracy: 36.96\n",
            "Iteration: 343\n",
            "Iteration: 344\n",
            "Cost:  0.17625792066426488 Train Accuracy: 37.96222222222222\n",
            "validation cost: 0.1787906182461201 Validation accuracy: 37.04\n",
            "Iteration: 345\n",
            "Iteration: 346\n",
            "Cost:  0.1761814929698227 Train Accuracy: 37.95111111111111\n",
            "validation cost: 0.17871884739841348 Validation accuracy: 37.04\n",
            "Iteration: 347\n",
            "Iteration: 348\n",
            "Cost:  0.176107022636969 Train Accuracy: 38.028888888888886\n",
            "validation cost: 0.1786605339564321 Validation accuracy: 37.04\n",
            "Iteration: 349\n",
            "Iteration: 350\n",
            "Cost:  0.17603444363228385 Train Accuracy: 38.06444444444445\n",
            "validation cost: 0.17859549525731286 Validation accuracy: 37.12\n",
            "Iteration: 351\n",
            "Iteration: 352\n",
            "Cost:  0.17596168967519232 Train Accuracy: 38.12\n",
            "validation cost: 0.17852877236448586 Validation accuracy: 37.019999999999996\n",
            "Iteration: 353\n",
            "Iteration: 354\n",
            "Cost:  0.175887994947677 Train Accuracy: 38.102222222222224\n",
            "validation cost: 0.17846956575605433 Validation accuracy: 36.980000000000004\n",
            "Iteration: 355\n",
            "Iteration: 356\n",
            "Cost:  0.17581473013749765 Train Accuracy: 38.10666666666667\n",
            "validation cost: 0.1784010048886261 Validation accuracy: 37.019999999999996\n",
            "Iteration: 357\n",
            "Iteration: 358\n",
            "Cost:  0.17574396855174967 Train Accuracy: 38.17111111111111\n",
            "validation cost: 0.17834076174360688 Validation accuracy: 37.12\n",
            "Iteration: 359\n",
            "Iteration: 360\n",
            "Cost:  0.17567097378076554 Train Accuracy: 38.17111111111111\n",
            "validation cost: 0.17827283745990247 Validation accuracy: 37.059999999999995\n",
            "Iteration: 361\n",
            "Iteration: 362\n",
            "Cost:  0.17560036554778496 Train Accuracy: 38.211111111111116\n",
            "validation cost: 0.17821096255456614 Validation accuracy: 37.04\n",
            "Iteration: 363\n",
            "Iteration: 364\n",
            "Cost:  0.17552908468068673 Train Accuracy: 38.208888888888886\n",
            "validation cost: 0.1781507741021241 Validation accuracy: 37.059999999999995\n",
            "Iteration: 365\n",
            "Iteration: 366\n",
            "Cost:  0.17545903536387136 Train Accuracy: 38.25333333333333\n",
            "validation cost: 0.17809064898942661 Validation accuracy: 36.980000000000004\n",
            "Iteration: 367\n",
            "Iteration: 368\n",
            "Cost:  0.17540007969440718 Train Accuracy: 38.34222222222222\n",
            "validation cost: 0.17804582411370834 Validation accuracy: 37.1\n",
            "Iteration: 369\n",
            "Iteration: 370\n",
            "Cost:  0.1753183175740193 Train Accuracy: 38.315555555555555\n",
            "validation cost: 0.177964134610769 Validation accuracy: 37.1\n",
            "Iteration: 371\n",
            "Iteration: 372\n",
            "Cost:  0.17525231261314908 Train Accuracy: 38.31777777777778\n",
            "validation cost: 0.177900128676328 Validation accuracy: 37.18\n",
            "Iteration: 373\n",
            "Iteration: 374\n",
            "Cost:  0.17518268160237863 Train Accuracy: 38.34888888888889\n",
            "validation cost: 0.1778337118298254 Validation accuracy: 37.059999999999995\n",
            "Iteration: 375\n",
            "Iteration: 376\n",
            "Cost:  0.17511149526842495 Train Accuracy: 38.38444444444444\n",
            "validation cost: 0.17777502263324993 Validation accuracy: 37.04\n",
            "Iteration: 377\n",
            "Iteration: 378\n",
            "Cost:  0.1750437785268942 Train Accuracy: 38.404444444444444\n",
            "validation cost: 0.17771951956514306 Validation accuracy: 37.18\n",
            "Iteration: 379\n",
            "Iteration: 380\n",
            "Cost:  0.17497451561625763 Train Accuracy: 38.446666666666665\n",
            "validation cost: 0.17765073002979126 Validation accuracy: 37.2\n",
            "Iteration: 381\n",
            "Iteration: 382\n",
            "Cost:  0.17490725363057935 Train Accuracy: 38.48888888888889\n",
            "validation cost: 0.1775917204898668 Validation accuracy: 37.14\n",
            "Iteration: 383\n",
            "Iteration: 384\n",
            "Cost:  0.17484027482305575 Train Accuracy: 38.48888888888889\n",
            "validation cost: 0.17753516818335033 Validation accuracy: 37.14\n",
            "Iteration: 385\n",
            "Iteration: 386\n",
            "Cost:  0.17477273728868112 Train Accuracy: 38.50666666666667\n",
            "validation cost: 0.17747547748499504 Validation accuracy: 37.3\n",
            "Iteration: 387\n",
            "Iteration: 388\n",
            "Cost:  0.17470531729579003 Train Accuracy: 38.526666666666664\n",
            "validation cost: 0.17742136015716078 Validation accuracy: 37.3\n",
            "Iteration: 389\n",
            "Iteration: 390\n",
            "Cost:  0.17463922225067466 Train Accuracy: 38.504444444444445\n",
            "validation cost: 0.17736445478609048 Validation accuracy: 37.24\n",
            "Iteration: 391\n",
            "Iteration: 392\n",
            "Cost:  0.17457282299584634 Train Accuracy: 38.58\n",
            "validation cost: 0.17730462370000935 Validation accuracy: 37.3\n",
            "Iteration: 393\n",
            "Iteration: 394\n",
            "Cost:  0.17450773415668394 Train Accuracy: 38.56888888888889\n",
            "validation cost: 0.17724292298702024 Validation accuracy: 37.4\n",
            "Iteration: 395\n",
            "Iteration: 396\n",
            "Cost:  0.1744412650328109 Train Accuracy: 38.62222222222223\n",
            "validation cost: 0.17719080030107576 Validation accuracy: 37.38\n",
            "Iteration: 397\n",
            "Iteration: 398\n",
            "Cost:  0.17437652803099193 Train Accuracy: 38.62222222222223\n",
            "validation cost: 0.17713198063680347 Validation accuracy: 37.32\n",
            "Iteration: 399\n",
            "Iteration: 400\n",
            "Cost:  0.1743122912591382 Train Accuracy: 38.68666666666667\n",
            "validation cost: 0.17707238693755353 Validation accuracy: 37.34\n",
            "Iteration: 401\n",
            "Iteration: 402\n",
            "Cost:  0.1742468941445787 Train Accuracy: 38.68888888888889\n",
            "validation cost: 0.17701300134968329 Validation accuracy: 37.480000000000004\n",
            "Iteration: 403\n",
            "Iteration: 404\n",
            "Cost:  0.17418274988553897 Train Accuracy: 38.733333333333334\n",
            "validation cost: 0.17695710722793542 Validation accuracy: 37.32\n",
            "Iteration: 405\n",
            "Iteration: 406\n",
            "Cost:  0.17411933265552096 Train Accuracy: 38.74\n",
            "validation cost: 0.17689812634656396 Validation accuracy: 37.46\n",
            "Iteration: 407\n",
            "Iteration: 408\n",
            "Cost:  0.17405599833253316 Train Accuracy: 38.782222222222224\n",
            "validation cost: 0.17684250813461555 Validation accuracy: 37.4\n",
            "Iteration: 409\n",
            "Iteration: 410\n",
            "Cost:  0.1739903192237164 Train Accuracy: 38.83333333333333\n",
            "validation cost: 0.17679108838860422 Validation accuracy: 37.46\n",
            "Iteration: 411\n",
            "Iteration: 412\n",
            "Cost:  0.1739280410511022 Train Accuracy: 38.82666666666667\n",
            "validation cost: 0.1767312147330751 Validation accuracy: 37.480000000000004\n",
            "Iteration: 413\n",
            "Iteration: 414\n",
            "Cost:  0.17386647919332088 Train Accuracy: 38.84222222222222\n",
            "validation cost: 0.1766819991548514 Validation accuracy: 37.44\n",
            "Iteration: 415\n",
            "Iteration: 416\n",
            "Cost:  0.1738019478721207 Train Accuracy: 38.88666666666667\n",
            "validation cost: 0.17662562324287445 Validation accuracy: 37.519999999999996\n",
            "Iteration: 417\n",
            "Iteration: 418\n",
            "Cost:  0.17374009937056556 Train Accuracy: 38.906666666666666\n",
            "validation cost: 0.17656740863131862 Validation accuracy: 37.519999999999996\n",
            "Iteration: 419\n",
            "Iteration: 420\n",
            "Cost:  0.17368008423570117 Train Accuracy: 38.93111111111111\n",
            "validation cost: 0.17651275550610987 Validation accuracy: 37.5\n",
            "Iteration: 421\n",
            "Iteration: 422\n",
            "Cost:  0.17361613218365002 Train Accuracy: 38.98222222222223\n",
            "validation cost: 0.1764659930305853 Validation accuracy: 37.480000000000004\n",
            "Iteration: 423\n",
            "Iteration: 424\n",
            "Cost:  0.17355410857670317 Train Accuracy: 38.98222222222223\n",
            "validation cost: 0.17640311246440113 Validation accuracy: 37.480000000000004\n",
            "Iteration: 425\n",
            "Iteration: 426\n",
            "Cost:  0.17349505028678372 Train Accuracy: 39.05111111111111\n",
            "validation cost: 0.17634957698685005 Validation accuracy: 37.5\n",
            "Iteration: 427\n",
            "Iteration: 428\n",
            "Cost:  0.1734339789814916 Train Accuracy: 39.01777777777778\n",
            "validation cost: 0.17630253114741914 Validation accuracy: 37.419999999999995\n",
            "Iteration: 429\n",
            "Iteration: 430\n",
            "Cost:  0.17337413942404714 Train Accuracy: 39.06444444444445\n",
            "validation cost: 0.1762436674734193 Validation accuracy: 37.62\n",
            "Iteration: 431\n",
            "Iteration: 432\n",
            "Cost:  0.17331061795035643 Train Accuracy: 39.135555555555555\n",
            "validation cost: 0.17619509670246883 Validation accuracy: 37.519999999999996\n",
            "Iteration: 433\n",
            "Iteration: 434\n",
            "Cost:  0.17325114088174168 Train Accuracy: 39.086666666666666\n",
            "validation cost: 0.1761408746032478 Validation accuracy: 37.62\n",
            "Iteration: 435\n",
            "Iteration: 436\n",
            "Cost:  0.17319100636567594 Train Accuracy: 39.144444444444446\n",
            "validation cost: 0.17608656059880218 Validation accuracy: 37.56\n",
            "Iteration: 437\n",
            "Iteration: 438\n",
            "Cost:  0.17313082402081734 Train Accuracy: 39.17777777777778\n",
            "validation cost: 0.1760369187327173 Validation accuracy: 37.64\n",
            "Iteration: 439\n",
            "Iteration: 440\n",
            "Cost:  0.1730719788467845 Train Accuracy: 39.215555555555554\n",
            "validation cost: 0.17598826792254516 Validation accuracy: 37.62\n",
            "Iteration: 441\n",
            "Iteration: 442\n",
            "Cost:  0.17301279718439555 Train Accuracy: 39.18\n",
            "validation cost: 0.17593229164032137 Validation accuracy: 37.62\n",
            "Iteration: 443\n",
            "Iteration: 444\n",
            "Cost:  0.17295605712392662 Train Accuracy: 39.248888888888885\n",
            "validation cost: 0.17588885636750642 Validation accuracy: 37.9\n",
            "Iteration: 445\n",
            "Iteration: 446\n",
            "Cost:  0.17289516254238987 Train Accuracy: 39.22888888888889\n",
            "validation cost: 0.1758348261459842 Validation accuracy: 37.66\n",
            "Iteration: 447\n",
            "Iteration: 448\n",
            "Cost:  0.1728374304370394 Train Accuracy: 39.32666666666667\n",
            "validation cost: 0.17577823539568224 Validation accuracy: 37.78\n",
            "Iteration: 449\n",
            "Iteration: 450\n",
            "Cost:  0.17277885976973084 Train Accuracy: 39.315555555555555\n",
            "validation cost: 0.1757224710554103 Validation accuracy: 37.82\n",
            "Iteration: 451\n",
            "Iteration: 452\n",
            "Cost:  0.17272056274033812 Train Accuracy: 39.34444444444444\n",
            "validation cost: 0.175674050487069 Validation accuracy: 37.74\n",
            "Iteration: 453\n",
            "Iteration: 454\n",
            "Cost:  0.17266304006695826 Train Accuracy: 39.355555555555554\n",
            "validation cost: 0.17563183845813957 Validation accuracy: 37.76\n",
            "Iteration: 455\n",
            "Iteration: 456\n",
            "Cost:  0.17260675136241563 Train Accuracy: 39.36\n",
            "validation cost: 0.1755827715596851 Validation accuracy: 37.940000000000005\n",
            "Iteration: 457\n",
            "Iteration: 458\n",
            "Cost:  0.17254807660830657 Train Accuracy: 39.404444444444444\n",
            "validation cost: 0.17552553400287696 Validation accuracy: 37.82\n",
            "Iteration: 459\n",
            "Iteration: 460\n",
            "Cost:  0.17249227937480907 Train Accuracy: 39.40888888888889\n",
            "validation cost: 0.1754809645760955 Validation accuracy: 37.7\n",
            "Iteration: 461\n",
            "Iteration: 462\n",
            "Cost:  0.17243527989899649 Train Accuracy: 39.464444444444446\n",
            "validation cost: 0.1754276646287049 Validation accuracy: 37.92\n",
            "Iteration: 463\n",
            "Iteration: 464\n",
            "Cost:  0.1723787478623018 Train Accuracy: 39.48\n",
            "validation cost: 0.17538643028662132 Validation accuracy: 37.9\n",
            "Iteration: 465\n",
            "Iteration: 466\n",
            "Cost:  0.17232295543101997 Train Accuracy: 39.46666666666667\n",
            "validation cost: 0.17533026430859291 Validation accuracy: 37.9\n",
            "Iteration: 467\n",
            "Iteration: 468\n",
            "Cost:  0.17226605335734171 Train Accuracy: 39.51555555555555\n",
            "validation cost: 0.17527812179133306 Validation accuracy: 37.82\n",
            "Iteration: 469\n",
            "Iteration: 470\n",
            "Cost:  0.17220928589278447 Train Accuracy: 39.519999999999996\n",
            "validation cost: 0.1752301048372251 Validation accuracy: 37.96\n",
            "Iteration: 471\n",
            "Iteration: 472\n",
            "Cost:  0.17215289992265526 Train Accuracy: 39.526666666666664\n",
            "validation cost: 0.1751851610610398 Validation accuracy: 37.9\n",
            "Iteration: 473\n",
            "Iteration: 474\n",
            "Cost:  0.17209844877375816 Train Accuracy: 39.577777777777776\n",
            "validation cost: 0.1751377258983678 Validation accuracy: 37.96\n",
            "Iteration: 475\n",
            "Iteration: 476\n",
            "Cost:  0.17204339396015214 Train Accuracy: 39.56444444444445\n",
            "validation cost: 0.17508937005718864 Validation accuracy: 38.080000000000005\n",
            "Iteration: 477\n",
            "Iteration: 478\n",
            "Cost:  0.1719886924419904 Train Accuracy: 39.635555555555555\n",
            "validation cost: 0.1750452494980479 Validation accuracy: 37.84\n",
            "Iteration: 479\n",
            "Iteration: 480\n",
            "Cost:  0.17193381860434484 Train Accuracy: 39.62222222222222\n",
            "validation cost: 0.17498450040230595 Validation accuracy: 38.019999999999996\n",
            "Iteration: 481\n",
            "Iteration: 482\n",
            "Cost:  0.1718790359899761 Train Accuracy: 39.6\n",
            "validation cost: 0.17494993738701148 Validation accuracy: 38.04\n",
            "Iteration: 483\n",
            "Iteration: 484\n",
            "Cost:  0.17182408450012515 Train Accuracy: 39.63777777777778\n",
            "validation cost: 0.17490231903997247 Validation accuracy: 38.06\n",
            "Iteration: 485\n",
            "Iteration: 486\n",
            "Cost:  0.17177045926175183 Train Accuracy: 39.69777777777777\n",
            "validation cost: 0.17485064040248072 Validation accuracy: 37.980000000000004\n",
            "Iteration: 487\n",
            "Iteration: 488\n",
            "Cost:  0.17171582574465727 Train Accuracy: 39.68222222222222\n",
            "validation cost: 0.17481138051979103 Validation accuracy: 38.1\n",
            "Iteration: 489\n",
            "Iteration: 490\n",
            "Cost:  0.1716642084883384 Train Accuracy: 39.708888888888886\n",
            "validation cost: 0.17476262662327946 Validation accuracy: 38.18\n",
            "Iteration: 491\n",
            "Iteration: 492\n",
            "Cost:  0.17161019021143883 Train Accuracy: 39.77111111111111\n",
            "validation cost: 0.1747093653114033 Validation accuracy: 38.019999999999996\n",
            "Iteration: 493\n",
            "Iteration: 494\n",
            "Cost:  0.1715549572029482 Train Accuracy: 39.76444444444445\n",
            "validation cost: 0.17466508916002832 Validation accuracy: 38.16\n",
            "Iteration: 495\n",
            "Iteration: 496\n",
            "Cost:  0.17150182498411967 Train Accuracy: 39.79333333333333\n",
            "validation cost: 0.17461477130444855 Validation accuracy: 38.16\n",
            "Iteration: 497\n",
            "Iteration: 498\n",
            "Cost:  0.1714484311207501 Train Accuracy: 39.80444444444444\n",
            "validation cost: 0.17457971419340268 Validation accuracy: 38.080000000000005\n",
            "Iteration: 499\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "mlp_tanh.fit_btch(lr=0.01, nitr= 500, alpha=0, beta=0, tol=5, epsilon=1e-5)\n",
        "t2 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcQ_Dn-PoyLm",
        "outputId": "4691459c-d235-4d69-a6de-62817aaef4f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(39.83, 0.1724528572309131)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_tanh.evaluate_acc(x_test_vector, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP_D21Oh6gku"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "And06uje6gzO"
      },
      "outputs": [],
      "source": [
        "mlp_tanh_perf = {'test_perf': mlp_tanh.evaluate_acc(x_test_vector, test_y), 'train_time': t2-t1,\n",
        "            'train_cost': mlp_tanh.costs, 'val_cost': mlp_tanh.val_costs}\n",
        "with open('mlp_tanh.pickle', 'wb') as h:\n",
        "    pickle.dump(mlp_tanh_perf, h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hzyx2M_6gzP"
      },
      "outputs": [],
      "source": [
        "#del file\n",
        "file = drive.CreateFile()\n",
        "file.SetContentFile('mlp_tanh.pickle')\n",
        "file.Upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDTK74wGo7xK"
      },
      "source": [
        "# Explore the effects of regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIgU3kgoo-yg"
      },
      "outputs": [],
      "source": [
        "# Both models will be assesed with regularization strength=0.1\n",
        "mlp_l1 = MLP(activation_func = relu, activation_deriv= relu_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 256, 256, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mK0xoMkpCPu",
        "outputId": "0d2cfbf7-f801-4874-9251-934411c2060f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Cost:  0.31791362423561514 Train Accuracy: 12.280000000000001\n",
            "validation cost: 0.32092473707609415 Validation accuracy: 11.219999999999999\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Cost:  0.2747463237495339 Train Accuracy: 15.07111111111111\n",
            "validation cost: 0.276849859340628 Validation accuracy: 14.42\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Cost:  0.25677995631334594 Train Accuracy: 17.626666666666665\n",
            "validation cost: 0.25865038915187527 Validation accuracy: 17.28\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Cost:  0.245769333659916 Train Accuracy: 19.224444444444444\n",
            "validation cost: 0.24748629458810437 Validation accuracy: 18.759999999999998\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Cost:  0.2381350062347684 Train Accuracy: 20.608888888888888\n",
            "validation cost: 0.2398320821305996 Validation accuracy: 19.74\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Cost:  0.2325618305504994 Train Accuracy: 21.804444444444446\n",
            "validation cost: 0.23423708570312135 Validation accuracy: 21.16\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Cost:  0.22817483392089133 Train Accuracy: 22.697777777777777\n",
            "validation cost: 0.229817487168759 Validation accuracy: 22.08\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Cost:  0.22456824193979427 Train Accuracy: 23.39333333333333\n",
            "validation cost: 0.22620049198735498 Validation accuracy: 23.1\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Cost:  0.22156611693068515 Train Accuracy: 24.06222222222222\n",
            "validation cost: 0.22315802021575176 Validation accuracy: 23.62\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Cost:  0.2190337122019404 Train Accuracy: 24.713333333333335\n",
            "validation cost: 0.2206883946410033 Validation accuracy: 24.16\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Cost:  0.21679958558843376 Train Accuracy: 25.2\n",
            "validation cost: 0.2184865460316118 Validation accuracy: 24.740000000000002\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Cost:  0.21488752675261488 Train Accuracy: 25.753333333333334\n",
            "validation cost: 0.21658044991040734 Validation accuracy: 25.180000000000003\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Cost:  0.21321200013406097 Train Accuracy: 26.13111111111111\n",
            "validation cost: 0.21492978073311217 Validation accuracy: 25.900000000000002\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Cost:  0.21165309671439209 Train Accuracy: 26.453333333333333\n",
            "validation cost: 0.21338277896595498 Validation accuracy: 26.32\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Cost:  0.21025842231076755 Train Accuracy: 26.82222222222222\n",
            "validation cost: 0.212000699443693 Validation accuracy: 26.68\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Cost:  0.2089809996432023 Train Accuracy: 27.20444444444444\n",
            "validation cost: 0.2107449561308238 Validation accuracy: 27.12\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Cost:  0.207747891212709 Train Accuracy: 27.54888888888889\n",
            "validation cost: 0.20956134388368458 Validation accuracy: 27.36\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Cost:  0.20669308002526532 Train Accuracy: 27.808888888888887\n",
            "validation cost: 0.20854292569927496 Validation accuracy: 27.639999999999997\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Cost:  0.20565458268099296 Train Accuracy: 28.197777777777777\n",
            "validation cost: 0.2074388044264929 Validation accuracy: 27.939999999999998\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Cost:  0.20469429471486011 Train Accuracy: 28.402222222222225\n",
            "validation cost: 0.20653876570415824 Validation accuracy: 28.42\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Cost:  0.20384346527449615 Train Accuracy: 28.673333333333336\n",
            "validation cost: 0.20564045238686018 Validation accuracy: 28.720000000000002\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Cost:  0.20298591810044248 Train Accuracy: 28.78\n",
            "validation cost: 0.20489857066023 Validation accuracy: 28.7\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Cost:  0.20216926755120565 Train Accuracy: 29.002222222222223\n",
            "validation cost: 0.20408383060134805 Validation accuracy: 28.860000000000003\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Cost:  0.2014300224506953 Train Accuracy: 29.26888888888889\n",
            "validation cost: 0.20335378474288268 Validation accuracy: 28.999999999999996\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Cost:  0.20072578035254546 Train Accuracy: 29.37777777777778\n",
            "validation cost: 0.20266843774656046 Validation accuracy: 29.439999999999998\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Cost:  0.20006644391528466 Train Accuracy: 29.62\n",
            "validation cost: 0.2020059618187618 Validation accuracy: 29.54\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Cost:  0.199412014952039 Train Accuracy: 29.828888888888887\n",
            "validation cost: 0.20138551070084937 Validation accuracy: 29.78\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Cost:  0.19879497151209527 Train Accuracy: 30.02444444444444\n",
            "validation cost: 0.20079209873487172 Validation accuracy: 29.74\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Cost:  0.1982253081127542 Train Accuracy: 30.182222222222222\n",
            "validation cost: 0.20025475610387278 Validation accuracy: 29.84\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Cost:  0.19765009007554246 Train Accuracy: 30.388888888888886\n",
            "validation cost: 0.19968492737353863 Validation accuracy: 29.86\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Cost:  0.19710158578127407 Train Accuracy: 30.50888888888889\n",
            "validation cost: 0.19913168474720183 Validation accuracy: 30.48\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Cost:  0.19658988762620322 Train Accuracy: 30.66888888888889\n",
            "validation cost: 0.19866009658048137 Validation accuracy: 30.4\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Cost:  0.19608688127955012 Train Accuracy: 30.91111111111111\n",
            "validation cost: 0.19812572684300805 Validation accuracy: 30.520000000000003\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Cost:  0.19559998901947495 Train Accuracy: 31.053333333333335\n",
            "validation cost: 0.19770106717724154 Validation accuracy: 30.42\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Cost:  0.1951415527801392 Train Accuracy: 31.208888888888893\n",
            "validation cost: 0.19722526603794555 Validation accuracy: 30.56\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Cost:  0.19470637687676887 Train Accuracy: 31.313333333333333\n",
            "validation cost: 0.19676811674890315 Validation accuracy: 30.7\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Cost:  0.194266709318405 Train Accuracy: 31.45777777777778\n",
            "validation cost: 0.19634913911055718 Validation accuracy: 30.919999999999998\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Cost:  0.19385813734358853 Train Accuracy: 31.69111111111111\n",
            "validation cost: 0.1959542028003962 Validation accuracy: 30.9\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Cost:  0.19344812386657365 Train Accuracy: 31.746666666666666\n",
            "validation cost: 0.19556678167061636 Validation accuracy: 31.04\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Cost:  0.1930455041413091 Train Accuracy: 31.83111111111111\n",
            "validation cost: 0.19515126311118486 Validation accuracy: 31.080000000000002\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Cost:  0.19266949235034136 Train Accuracy: 31.966666666666665\n",
            "validation cost: 0.19475724561384763 Validation accuracy: 31.259999999999998\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Cost:  0.19230119455691208 Train Accuracy: 32.07333333333333\n",
            "validation cost: 0.19444562058775616 Validation accuracy: 31.319999999999997\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Cost:  0.19192973780816114 Train Accuracy: 32.15777777777778\n",
            "validation cost: 0.19405860606179512 Validation accuracy: 31.480000000000004\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Cost:  0.191581392499864 Train Accuracy: 32.24444444444444\n",
            "validation cost: 0.19370935874935408 Validation accuracy: 31.52\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Cost:  0.19123580993394415 Train Accuracy: 32.4\n",
            "validation cost: 0.19336880824112068 Validation accuracy: 31.78\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Cost:  0.1909195998992364 Train Accuracy: 32.60666666666667\n",
            "validation cost: 0.19308848450572833 Validation accuracy: 31.979999999999997\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Cost:  0.19055882911724345 Train Accuracy: 32.62444444444444\n",
            "validation cost: 0.1927183817712752 Validation accuracy: 32.16\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Cost:  0.19024650732472706 Train Accuracy: 32.79333333333334\n",
            "validation cost: 0.19240720475758832 Validation accuracy: 32.22\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Cost:  0.1899233233586346 Train Accuracy: 32.88444444444444\n",
            "validation cost: 0.19212845360945402 Validation accuracy: 32.22\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Cost:  0.18963358315314158 Train Accuracy: 33.06222222222222\n",
            "validation cost: 0.19185800166104117 Validation accuracy: 32.48\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Cost:  0.1893216089502478 Train Accuracy: 33.09777777777778\n",
            "validation cost: 0.19155097356378717 Validation accuracy: 32.5\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Cost:  0.1890390590870197 Train Accuracy: 33.17333333333333\n",
            "validation cost: 0.19128529382317436 Validation accuracy: 32.64\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Cost:  0.18875641518246236 Train Accuracy: 33.30888888888889\n",
            "validation cost: 0.1909887607369721 Validation accuracy: 32.82\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Cost:  0.1884688738417234 Train Accuracy: 33.34444444444444\n",
            "validation cost: 0.19072193600127238 Validation accuracy: 32.879999999999995\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Cost:  0.1882081593037259 Train Accuracy: 33.47333333333333\n",
            "validation cost: 0.1904836140037894 Validation accuracy: 32.96\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Cost:  0.18793396554436817 Train Accuracy: 33.53111111111111\n",
            "validation cost: 0.19024738447429854 Validation accuracy: 33.06\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Cost:  0.1876612030157842 Train Accuracy: 33.626666666666665\n",
            "validation cost: 0.18996080778735353 Validation accuracy: 33.4\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Cost:  0.18740498516232212 Train Accuracy: 33.75333333333334\n",
            "validation cost: 0.1897183152620851 Validation accuracy: 33.52\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Cost:  0.18715475934239953 Train Accuracy: 33.79333333333333\n",
            "validation cost: 0.18947697139762426 Validation accuracy: 33.58\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Cost:  0.18690756757687924 Train Accuracy: 33.84444444444444\n",
            "validation cost: 0.18927269159296203 Validation accuracy: 33.6\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Cost:  0.18666796762444038 Train Accuracy: 33.94\n",
            "validation cost: 0.18906245935858723 Validation accuracy: 33.52\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Cost:  0.18641864782468648 Train Accuracy: 34.03333333333333\n",
            "validation cost: 0.18875227490644683 Validation accuracy: 33.86\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Cost:  0.18617421073482654 Train Accuracy: 34.16888888888889\n",
            "validation cost: 0.18853104140989668 Validation accuracy: 34.0\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Cost:  0.18596121708834645 Train Accuracy: 34.27111111111111\n",
            "validation cost: 0.1883114355342282 Validation accuracy: 34.02\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Cost:  0.18571856747494483 Train Accuracy: 34.31333333333333\n",
            "validation cost: 0.18815158186831418 Validation accuracy: 34.260000000000005\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Cost:  0.18553375228313368 Train Accuracy: 34.428888888888885\n",
            "validation cost: 0.1879266183723818 Validation accuracy: 34.12\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Cost:  0.18527069069454788 Train Accuracy: 34.488888888888894\n",
            "validation cost: 0.1877145100511312 Validation accuracy: 34.14\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Cost:  0.18507535312812515 Train Accuracy: 34.58444444444444\n",
            "validation cost: 0.18749651735665718 Validation accuracy: 34.38\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Cost:  0.1848520510895493 Train Accuracy: 34.602222222222224\n",
            "validation cost: 0.1873494610380671 Validation accuracy: 34.239999999999995\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Cost:  0.18465064662510314 Train Accuracy: 34.64888888888889\n",
            "validation cost: 0.18715147324231163 Validation accuracy: 34.32\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Cost:  0.18443582675485412 Train Accuracy: 34.72666666666667\n",
            "validation cost: 0.1869457375005964 Validation accuracy: 34.38\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Cost:  0.1842375976044182 Train Accuracy: 34.77111111111111\n",
            "validation cost: 0.18677260082688052 Validation accuracy: 34.44\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Cost:  0.18402993376088508 Train Accuracy: 34.93777777777778\n",
            "validation cost: 0.18652673384317014 Validation accuracy: 34.46\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Cost:  0.18383637853859222 Train Accuracy: 34.95777777777778\n",
            "validation cost: 0.1864091236310592 Validation accuracy: 34.28\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Cost:  0.1836267973609954 Train Accuracy: 35.04888888888889\n",
            "validation cost: 0.18620109489903322 Validation accuracy: 34.64\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Cost:  0.18344829135244015 Train Accuracy: 35.102222222222224\n",
            "validation cost: 0.18604279482932679 Validation accuracy: 34.52\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Cost:  0.18328343214869117 Train Accuracy: 35.15555555555556\n",
            "validation cost: 0.18589305526796945 Validation accuracy: 34.48\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Cost:  0.18306405161331027 Train Accuracy: 35.282222222222224\n",
            "validation cost: 0.18567941814992492 Validation accuracy: 34.82\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "Cost:  0.18287850564775873 Train Accuracy: 35.364444444444445\n",
            "validation cost: 0.1855215326410907 Validation accuracy: 34.78\n",
            "Iteration: 157\n",
            "Iteration: 158\n",
            "Cost:  0.18269717367229363 Train Accuracy: 35.32666666666667\n",
            "validation cost: 0.18536575795281185 Validation accuracy: 34.699999999999996\n",
            "Iteration: 159\n",
            "Iteration: 160\n",
            "Cost:  0.18251959549261326 Train Accuracy: 35.46666666666667\n",
            "validation cost: 0.1852093146421042 Validation accuracy: 34.68\n",
            "Iteration: 161\n",
            "Iteration: 162\n",
            "Cost:  0.18233371087809178 Train Accuracy: 35.44444444444444\n",
            "validation cost: 0.18502251539394943 Validation accuracy: 34.88\n",
            "Iteration: 163\n",
            "Iteration: 164\n",
            "Cost:  0.18216184601966373 Train Accuracy: 35.57777777777778\n",
            "validation cost: 0.1848570532392564 Validation accuracy: 34.88\n",
            "Iteration: 165\n",
            "Iteration: 166\n",
            "Cost:  0.18199915213236073 Train Accuracy: 35.626666666666665\n",
            "validation cost: 0.18469983731841239 Validation accuracy: 34.839999999999996\n",
            "Iteration: 167\n",
            "Iteration: 168\n",
            "Cost:  0.18180908819504424 Train Accuracy: 35.56666666666667\n",
            "validation cost: 0.1845443426707528 Validation accuracy: 34.839999999999996\n",
            "Iteration: 169\n",
            "Iteration: 170\n",
            "Cost:  0.181636502518353 Train Accuracy: 35.71333333333334\n",
            "validation cost: 0.18439944181064227 Validation accuracy: 35.06\n",
            "Iteration: 171\n",
            "Iteration: 172\n",
            "Cost:  0.18148362077721078 Train Accuracy: 35.86666666666667\n",
            "validation cost: 0.18422325812432747 Validation accuracy: 35.14\n",
            "Iteration: 173\n",
            "Iteration: 174\n",
            "Cost:  0.18131357284333618 Train Accuracy: 35.88222222222222\n",
            "validation cost: 0.18409155698976865 Validation accuracy: 35.18\n",
            "Iteration: 175\n",
            "Iteration: 176\n",
            "Cost:  0.18114669422185078 Train Accuracy: 35.93555555555555\n",
            "validation cost: 0.18394585274961187 Validation accuracy: 35.42\n",
            "Iteration: 177\n",
            "Iteration: 178\n",
            "Cost:  0.18098945969420854 Train Accuracy: 35.973333333333336\n",
            "validation cost: 0.18377847116823065 Validation accuracy: 35.480000000000004\n",
            "Iteration: 179\n",
            "Iteration: 180\n",
            "Cost:  0.18082272367525307 Train Accuracy: 36.059999999999995\n",
            "validation cost: 0.18363525432785835 Validation accuracy: 35.44\n",
            "Iteration: 181\n",
            "Iteration: 182\n",
            "Cost:  0.18067001333089558 Train Accuracy: 36.07111111111111\n",
            "validation cost: 0.1835326035921571 Validation accuracy: 35.28\n",
            "Iteration: 183\n",
            "Iteration: 184\n",
            "Cost:  0.18050438786742087 Train Accuracy: 36.15111111111111\n",
            "validation cost: 0.18338655413322053 Validation accuracy: 35.54\n",
            "Iteration: 185\n",
            "Iteration: 186\n",
            "Cost:  0.18036242538565925 Train Accuracy: 36.26\n",
            "validation cost: 0.18322629147974162 Validation accuracy: 35.74\n",
            "Iteration: 187\n",
            "Iteration: 188\n",
            "Cost:  0.18019374748686554 Train Accuracy: 36.24666666666666\n",
            "validation cost: 0.1830903271065938 Validation accuracy: 35.78\n",
            "Iteration: 189\n",
            "Iteration: 190\n",
            "Cost:  0.18003946376047497 Train Accuracy: 36.34222222222222\n",
            "validation cost: 0.18300026183135368 Validation accuracy: 35.68\n",
            "Iteration: 191\n",
            "Iteration: 192\n",
            "Cost:  0.179917766914087 Train Accuracy: 36.44444444444444\n",
            "validation cost: 0.1828464353287977 Validation accuracy: 35.6\n",
            "Iteration: 193\n",
            "Iteration: 194\n",
            "Cost:  0.1797429021597649 Train Accuracy: 36.455555555555556\n",
            "validation cost: 0.1827414001331328 Validation accuracy: 35.66\n",
            "Iteration: 195\n",
            "Iteration: 196\n",
            "Cost:  0.17963187537164318 Train Accuracy: 36.48444444444445\n",
            "validation cost: 0.1826877349240313 Validation accuracy: 35.74\n",
            "Iteration: 197\n",
            "Iteration: 198\n",
            "Cost:  0.17945095687575652 Train Accuracy: 36.662222222222226\n",
            "validation cost: 0.1824353397553692 Validation accuracy: 35.8\n",
            "Iteration: 199\n",
            "Iteration: 200\n",
            "Cost:  0.17930240656561858 Train Accuracy: 36.66444444444444\n",
            "validation cost: 0.1823227337806092 Validation accuracy: 36.14\n",
            "Iteration: 201\n",
            "Iteration: 202\n",
            "Cost:  0.17915559564020977 Train Accuracy: 36.76\n",
            "validation cost: 0.1822048833272542 Validation accuracy: 35.88\n",
            "Iteration: 203\n",
            "Iteration: 204\n",
            "Cost:  0.17902884076751807 Train Accuracy: 36.8\n",
            "validation cost: 0.1820951985803268 Validation accuracy: 35.64\n",
            "Iteration: 205\n",
            "Iteration: 206\n",
            "Cost:  0.17887530335193846 Train Accuracy: 36.748888888888885\n",
            "validation cost: 0.1819613422054677 Validation accuracy: 35.86\n",
            "Iteration: 207\n",
            "Iteration: 208\n",
            "Cost:  0.17873868910559226 Train Accuracy: 36.87777777777777\n",
            "validation cost: 0.18182323645961737 Validation accuracy: 35.9\n",
            "Iteration: 209\n",
            "Iteration: 210\n",
            "Cost:  0.1786073029110421 Train Accuracy: 36.824444444444445\n",
            "validation cost: 0.18170024569466348 Validation accuracy: 36.059999999999995\n",
            "Iteration: 211\n",
            "Iteration: 212\n",
            "Cost:  0.1784561357369848 Train Accuracy: 37.04888888888889\n",
            "validation cost: 0.18159770960641494 Validation accuracy: 35.92\n",
            "Iteration: 213\n",
            "Iteration: 214\n",
            "Cost:  0.17837136241558413 Train Accuracy: 36.98444444444444\n",
            "validation cost: 0.18149459927977277 Validation accuracy: 35.980000000000004\n",
            "Iteration: 215\n",
            "Iteration: 216\n",
            "Cost:  0.17820469936072206 Train Accuracy: 37.162222222222226\n",
            "validation cost: 0.18136372097020548 Validation accuracy: 35.92\n",
            "Iteration: 217\n",
            "Iteration: 218\n",
            "Cost:  0.17809647265854506 Train Accuracy: 37.12444444444444\n",
            "validation cost: 0.18130493461904956 Validation accuracy: 36.0\n",
            "Iteration: 219\n",
            "Iteration: 220\n",
            "Cost:  0.1779254147900007 Train Accuracy: 37.17777777777778\n",
            "validation cost: 0.1811337362601416 Validation accuracy: 36.199999999999996\n",
            "Iteration: 221\n",
            "Iteration: 222\n",
            "Cost:  0.17781190359724103 Train Accuracy: 37.30444444444444\n",
            "validation cost: 0.1809897231276728 Validation accuracy: 36.059999999999995\n",
            "Iteration: 223\n",
            "Iteration: 224\n",
            "Cost:  0.17766873654462262 Train Accuracy: 37.37333333333333\n",
            "validation cost: 0.18089647729110347 Validation accuracy: 36.0\n",
            "Iteration: 225\n",
            "Iteration: 226\n",
            "Cost:  0.1775438801107825 Train Accuracy: 37.30444444444444\n",
            "validation cost: 0.18083078961987822 Validation accuracy: 36.28\n",
            "Iteration: 227\n",
            "Iteration: 228\n",
            "Cost:  0.17742688341903579 Train Accuracy: 37.31111111111111\n",
            "validation cost: 0.18072585409471645 Validation accuracy: 36.22\n",
            "Iteration: 229\n",
            "Iteration: 230\n",
            "Cost:  0.17728888696134465 Train Accuracy: 37.44222222222222\n",
            "validation cost: 0.18059816181216626 Validation accuracy: 36.44\n",
            "Iteration: 231\n",
            "Iteration: 232\n",
            "Cost:  0.17716579751367093 Train Accuracy: 37.43111111111111\n",
            "validation cost: 0.1804844503470479 Validation accuracy: 36.38\n",
            "Iteration: 233\n",
            "Iteration: 234\n",
            "Cost:  0.17704212591575863 Train Accuracy: 37.586666666666666\n",
            "validation cost: 0.18036800907785785 Validation accuracy: 36.120000000000005\n",
            "Iteration: 235\n",
            "Iteration: 236\n",
            "Cost:  0.17692249059430615 Train Accuracy: 37.60222222222222\n",
            "validation cost: 0.18024754806753143 Validation accuracy: 36.34\n",
            "Iteration: 237\n",
            "Iteration: 238\n",
            "Cost:  0.17680371320115212 Train Accuracy: 37.64222222222222\n",
            "validation cost: 0.18017726439221765 Validation accuracy: 36.18\n",
            "Iteration: 239\n",
            "Iteration: 240\n",
            "Cost:  0.1766918051984646 Train Accuracy: 37.68888888888889\n",
            "validation cost: 0.18006384456432198 Validation accuracy: 36.38\n",
            "Iteration: 241\n",
            "Iteration: 242\n",
            "Cost:  0.17656673791617244 Train Accuracy: 37.72888888888889\n",
            "validation cost: 0.17998395446158916 Validation accuracy: 36.38\n",
            "Iteration: 243\n",
            "Iteration: 244\n",
            "Cost:  0.1764561783118109 Train Accuracy: 37.77777777777778\n",
            "validation cost: 0.17987194547943255 Validation accuracy: 36.18\n",
            "Iteration: 245\n",
            "Iteration: 246\n",
            "Cost:  0.1763320701455191 Train Accuracy: 37.80222222222222\n",
            "validation cost: 0.17979742699972753 Validation accuracy: 36.44\n",
            "Iteration: 247\n",
            "Iteration: 248\n",
            "Cost:  0.17622122524773176 Train Accuracy: 37.82\n",
            "validation cost: 0.1796919595291918 Validation accuracy: 36.5\n",
            "Iteration: 249\n",
            "Iteration: 250\n",
            "Cost:  0.1760890964678329 Train Accuracy: 37.906666666666666\n",
            "validation cost: 0.17957083483828676 Validation accuracy: 36.5\n",
            "Iteration: 251\n",
            "Iteration: 252\n",
            "Cost:  0.17599833597522135 Train Accuracy: 37.971111111111114\n",
            "validation cost: 0.1795039157903782 Validation accuracy: 36.52\n",
            "Iteration: 253\n",
            "Iteration: 254\n",
            "Cost:  0.1759087518247159 Train Accuracy: 38.01111111111111\n",
            "validation cost: 0.17942467717661187 Validation accuracy: 36.5\n",
            "Iteration: 255\n",
            "Iteration: 256\n",
            "Cost:  0.17576650609713443 Train Accuracy: 38.04666666666667\n",
            "validation cost: 0.1792778382319399 Validation accuracy: 36.44\n",
            "Iteration: 257\n",
            "Iteration: 258\n",
            "Cost:  0.17565841809801136 Train Accuracy: 38.111111111111114\n",
            "validation cost: 0.1792052004904674 Validation accuracy: 36.68\n",
            "Iteration: 259\n",
            "Iteration: 260\n",
            "Cost:  0.1755551844389155 Train Accuracy: 38.14444444444444\n",
            "validation cost: 0.17911329841525458 Validation accuracy: 36.64\n",
            "Iteration: 261\n",
            "Iteration: 262\n",
            "Cost:  0.17544311050623446 Train Accuracy: 38.15555555555555\n",
            "validation cost: 0.1789887284496102 Validation accuracy: 36.64\n",
            "Iteration: 263\n",
            "Iteration: 264\n",
            "Cost:  0.1753380948787533 Train Accuracy: 38.29333333333334\n",
            "validation cost: 0.1788955440206059 Validation accuracy: 36.76\n",
            "Iteration: 265\n",
            "Iteration: 266\n",
            "Cost:  0.17523661454149136 Train Accuracy: 38.33111111111111\n",
            "validation cost: 0.17882298044340197 Validation accuracy: 36.720000000000006\n",
            "Iteration: 267\n",
            "Iteration: 268\n",
            "Cost:  0.17512341809996668 Train Accuracy: 38.315555555555555\n",
            "validation cost: 0.17872940128025333 Validation accuracy: 36.78\n",
            "Iteration: 269\n",
            "Iteration: 270\n",
            "Cost:  0.17502457949489147 Train Accuracy: 38.42444444444445\n",
            "validation cost: 0.1786207297902817 Validation accuracy: 36.82\n",
            "Iteration: 271\n",
            "Iteration: 272\n",
            "Cost:  0.1749170927935095 Train Accuracy: 38.40222222222222\n",
            "validation cost: 0.1785543429543754 Validation accuracy: 36.66\n",
            "Iteration: 273\n",
            "Iteration: 274\n",
            "Cost:  0.1748170519772903 Train Accuracy: 38.48222222222223\n",
            "validation cost: 0.17848874685379623 Validation accuracy: 36.84\n",
            "Iteration: 275\n",
            "Iteration: 276\n",
            "Cost:  0.17471261280740044 Train Accuracy: 38.50666666666667\n",
            "validation cost: 0.1783836748510839 Validation accuracy: 36.94\n",
            "Iteration: 277\n",
            "Iteration: 278\n",
            "Cost:  0.17461491007425822 Train Accuracy: 38.54888888888889\n",
            "validation cost: 0.17829741860579726 Validation accuracy: 36.980000000000004\n",
            "Iteration: 279\n",
            "Iteration: 280\n",
            "Cost:  0.17450839786521505 Train Accuracy: 38.58222222222222\n",
            "validation cost: 0.17818799706737187 Validation accuracy: 37.1\n",
            "Iteration: 281\n",
            "Iteration: 282\n",
            "Cost:  0.17441097071217632 Train Accuracy: 38.57111111111111\n",
            "validation cost: 0.17814998338614957 Validation accuracy: 36.64\n",
            "Iteration: 283\n",
            "Iteration: 284\n",
            "Cost:  0.17431892176498065 Train Accuracy: 38.64666666666667\n",
            "validation cost: 0.17802931241010617 Validation accuracy: 36.980000000000004\n",
            "Iteration: 285\n",
            "Iteration: 286\n",
            "Cost:  0.17421834077622997 Train Accuracy: 38.66\n",
            "validation cost: 0.1779500828493644 Validation accuracy: 36.82\n",
            "Iteration: 287\n",
            "Iteration: 288\n",
            "Cost:  0.1741189120396954 Train Accuracy: 38.84\n",
            "validation cost: 0.17789149921720934 Validation accuracy: 37.16\n",
            "Iteration: 289\n",
            "Iteration: 290\n",
            "Cost:  0.17401294049944638 Train Accuracy: 38.76888888888889\n",
            "validation cost: 0.17777832402339508 Validation accuracy: 37.14\n",
            "Iteration: 291\n",
            "Iteration: 292\n",
            "Cost:  0.17392172672466902 Train Accuracy: 38.82666666666667\n",
            "validation cost: 0.1777149893858755 Validation accuracy: 37.059999999999995\n",
            "Iteration: 293\n",
            "Iteration: 294\n",
            "Cost:  0.17384973559443181 Train Accuracy: 38.84\n",
            "validation cost: 0.1775994783724054 Validation accuracy: 37.18\n",
            "Iteration: 295\n",
            "Iteration: 296\n",
            "Cost:  0.17375679813720532 Train Accuracy: 38.913333333333334\n",
            "validation cost: 0.17752056714290665 Validation accuracy: 37.3\n",
            "Iteration: 297\n",
            "Iteration: 298\n",
            "Cost:  0.17363757713142883 Train Accuracy: 38.89555555555555\n",
            "validation cost: 0.17743837188999986 Validation accuracy: 37.14\n",
            "Iteration: 299\n",
            "Iteration: 300\n",
            "Cost:  0.17354457369312581 Train Accuracy: 38.995555555555555\n",
            "validation cost: 0.1773942997813501 Validation accuracy: 37.18\n",
            "Iteration: 301\n",
            "Iteration: 302\n",
            "Cost:  0.17346860671232467 Train Accuracy: 38.977777777777774\n",
            "validation cost: 0.17733776904601986 Validation accuracy: 37.16\n",
            "Iteration: 303\n",
            "Iteration: 304\n",
            "Cost:  0.17336113284646748 Train Accuracy: 39.06\n",
            "validation cost: 0.17721117852248483 Validation accuracy: 37.36\n",
            "Iteration: 305\n",
            "Iteration: 306\n",
            "Cost:  0.17327370980189954 Train Accuracy: 39.11333333333333\n",
            "validation cost: 0.17709965328257854 Validation accuracy: 37.32\n",
            "Iteration: 307\n",
            "Iteration: 308\n",
            "Cost:  0.17318909874600372 Train Accuracy: 39.160000000000004\n",
            "validation cost: 0.17703758949077195 Validation accuracy: 37.22\n",
            "Iteration: 309\n",
            "Iteration: 310\n",
            "Cost:  0.1730985590969624 Train Accuracy: 39.068888888888885\n",
            "validation cost: 0.1769829032921539 Validation accuracy: 37.56\n",
            "Iteration: 311\n",
            "Iteration: 312\n",
            "Cost:  0.17299525073173141 Train Accuracy: 39.184444444444445\n",
            "validation cost: 0.1768931384545935 Validation accuracy: 37.3\n",
            "Iteration: 313\n",
            "Iteration: 314\n",
            "Cost:  0.17291744899483313 Train Accuracy: 39.24\n",
            "validation cost: 0.17684265063192325 Validation accuracy: 37.64\n",
            "Iteration: 315\n",
            "Iteration: 316\n",
            "Cost:  0.1728240760553876 Train Accuracy: 39.20444444444444\n",
            "validation cost: 0.17676037173801465 Validation accuracy: 37.56\n",
            "Iteration: 317\n",
            "Iteration: 318\n",
            "Cost:  0.17274034170804028 Train Accuracy: 39.266666666666666\n",
            "validation cost: 0.17664497019498623 Validation accuracy: 37.519999999999996\n",
            "Iteration: 319\n",
            "Iteration: 320\n",
            "Cost:  0.17264555926976516 Train Accuracy: 39.24444444444444\n",
            "validation cost: 0.17661523689493627 Validation accuracy: 37.580000000000005\n",
            "Iteration: 321\n",
            "Iteration: 322\n",
            "Cost:  0.17255771402946246 Train Accuracy: 39.4\n",
            "validation cost: 0.17649789768182833 Validation accuracy: 37.580000000000005\n",
            "Iteration: 323\n",
            "Iteration: 324\n",
            "Cost:  0.1724805651163239 Train Accuracy: 39.31777777777778\n",
            "validation cost: 0.17648101194672552 Validation accuracy: 37.580000000000005\n",
            "Iteration: 325\n",
            "Iteration: 326\n",
            "Cost:  0.17238113667746172 Train Accuracy: 39.40888888888889\n",
            "validation cost: 0.176381887116158 Validation accuracy: 37.56\n",
            "Iteration: 327\n",
            "Iteration: 328\n",
            "Cost:  0.17231687246656638 Train Accuracy: 39.38666666666666\n",
            "validation cost: 0.1763099109690039 Validation accuracy: 37.7\n",
            "Iteration: 329\n",
            "Iteration: 330\n",
            "Cost:  0.17222732149636913 Train Accuracy: 39.4\n",
            "validation cost: 0.1762390232964939 Validation accuracy: 37.56\n",
            "Iteration: 331\n",
            "Iteration: 332\n",
            "Cost:  0.17212828540859182 Train Accuracy: 39.42\n",
            "validation cost: 0.17614455847150176 Validation accuracy: 37.8\n",
            "Iteration: 333\n",
            "Iteration: 334\n",
            "Cost:  0.17206175008999827 Train Accuracy: 39.42\n",
            "validation cost: 0.1761199943990613 Validation accuracy: 37.68\n",
            "Iteration: 335\n",
            "Iteration: 336\n",
            "Cost:  0.17198119518998337 Train Accuracy: 39.568888888888885\n",
            "validation cost: 0.1760286371205093 Validation accuracy: 37.56\n",
            "Iteration: 337\n",
            "Iteration: 338\n",
            "Cost:  0.17188270819636253 Train Accuracy: 39.58222222222222\n",
            "validation cost: 0.1759507871931869 Validation accuracy: 37.64\n",
            "Iteration: 339\n",
            "Iteration: 340\n",
            "Cost:  0.17181273046336923 Train Accuracy: 39.513333333333335\n",
            "validation cost: 0.1758723544609305 Validation accuracy: 37.6\n",
            "Iteration: 341\n",
            "Iteration: 342\n",
            "Cost:  0.17173800429522298 Train Accuracy: 39.608888888888885\n",
            "validation cost: 0.17581805371211748 Validation accuracy: 37.68\n",
            "Iteration: 343\n",
            "Iteration: 344\n",
            "Cost:  0.17163806904609644 Train Accuracy: 39.67333333333333\n",
            "validation cost: 0.1757215279222469 Validation accuracy: 37.74\n",
            "Iteration: 345\n",
            "Iteration: 346\n",
            "Cost:  0.17157613338450128 Train Accuracy: 39.76888888888889\n",
            "validation cost: 0.17568562778233274 Validation accuracy: 37.940000000000005\n",
            "Iteration: 347\n",
            "Iteration: 348\n",
            "Cost:  0.17148560245645675 Train Accuracy: 39.82666666666667\n",
            "validation cost: 0.17560526096991366 Validation accuracy: 37.92\n",
            "Iteration: 349\n",
            "Iteration: 350\n",
            "Cost:  0.1714209842694707 Train Accuracy: 39.82222222222222\n",
            "validation cost: 0.17554508676880584 Validation accuracy: 37.96\n",
            "Iteration: 351\n",
            "Iteration: 352\n",
            "Cost:  0.17133603698712263 Train Accuracy: 39.800000000000004\n",
            "validation cost: 0.17546748852168267 Validation accuracy: 37.92\n",
            "Iteration: 353\n",
            "Iteration: 354\n",
            "Cost:  0.17126678541790302 Train Accuracy: 39.74444444444444\n",
            "validation cost: 0.17545632063026853 Validation accuracy: 37.92\n",
            "Iteration: 355\n",
            "Iteration: 356\n",
            "Cost:  0.1711903397778788 Train Accuracy: 39.89111111111111\n",
            "validation cost: 0.1753148558000568 Validation accuracy: 38.06\n",
            "Iteration: 357\n",
            "Iteration: 358\n",
            "Cost:  0.17110919209781808 Train Accuracy: 39.79333333333333\n",
            "validation cost: 0.17533153912121863 Validation accuracy: 37.980000000000004\n",
            "Iteration: 359\n",
            "Iteration: 360\n",
            "Cost:  0.1710511394131215 Train Accuracy: 39.80888888888889\n",
            "validation cost: 0.17529792087568766 Validation accuracy: 38.04\n",
            "Iteration: 361\n",
            "Iteration: 362\n",
            "Cost:  0.17095243666545626 Train Accuracy: 39.955555555555556\n",
            "validation cost: 0.1751213892239079 Validation accuracy: 37.940000000000005\n",
            "Iteration: 363\n",
            "Iteration: 364\n",
            "Cost:  0.17088604154760412 Train Accuracy: 40.00222222222222\n",
            "validation cost: 0.17506917423116317 Validation accuracy: 38.04\n",
            "Iteration: 365\n",
            "Iteration: 366\n",
            "Cost:  0.17081628335070526 Train Accuracy: 40.02222222222222\n",
            "validation cost: 0.17503574067329625 Validation accuracy: 38.22\n",
            "Iteration: 367\n",
            "Iteration: 368\n",
            "Cost:  0.17071156434384147 Train Accuracy: 40.01777777777778\n",
            "validation cost: 0.17491769188167583 Validation accuracy: 38.12\n",
            "Iteration: 369\n",
            "Iteration: 370\n",
            "Cost:  0.17063864484697888 Train Accuracy: 40.02444444444445\n",
            "validation cost: 0.17486364523930234 Validation accuracy: 38.12\n",
            "Iteration: 371\n",
            "Iteration: 372\n",
            "Cost:  0.17056115015029163 Train Accuracy: 40.06444444444445\n",
            "validation cost: 0.17479430998758727 Validation accuracy: 38.14\n",
            "Iteration: 373\n",
            "Iteration: 374\n",
            "Cost:  0.17049102228555438 Train Accuracy: 40.14\n",
            "validation cost: 0.17476670286783186 Validation accuracy: 38.019999999999996\n",
            "Iteration: 375\n",
            "Iteration: 376\n",
            "Cost:  0.17042357895963273 Train Accuracy: 40.126666666666665\n",
            "validation cost: 0.17468876385926488 Validation accuracy: 38.22\n",
            "Iteration: 377\n",
            "Iteration: 378\n",
            "Cost:  0.17033942692629125 Train Accuracy: 40.24666666666666\n",
            "validation cost: 0.1746105798860882 Validation accuracy: 38.12\n",
            "Iteration: 379\n",
            "Iteration: 380\n",
            "Cost:  0.17028384004417976 Train Accuracy: 40.14666666666667\n",
            "validation cost: 0.17455908381367968 Validation accuracy: 38.3\n",
            "Iteration: 381\n",
            "Iteration: 382\n",
            "Cost:  0.17019219104311153 Train Accuracy: 40.31111111111111\n",
            "validation cost: 0.17448899400944368 Validation accuracy: 38.24\n",
            "Iteration: 383\n",
            "Iteration: 384\n",
            "Cost:  0.17013670856395272 Train Accuracy: 40.22888888888889\n",
            "validation cost: 0.17443747684217506 Validation accuracy: 38.279999999999994\n",
            "Iteration: 385\n",
            "Iteration: 386\n",
            "Cost:  0.1700608998687326 Train Accuracy: 40.215555555555554\n",
            "validation cost: 0.1743827833236586 Validation accuracy: 38.32\n",
            "Iteration: 387\n",
            "Iteration: 388\n",
            "Cost:  0.16999830225443668 Train Accuracy: 40.282222222222224\n",
            "validation cost: 0.1743349244479668 Validation accuracy: 38.3\n",
            "Iteration: 389\n",
            "Iteration: 390\n",
            "Cost:  0.1699132971491904 Train Accuracy: 40.29555555555556\n",
            "validation cost: 0.1742313576539119 Validation accuracy: 38.379999999999995\n",
            "Iteration: 391\n",
            "Iteration: 392\n",
            "Cost:  0.16985203204451135 Train Accuracy: 40.35777777777778\n",
            "validation cost: 0.17418331849478363 Validation accuracy: 38.4\n",
            "Iteration: 393\n",
            "Iteration: 394\n",
            "Cost:  0.16977014407543395 Train Accuracy: 40.486666666666665\n",
            "validation cost: 0.17412410337948458 Validation accuracy: 38.36\n",
            "Iteration: 395\n",
            "Iteration: 396\n",
            "Cost:  0.16970875530849686 Train Accuracy: 40.50222222222222\n",
            "validation cost: 0.1741037384288019 Validation accuracy: 38.440000000000005\n",
            "Iteration: 397\n",
            "Iteration: 398\n",
            "Cost:  0.16964319665848565 Train Accuracy: 40.45111111111111\n",
            "validation cost: 0.17403044399275042 Validation accuracy: 38.519999999999996\n",
            "Iteration: 399\n",
            "Iteration: 400\n",
            "Cost:  0.1695590600339922 Train Accuracy: 40.48222222222223\n",
            "validation cost: 0.17396189807740187 Validation accuracy: 38.58\n",
            "Iteration: 401\n",
            "Iteration: 402\n",
            "Cost:  0.16948883770216913 Train Accuracy: 40.513333333333335\n",
            "validation cost: 0.17389019705160114 Validation accuracy: 38.48\n",
            "Iteration: 403\n",
            "Iteration: 404\n",
            "Cost:  0.169418841199245 Train Accuracy: 40.6\n",
            "validation cost: 0.17386540125845296 Validation accuracy: 38.46\n",
            "Iteration: 405\n",
            "Iteration: 406\n",
            "Cost:  0.16934998076026364 Train Accuracy: 40.58222222222222\n",
            "validation cost: 0.17376752742531792 Validation accuracy: 38.6\n",
            "Iteration: 407\n",
            "Iteration: 408\n",
            "Cost:  0.16929169579427544 Train Accuracy: 40.553333333333335\n",
            "validation cost: 0.17373769114139317 Validation accuracy: 38.68\n",
            "Iteration: 409\n",
            "Iteration: 410\n",
            "Cost:  0.1692298212255098 Train Accuracy: 40.66222222222222\n",
            "validation cost: 0.17364261405649392 Validation accuracy: 38.64\n",
            "Iteration: 411\n",
            "Iteration: 412\n",
            "Cost:  0.16914722992557424 Train Accuracy: 40.67333333333333\n",
            "validation cost: 0.17363111091550773 Validation accuracy: 38.5\n",
            "Iteration: 413\n",
            "Iteration: 414\n",
            "Cost:  0.16908179164817502 Train Accuracy: 40.71777777777778\n",
            "validation cost: 0.1735468501901382 Validation accuracy: 38.62\n",
            "Iteration: 415\n",
            "Iteration: 416\n",
            "Cost:  0.1690187454473518 Train Accuracy: 40.64\n",
            "validation cost: 0.17350386371595866 Validation accuracy: 38.9\n",
            "Iteration: 417\n",
            "Iteration: 418\n",
            "Cost:  0.16895329858629346 Train Accuracy: 40.78888888888889\n",
            "validation cost: 0.17344672541528272 Validation accuracy: 38.7\n",
            "Iteration: 419\n",
            "Iteration: 420\n",
            "Cost:  0.16889125120997112 Train Accuracy: 40.742222222222225\n",
            "validation cost: 0.17342433456966594 Validation accuracy: 38.76\n",
            "Iteration: 421\n",
            "Iteration: 422\n",
            "Cost:  0.16882682094276363 Train Accuracy: 40.784444444444446\n",
            "validation cost: 0.17334184517287152 Validation accuracy: 39.0\n",
            "Iteration: 423\n",
            "Iteration: 424\n",
            "Cost:  0.16875143748475646 Train Accuracy: 40.87777777777778\n",
            "validation cost: 0.1732779853833816 Validation accuracy: 38.74\n",
            "Iteration: 425\n",
            "Iteration: 426\n",
            "Cost:  0.1686832668202016 Train Accuracy: 40.86\n",
            "validation cost: 0.1732154432387431 Validation accuracy: 38.92\n",
            "Iteration: 427\n",
            "Iteration: 428\n",
            "Cost:  0.16863402911535103 Train Accuracy: 40.922222222222224\n",
            "validation cost: 0.1731977315365227 Validation accuracy: 38.62\n",
            "Iteration: 429\n",
            "Iteration: 430\n",
            "Cost:  0.16858003781418252 Train Accuracy: 40.791111111111114\n",
            "validation cost: 0.17318709112788455 Validation accuracy: 39.019999999999996\n",
            "Iteration: 431\n",
            "Iteration: 432\n",
            "Cost:  0.16849952140509658 Train Accuracy: 40.93555555555555\n",
            "validation cost: 0.1730725017163685 Validation accuracy: 38.940000000000005\n",
            "Iteration: 433\n",
            "Iteration: 434\n",
            "Cost:  0.16842808364103584 Train Accuracy: 40.96222222222222\n",
            "validation cost: 0.1730343339477131 Validation accuracy: 38.66\n",
            "Iteration: 435\n",
            "Iteration: 436\n",
            "Cost:  0.1683700091865677 Train Accuracy: 40.91555555555556\n",
            "validation cost: 0.1729850382455868 Validation accuracy: 38.96\n",
            "Iteration: 437\n",
            "Iteration: 438\n",
            "Cost:  0.1683058951291733 Train Accuracy: 40.96\n",
            "validation cost: 0.17294275954160526 Validation accuracy: 38.96\n",
            "Iteration: 439\n",
            "Iteration: 440\n",
            "Cost:  0.16823375040275876 Train Accuracy: 41.004444444444445\n",
            "validation cost: 0.17283955358250302 Validation accuracy: 38.879999999999995\n",
            "Iteration: 441\n",
            "Iteration: 442\n",
            "Cost:  0.16817114914678327 Train Accuracy: 41.11333333333334\n",
            "validation cost: 0.17280808755189767 Validation accuracy: 39.04\n",
            "Iteration: 443\n",
            "Iteration: 444\n",
            "Cost:  0.16812520262891756 Train Accuracy: 41.05777777777778\n",
            "validation cost: 0.17280449973563752 Validation accuracy: 39.1\n",
            "Iteration: 445\n",
            "Iteration: 446\n",
            "Cost:  0.16804161918386137 Train Accuracy: 41.08444444444444\n",
            "validation cost: 0.17271933339774637 Validation accuracy: 39.019999999999996\n",
            "Iteration: 447\n",
            "Iteration: 448\n",
            "Cost:  0.1680115013210979 Train Accuracy: 41.15555555555556\n",
            "validation cost: 0.17266153450964772 Validation accuracy: 39.019999999999996\n",
            "Iteration: 449\n",
            "Iteration: 450\n",
            "Cost:  0.16792765260994097 Train Accuracy: 41.135555555555555\n",
            "validation cost: 0.17262085653127296 Validation accuracy: 39.24\n",
            "Iteration: 451\n",
            "Iteration: 452\n",
            "Cost:  0.16786684711503969 Train Accuracy: 41.086666666666666\n",
            "validation cost: 0.17256175188869757 Validation accuracy: 39.08\n",
            "Iteration: 453\n",
            "Iteration: 454\n",
            "Cost:  0.16780980738866638 Train Accuracy: 41.215555555555554\n",
            "validation cost: 0.17253734142742091 Validation accuracy: 39.04\n",
            "Iteration: 455\n",
            "Iteration: 456\n",
            "Cost:  0.1677652883260475 Train Accuracy: 41.15111111111111\n",
            "validation cost: 0.17247452312939393 Validation accuracy: 39.08\n",
            "Iteration: 457\n",
            "Iteration: 458\n",
            "Cost:  0.16768411877018508 Train Accuracy: 41.266666666666666\n",
            "validation cost: 0.17243415451807723 Validation accuracy: 39.14\n",
            "Iteration: 459\n",
            "Iteration: 460\n",
            "Cost:  0.16763691673075362 Train Accuracy: 41.266666666666666\n",
            "validation cost: 0.17240894509155627 Validation accuracy: 39.2\n",
            "Iteration: 461\n",
            "Iteration: 462\n",
            "Cost:  0.16755447430800424 Train Accuracy: 41.30888888888889\n",
            "validation cost: 0.1723265505757453 Validation accuracy: 39.42\n",
            "Iteration: 463\n",
            "Iteration: 464\n",
            "Cost:  0.16748629390432396 Train Accuracy: 41.37555555555556\n",
            "validation cost: 0.1722657174572573 Validation accuracy: 39.22\n",
            "Iteration: 465\n",
            "Iteration: 466\n",
            "Cost:  0.16743175570035745 Train Accuracy: 41.40222222222222\n",
            "validation cost: 0.17222122290310132 Validation accuracy: 39.34\n",
            "Iteration: 467\n",
            "Iteration: 468\n",
            "Cost:  0.16738010511050017 Train Accuracy: 41.30444444444444\n",
            "validation cost: 0.17215497545939346 Validation accuracy: 39.26\n",
            "Iteration: 469\n",
            "Iteration: 470\n",
            "Cost:  0.16731081969999287 Train Accuracy: 41.406666666666666\n",
            "validation cost: 0.17210567658744902 Validation accuracy: 39.22\n",
            "Iteration: 471\n",
            "Iteration: 472\n",
            "Cost:  0.16727347377121904 Train Accuracy: 41.397777777777776\n",
            "validation cost: 0.17206770948761568 Validation accuracy: 39.24\n",
            "Iteration: 473\n",
            "Iteration: 474\n",
            "Cost:  0.1672034642877457 Train Accuracy: 41.47777777777778\n",
            "validation cost: 0.17204480674113024 Validation accuracy: 39.26\n",
            "Iteration: 475\n",
            "Iteration: 476\n",
            "Cost:  0.16713884734655923 Train Accuracy: 41.47111111111111\n",
            "validation cost: 0.1719673975450365 Validation accuracy: 39.379999999999995\n",
            "Iteration: 477\n",
            "Iteration: 478\n",
            "Cost:  0.16709238174349517 Train Accuracy: 41.422222222222224\n",
            "validation cost: 0.17197214237599456 Validation accuracy: 39.48\n",
            "Iteration: 479\n",
            "Iteration: 480\n",
            "Cost:  0.16702821840068627 Train Accuracy: 41.504444444444445\n",
            "validation cost: 0.17189544504645016 Validation accuracy: 39.44\n",
            "Iteration: 481\n",
            "Iteration: 482\n",
            "Cost:  0.16697181015197382 Train Accuracy: 41.53333333333333\n",
            "validation cost: 0.17186387889453744 Validation accuracy: 39.6\n",
            "Iteration: 483\n",
            "Iteration: 484\n",
            "Cost:  0.16691153455233038 Train Accuracy: 41.62888888888889\n",
            "validation cost: 0.17178436277618933 Validation accuracy: 39.32\n",
            "Iteration: 485\n",
            "Iteration: 486\n",
            "Cost:  0.16685534898886006 Train Accuracy: 41.58\n",
            "validation cost: 0.17176183347139085 Validation accuracy: 39.379999999999995\n",
            "Iteration: 487\n",
            "Iteration: 488\n",
            "Cost:  0.166794452432394 Train Accuracy: 41.62888888888889\n",
            "validation cost: 0.17167748471616495 Validation accuracy: 39.4\n",
            "Iteration: 489\n",
            "Iteration: 490\n",
            "Cost:  0.1667427571556241 Train Accuracy: 41.65111111111111\n",
            "validation cost: 0.17165794133635343 Validation accuracy: 39.44\n",
            "Iteration: 491\n",
            "Iteration: 492\n",
            "Cost:  0.16669516021146155 Train Accuracy: 41.657777777777774\n",
            "validation cost: 0.17161638019541958 Validation accuracy: 39.44\n",
            "Iteration: 493\n",
            "Iteration: 494\n",
            "Cost:  0.16663223268074573 Train Accuracy: 41.66444444444444\n",
            "validation cost: 0.17158735442826084 Validation accuracy: 39.5\n",
            "Iteration: 495\n",
            "Iteration: 496\n",
            "Cost:  0.16658090740158296 Train Accuracy: 41.693333333333335\n",
            "validation cost: 0.17148757552213803 Validation accuracy: 39.48\n",
            "Iteration: 497\n",
            "Iteration: 498\n",
            "Cost:  0.16651254650378164 Train Accuracy: 41.67333333333333\n",
            "validation cost: 0.17145057949493786 Validation accuracy: 39.62\n",
            "Iteration: 499\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "mlp_l1.fit_btch(lr=0.01, nitr= 500, alpha=0, beta=0.1, tol=5, epsilon=1e-5)\n",
        "t2 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNSAmNypFhD",
        "outputId": "45db64f1-b082-4e69-f9d0-c5bbe4b3c4db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40.22, 0.16949206481186058)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_l1.evaluate_acc(x_test_vector, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3puxf0Sb-1k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBTWtX1wb_MP"
      },
      "outputs": [],
      "source": [
        "mlp_l1_perf = {'test_perf': mlp_l1.evaluate_acc(x_test_vector, test_y), 'train_time': t2-t1,\n",
        "            'train_cost': mlp_l1.costs, 'val_cost': mlp_l1.val_costs}\n",
        "with open('mlp_l1.pickle', 'wb') as h:\n",
        "    pickle.dump(mlp_l1_perf, h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THdr7Dsnb_MR"
      },
      "outputs": [],
      "source": [
        "#del file\n",
        "file = drive.CreateFile()\n",
        "file.SetContentFile('mlp_l1.pickle')\n",
        "file.Upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMJHqKLbpIM3"
      },
      "outputs": [],
      "source": [
        "mlp_l2 = MLP(activation_func = relu, activation_deriv= relu_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 256, 256, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1uGSv3mpIxK",
        "outputId": "966569b3-57fb-4acd-a73a-8ee54b2eb320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Cost:  0.3340346948160217 Train Accuracy: 8.975555555555555\n",
            "validation cost: 0.33109495782534587 Validation accuracy: 9.02\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Cost:  0.28296538442487595 Train Accuracy: 11.86\n",
            "validation cost: 0.2802644232547973 Validation accuracy: 11.959999999999999\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Cost:  0.2650236671731104 Train Accuracy: 14.453333333333335\n",
            "validation cost: 0.26260162346214305 Validation accuracy: 14.760000000000002\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Cost:  0.25400389093255715 Train Accuracy: 16.344444444444445\n",
            "validation cost: 0.2518293507690181 Validation accuracy: 16.76\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Cost:  0.2464994754948658 Train Accuracy: 17.846666666666668\n",
            "validation cost: 0.24452696820787456 Validation accuracy: 18.279999999999998\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Cost:  0.24086689370170453 Train Accuracy: 19.13111111111111\n",
            "validation cost: 0.23907764809389365 Validation accuracy: 19.24\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Cost:  0.23637621138381953 Train Accuracy: 20.20888888888889\n",
            "validation cost: 0.23478392209134877 Validation accuracy: 20.54\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Cost:  0.23265061832459588 Train Accuracy: 21.13111111111111\n",
            "validation cost: 0.2312445364896878 Validation accuracy: 21.52\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Cost:  0.22942915658333934 Train Accuracy: 21.926666666666666\n",
            "validation cost: 0.22816281226865 Validation accuracy: 22.2\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Cost:  0.22662964643704753 Train Accuracy: 22.675555555555555\n",
            "validation cost: 0.22553109538457036 Validation accuracy: 22.720000000000002\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Cost:  0.22416095168523922 Train Accuracy: 23.266666666666666\n",
            "validation cost: 0.2231563012180005 Validation accuracy: 23.380000000000003\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Cost:  0.22196757490350655 Train Accuracy: 23.915555555555557\n",
            "validation cost: 0.2210597911555065 Validation accuracy: 23.919999999999998\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Cost:  0.21997887792199858 Train Accuracy: 24.43777777777778\n",
            "validation cost: 0.2191714241942642 Validation accuracy: 24.36\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Cost:  0.21816858267936665 Train Accuracy: 24.855555555555554\n",
            "validation cost: 0.21745184950231086 Validation accuracy: 24.88\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Cost:  0.21651857505553282 Train Accuracy: 25.333333333333336\n",
            "validation cost: 0.21589224674816232 Validation accuracy: 25.36\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Cost:  0.21502554270330063 Train Accuracy: 25.675555555555558\n",
            "validation cost: 0.21447544074175368 Validation accuracy: 25.86\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Cost:  0.21361255965522943 Train Accuracy: 26.24222222222222\n",
            "validation cost: 0.21315833805328682 Validation accuracy: 26.22\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Cost:  0.2123152872232521 Train Accuracy: 26.568888888888885\n",
            "validation cost: 0.21193434330789984 Validation accuracy: 26.58\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Cost:  0.2110832946009295 Train Accuracy: 26.966666666666665\n",
            "validation cost: 0.2107585173502146 Validation accuracy: 26.8\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Cost:  0.20994930625993932 Train Accuracy: 27.295555555555556\n",
            "validation cost: 0.20970693322726333 Validation accuracy: 27.3\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Cost:  0.20889869948953535 Train Accuracy: 27.655555555555555\n",
            "validation cost: 0.20874446720868334 Validation accuracy: 27.66\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Cost:  0.2078924842024965 Train Accuracy: 27.913333333333334\n",
            "validation cost: 0.20779490201346493 Validation accuracy: 28.12\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Cost:  0.20694967081231022 Train Accuracy: 28.271111111111114\n",
            "validation cost: 0.20691193973553032 Validation accuracy: 28.4\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Cost:  0.20605190619653224 Train Accuracy: 28.446666666666665\n",
            "validation cost: 0.20608996749958008 Validation accuracy: 28.7\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Cost:  0.20518706789967525 Train Accuracy: 28.695555555555558\n",
            "validation cost: 0.20528568545662704 Validation accuracy: 28.84\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Cost:  0.20438162503833324 Train Accuracy: 28.884444444444448\n",
            "validation cost: 0.2045435060301084 Validation accuracy: 29.18\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Cost:  0.20359837501420758 Train Accuracy: 29.186666666666667\n",
            "validation cost: 0.20383473374653358 Validation accuracy: 29.599999999999998\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Cost:  0.20285662368084872 Train Accuracy: 29.468888888888888\n",
            "validation cost: 0.20315821206501486 Validation accuracy: 29.74\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Cost:  0.20215909060695614 Train Accuracy: 29.593333333333334\n",
            "validation cost: 0.2025259439751712 Validation accuracy: 29.78\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Cost:  0.2014943141259528 Train Accuracy: 29.835555555555555\n",
            "validation cost: 0.20191685582581545 Validation accuracy: 29.98\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Cost:  0.20083271195015548 Train Accuracy: 30.09111111111111\n",
            "validation cost: 0.20133352315785552 Validation accuracy: 29.880000000000003\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Cost:  0.20020535740860465 Train Accuracy: 30.24222222222222\n",
            "validation cost: 0.20078169860560277 Validation accuracy: 30.04\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Cost:  0.19962288559199381 Train Accuracy: 30.433333333333334\n",
            "validation cost: 0.2002550505948893 Validation accuracy: 30.18\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Cost:  0.1990317828784171 Train Accuracy: 30.513333333333332\n",
            "validation cost: 0.19971312564644336 Validation accuracy: 30.36\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Cost:  0.19848077303715828 Train Accuracy: 30.693333333333335\n",
            "validation cost: 0.19920489287709944 Validation accuracy: 30.520000000000003\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Cost:  0.19794549053240573 Train Accuracy: 30.866666666666664\n",
            "validation cost: 0.19871587041740396 Validation accuracy: 30.459999999999997\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Cost:  0.19742327015699423 Train Accuracy: 31.046666666666667\n",
            "validation cost: 0.19823948573932942 Validation accuracy: 30.659999999999997\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Cost:  0.19692737453715123 Train Accuracy: 31.166666666666664\n",
            "validation cost: 0.1977574670322195 Validation accuracy: 30.7\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Cost:  0.19644858733364304 Train Accuracy: 31.28\n",
            "validation cost: 0.19732866226162266 Validation accuracy: 30.880000000000003\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Cost:  0.19596501805800304 Train Accuracy: 31.4\n",
            "validation cost: 0.19688428149774653 Validation accuracy: 31.0\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Cost:  0.19549807784324988 Train Accuracy: 31.57111111111111\n",
            "validation cost: 0.19644638837538664 Validation accuracy: 31.28\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Cost:  0.19506231057591525 Train Accuracy: 31.77333333333333\n",
            "validation cost: 0.19605490748423768 Validation accuracy: 31.46\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Cost:  0.19464532951884783 Train Accuracy: 31.77111111111111\n",
            "validation cost: 0.1956518122270711 Validation accuracy: 31.44\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Cost:  0.1942027447935933 Train Accuracy: 32.05555555555556\n",
            "validation cost: 0.1952476712033022 Validation accuracy: 31.64\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Cost:  0.19380100241553636 Train Accuracy: 32.02444444444444\n",
            "validation cost: 0.19489284193574818 Validation accuracy: 31.86\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Cost:  0.19339567944441635 Train Accuracy: 32.24444444444444\n",
            "validation cost: 0.19450684598269963 Validation accuracy: 31.8\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Cost:  0.19299992202536026 Train Accuracy: 32.27777777777778\n",
            "validation cost: 0.19414139349448511 Validation accuracy: 32.06\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Cost:  0.19262324399285732 Train Accuracy: 32.406666666666666\n",
            "validation cost: 0.1938010167926718 Validation accuracy: 32.12\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Cost:  0.19225607134676453 Train Accuracy: 32.49333333333333\n",
            "validation cost: 0.19347748621710653 Validation accuracy: 32.22\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Cost:  0.19189996261857264 Train Accuracy: 32.675555555555555\n",
            "validation cost: 0.19317230346299305 Validation accuracy: 32.22\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Cost:  0.19154540058418523 Train Accuracy: 32.72888888888889\n",
            "validation cost: 0.19284898885757662 Validation accuracy: 32.379999999999995\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Cost:  0.19120317555531036 Train Accuracy: 32.91111111111111\n",
            "validation cost: 0.1925270476176241 Validation accuracy: 32.34\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Cost:  0.1908826456295529 Train Accuracy: 32.97333333333333\n",
            "validation cost: 0.19223768329516575 Validation accuracy: 32.48\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Cost:  0.19053499190631276 Train Accuracy: 33.111111111111114\n",
            "validation cost: 0.19192790035543125 Validation accuracy: 32.4\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Cost:  0.19019647446942797 Train Accuracy: 33.153333333333336\n",
            "validation cost: 0.19160693775041326 Validation accuracy: 32.36\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Cost:  0.18988335194239878 Train Accuracy: 33.35111111111111\n",
            "validation cost: 0.1913391560402646 Validation accuracy: 32.440000000000005\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Cost:  0.18956735759841753 Train Accuracy: 33.34888888888889\n",
            "validation cost: 0.1910490724154847 Validation accuracy: 32.5\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Cost:  0.18927894158390962 Train Accuracy: 33.48\n",
            "validation cost: 0.19078539756072926 Validation accuracy: 32.82\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Cost:  0.1889635655372302 Train Accuracy: 33.61777777777778\n",
            "validation cost: 0.19052757111142163 Validation accuracy: 32.879999999999995\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Cost:  0.18867185516549817 Train Accuracy: 33.69777777777777\n",
            "validation cost: 0.19023605936370983 Validation accuracy: 32.7\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Cost:  0.18837707988880892 Train Accuracy: 33.81333333333333\n",
            "validation cost: 0.18996308364105557 Validation accuracy: 33.0\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Cost:  0.1881079710751502 Train Accuracy: 33.873333333333335\n",
            "validation cost: 0.18971519236805034 Validation accuracy: 33.019999999999996\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Cost:  0.18784801312019425 Train Accuracy: 34.093333333333334\n",
            "validation cost: 0.18948860162877076 Validation accuracy: 33.12\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Cost:  0.18755349887906095 Train Accuracy: 34.05555555555556\n",
            "validation cost: 0.18920266837072722 Validation accuracy: 33.08\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Cost:  0.18728872000733698 Train Accuracy: 34.14888888888889\n",
            "validation cost: 0.18895852888920214 Validation accuracy: 33.239999999999995\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Cost:  0.1870383790110312 Train Accuracy: 34.28222222222222\n",
            "validation cost: 0.18870058305648574 Validation accuracy: 33.28\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Cost:  0.1867872002226569 Train Accuracy: 34.28666666666666\n",
            "validation cost: 0.18848909060086746 Validation accuracy: 33.44\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Cost:  0.18655557060810338 Train Accuracy: 34.52222222222222\n",
            "validation cost: 0.18825660102723793 Validation accuracy: 33.78\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Cost:  0.18630281626932754 Train Accuracy: 34.48222222222222\n",
            "validation cost: 0.18801314603748487 Validation accuracy: 33.6\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Cost:  0.18605490075557574 Train Accuracy: 34.54\n",
            "validation cost: 0.1877993348031689 Validation accuracy: 33.6\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Cost:  0.18583689658288824 Train Accuracy: 34.61111111111111\n",
            "validation cost: 0.1875888996013216 Validation accuracy: 33.660000000000004\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Cost:  0.18559262371824667 Train Accuracy: 34.724444444444444\n",
            "validation cost: 0.18737409443932831 Validation accuracy: 33.82\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Cost:  0.18537397390803548 Train Accuracy: 34.78\n",
            "validation cost: 0.18718643177083272 Validation accuracy: 33.82\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Cost:  0.18515405243025546 Train Accuracy: 34.97777777777778\n",
            "validation cost: 0.18695418178610548 Validation accuracy: 34.0\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Cost:  0.18494524521528044 Train Accuracy: 34.96666666666667\n",
            "validation cost: 0.18677341569674485 Validation accuracy: 34.02\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Cost:  0.18472206411570824 Train Accuracy: 35.028888888888886\n",
            "validation cost: 0.18658268586558022 Validation accuracy: 34.08\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Cost:  0.18450084006583245 Train Accuracy: 35.16666666666667\n",
            "validation cost: 0.18638425424336105 Validation accuracy: 34.339999999999996\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Cost:  0.18429245559542534 Train Accuracy: 35.282222222222224\n",
            "validation cost: 0.18620673565160287 Validation accuracy: 34.300000000000004\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "Cost:  0.18408643157804036 Train Accuracy: 35.342222222222226\n",
            "validation cost: 0.18599465853415564 Validation accuracy: 34.58\n",
            "Iteration: 157\n",
            "Iteration: 158\n",
            "Cost:  0.1838839578847347 Train Accuracy: 35.348888888888894\n",
            "validation cost: 0.1858291226824982 Validation accuracy: 34.5\n",
            "Iteration: 159\n",
            "Iteration: 160\n",
            "Cost:  0.18368043882150129 Train Accuracy: 35.49777777777778\n",
            "validation cost: 0.18564915088474823 Validation accuracy: 34.68\n",
            "Iteration: 161\n",
            "Iteration: 162\n",
            "Cost:  0.1834852387620191 Train Accuracy: 35.54\n",
            "validation cost: 0.18546750063856268 Validation accuracy: 34.52\n",
            "Iteration: 163\n",
            "Iteration: 164\n",
            "Cost:  0.18327879639914654 Train Accuracy: 35.65555555555556\n",
            "validation cost: 0.18526561541617034 Validation accuracy: 34.8\n",
            "Iteration: 165\n",
            "Iteration: 166\n",
            "Cost:  0.18310284763195186 Train Accuracy: 35.64888888888889\n",
            "validation cost: 0.18511372983727836 Validation accuracy: 34.599999999999994\n",
            "Iteration: 167\n",
            "Iteration: 168\n",
            "Cost:  0.18290379122725997 Train Accuracy: 35.733333333333334\n",
            "validation cost: 0.1849460005174552 Validation accuracy: 34.96\n",
            "Iteration: 169\n",
            "Iteration: 170\n",
            "Cost:  0.18272877175433969 Train Accuracy: 35.79555555555556\n",
            "validation cost: 0.18477163606675698 Validation accuracy: 34.94\n",
            "Iteration: 171\n",
            "Iteration: 172\n",
            "Cost:  0.18253755382310644 Train Accuracy: 35.90888888888889\n",
            "validation cost: 0.18460955115148187 Validation accuracy: 34.86\n",
            "Iteration: 173\n",
            "Iteration: 174\n",
            "Cost:  0.18236457575378284 Train Accuracy: 35.91555555555556\n",
            "validation cost: 0.1844524587046514 Validation accuracy: 35.14\n",
            "Iteration: 175\n",
            "Iteration: 176\n",
            "Cost:  0.18218722261623566 Train Accuracy: 35.95333333333333\n",
            "validation cost: 0.18432121954068786 Validation accuracy: 35.14\n",
            "Iteration: 177\n",
            "Iteration: 178\n",
            "Cost:  0.18199933086156467 Train Accuracy: 36.12222222222222\n",
            "validation cost: 0.1841453815828581 Validation accuracy: 35.260000000000005\n",
            "Iteration: 179\n",
            "Iteration: 180\n",
            "Cost:  0.18182496293438266 Train Accuracy: 36.144444444444446\n",
            "validation cost: 0.18396399415074652 Validation accuracy: 35.28\n",
            "Iteration: 181\n",
            "Iteration: 182\n",
            "Cost:  0.18165958550067218 Train Accuracy: 36.17333333333333\n",
            "validation cost: 0.18381319321311956 Validation accuracy: 35.24\n",
            "Iteration: 183\n",
            "Iteration: 184\n",
            "Cost:  0.18149163700230206 Train Accuracy: 36.15333333333333\n",
            "validation cost: 0.18368633429224582 Validation accuracy: 35.18\n",
            "Iteration: 185\n",
            "Iteration: 186\n",
            "Cost:  0.18132246506573074 Train Accuracy: 36.32222222222222\n",
            "validation cost: 0.18355072565056774 Validation accuracy: 35.46\n",
            "Iteration: 187\n",
            "Iteration: 188\n",
            "Cost:  0.18117115935127198 Train Accuracy: 36.38444444444445\n",
            "validation cost: 0.18338479919227327 Validation accuracy: 35.46\n",
            "Iteration: 189\n",
            "Iteration: 190\n",
            "Cost:  0.1809890194543876 Train Accuracy: 36.48222222222222\n",
            "validation cost: 0.1832300147288007 Validation accuracy: 35.52\n",
            "Iteration: 191\n",
            "Iteration: 192\n",
            "Cost:  0.18084389784930635 Train Accuracy: 36.46888888888889\n",
            "validation cost: 0.18311163102918337 Validation accuracy: 35.56\n",
            "Iteration: 193\n",
            "Iteration: 194\n",
            "Cost:  0.1806877274298136 Train Accuracy: 36.473333333333336\n",
            "validation cost: 0.18298615253095493 Validation accuracy: 35.72\n",
            "Iteration: 195\n",
            "Iteration: 196\n",
            "Cost:  0.18052689670776215 Train Accuracy: 36.56666666666666\n",
            "validation cost: 0.18284296829451105 Validation accuracy: 35.56\n",
            "Iteration: 197\n",
            "Iteration: 198\n",
            "Cost:  0.18037529606380096 Train Accuracy: 36.8\n",
            "validation cost: 0.18267878816619687 Validation accuracy: 35.8\n",
            "Iteration: 199\n",
            "Iteration: 200\n",
            "Cost:  0.18021042318576677 Train Accuracy: 36.67111111111111\n",
            "validation cost: 0.18253556881143682 Validation accuracy: 35.78\n",
            "Iteration: 201\n",
            "Iteration: 202\n",
            "Cost:  0.18007464939763607 Train Accuracy: 36.78444444444444\n",
            "validation cost: 0.18242189573758497 Validation accuracy: 35.9\n",
            "Iteration: 203\n",
            "Iteration: 204\n",
            "Cost:  0.17992429907890764 Train Accuracy: 36.73111111111111\n",
            "validation cost: 0.18229372956085285 Validation accuracy: 36.120000000000005\n",
            "Iteration: 205\n",
            "Iteration: 206\n",
            "Cost:  0.17976317856856164 Train Accuracy: 36.84444444444445\n",
            "validation cost: 0.1821344881848625 Validation accuracy: 36.04\n",
            "Iteration: 207\n",
            "Iteration: 208\n",
            "Cost:  0.17962243718071863 Train Accuracy: 36.93111111111111\n",
            "validation cost: 0.18200807703239755 Validation accuracy: 36.120000000000005\n",
            "Iteration: 209\n",
            "Iteration: 210\n",
            "Cost:  0.17947818094396023 Train Accuracy: 36.971111111111114\n",
            "validation cost: 0.181876500482568 Validation accuracy: 36.1\n",
            "Iteration: 211\n",
            "Iteration: 212\n",
            "Cost:  0.17933355890388628 Train Accuracy: 37.05555555555556\n",
            "validation cost: 0.18176329044172532 Validation accuracy: 36.32\n",
            "Iteration: 213\n",
            "Iteration: 214\n",
            "Cost:  0.17919602931560838 Train Accuracy: 37.12\n",
            "validation cost: 0.1815940417010337 Validation accuracy: 36.22\n",
            "Iteration: 215\n",
            "Iteration: 216\n",
            "Cost:  0.17905467538230696 Train Accuracy: 37.086666666666666\n",
            "validation cost: 0.18148968350441916 Validation accuracy: 36.34\n",
            "Iteration: 217\n",
            "Iteration: 218\n",
            "Cost:  0.1789241027929819 Train Accuracy: 37.20444444444445\n",
            "validation cost: 0.1813882635657314 Validation accuracy: 36.42\n",
            "Iteration: 219\n",
            "Iteration: 220\n",
            "Cost:  0.17878266447870308 Train Accuracy: 37.15777777777778\n",
            "validation cost: 0.18126509924742307 Validation accuracy: 36.54\n",
            "Iteration: 221\n",
            "Iteration: 222\n",
            "Cost:  0.17864223100808072 Train Accuracy: 37.31333333333333\n",
            "validation cost: 0.18112410969107284 Validation accuracy: 36.6\n",
            "Iteration: 223\n",
            "Iteration: 224\n",
            "Cost:  0.17850376234541188 Train Accuracy: 37.29333333333334\n",
            "validation cost: 0.18100793058876957 Validation accuracy: 36.46\n",
            "Iteration: 225\n",
            "Iteration: 226\n",
            "Cost:  0.17837227223969054 Train Accuracy: 37.29555555555555\n",
            "validation cost: 0.18089366644212873 Validation accuracy: 36.7\n",
            "Iteration: 227\n",
            "Iteration: 228\n",
            "Cost:  0.17824810008479647 Train Accuracy: 37.36666666666667\n",
            "validation cost: 0.18079534229849417 Validation accuracy: 36.84\n",
            "Iteration: 229\n",
            "Iteration: 230\n",
            "Cost:  0.17812094718844795 Train Accuracy: 37.46\n",
            "validation cost: 0.1806653546481201 Validation accuracy: 36.78\n",
            "Iteration: 231\n",
            "Iteration: 232\n",
            "Cost:  0.17799019083240894 Train Accuracy: 37.44\n",
            "validation cost: 0.18052139775320727 Validation accuracy: 36.8\n",
            "Iteration: 233\n",
            "Iteration: 234\n",
            "Cost:  0.17785278190951595 Train Accuracy: 37.51777777777778\n",
            "validation cost: 0.1804175478221957 Validation accuracy: 37.019999999999996\n",
            "Iteration: 235\n",
            "Iteration: 236\n",
            "Cost:  0.1777323927524855 Train Accuracy: 37.56666666666666\n",
            "validation cost: 0.18030902687350633 Validation accuracy: 36.9\n",
            "Iteration: 237\n",
            "Iteration: 238\n",
            "Cost:  0.17759208683082534 Train Accuracy: 37.684444444444445\n",
            "validation cost: 0.18019728301130628 Validation accuracy: 37.059999999999995\n",
            "Iteration: 239\n",
            "Iteration: 240\n",
            "Cost:  0.1774698064597891 Train Accuracy: 37.62888888888889\n",
            "validation cost: 0.18008082887916618 Validation accuracy: 36.96\n",
            "Iteration: 241\n",
            "Iteration: 242\n",
            "Cost:  0.1773478725587397 Train Accuracy: 37.65555555555555\n",
            "validation cost: 0.1799742411832634 Validation accuracy: 37.2\n",
            "Iteration: 243\n",
            "Iteration: 244\n",
            "Cost:  0.17722219218840177 Train Accuracy: 37.75555555555555\n",
            "validation cost: 0.17987369097579786 Validation accuracy: 37.3\n",
            "Iteration: 245\n",
            "Iteration: 246\n",
            "Cost:  0.17711174023257856 Train Accuracy: 37.74666666666667\n",
            "validation cost: 0.17976913041346831 Validation accuracy: 37.22\n",
            "Iteration: 247\n",
            "Iteration: 248\n",
            "Cost:  0.17697802807574542 Train Accuracy: 37.82666666666666\n",
            "validation cost: 0.17964592495340764 Validation accuracy: 37.38\n",
            "Iteration: 249\n",
            "Iteration: 250\n",
            "Cost:  0.17686348626121665 Train Accuracy: 37.833333333333336\n",
            "validation cost: 0.1795547697564352 Validation accuracy: 37.24\n",
            "Iteration: 251\n",
            "Iteration: 252\n",
            "Cost:  0.1767574338289174 Train Accuracy: 37.9\n",
            "validation cost: 0.17943316247657992 Validation accuracy: 37.26\n",
            "Iteration: 253\n",
            "Iteration: 254\n",
            "Cost:  0.17663274872442392 Train Accuracy: 37.91111111111111\n",
            "validation cost: 0.17936260058996487 Validation accuracy: 37.18\n",
            "Iteration: 255\n",
            "Iteration: 256\n",
            "Cost:  0.17650802280075734 Train Accuracy: 38.026666666666664\n",
            "validation cost: 0.17922971817091568 Validation accuracy: 37.18\n",
            "Iteration: 257\n",
            "Iteration: 258\n",
            "Cost:  0.17639202129072926 Train Accuracy: 38.019999999999996\n",
            "validation cost: 0.1791344880550826 Validation accuracy: 37.3\n",
            "Iteration: 259\n",
            "Iteration: 260\n",
            "Cost:  0.17628127880469513 Train Accuracy: 38.11333333333333\n",
            "validation cost: 0.17903604490815905 Validation accuracy: 37.36\n",
            "Iteration: 261\n",
            "Iteration: 262\n",
            "Cost:  0.1761774355727125 Train Accuracy: 38.166666666666664\n",
            "validation cost: 0.1789381405140526 Validation accuracy: 37.3\n",
            "Iteration: 263\n",
            "Iteration: 264\n",
            "Cost:  0.17605642880974454 Train Accuracy: 38.13333333333333\n",
            "validation cost: 0.1788654902963968 Validation accuracy: 37.28\n",
            "Iteration: 265\n",
            "Iteration: 266\n",
            "Cost:  0.1759398085523724 Train Accuracy: 38.24444444444444\n",
            "validation cost: 0.17874394476955785 Validation accuracy: 37.38\n",
            "Iteration: 267\n",
            "Iteration: 268\n",
            "Cost:  0.17583282374337186 Train Accuracy: 38.22888888888889\n",
            "validation cost: 0.17864014367470418 Validation accuracy: 37.3\n",
            "Iteration: 269\n",
            "Iteration: 270\n",
            "Cost:  0.17573552599588663 Train Accuracy: 38.31777777777778\n",
            "validation cost: 0.178569961633244 Validation accuracy: 37.46\n",
            "Iteration: 271\n",
            "Iteration: 272\n",
            "Cost:  0.17560940272223366 Train Accuracy: 38.37555555555556\n",
            "validation cost: 0.1784387826553168 Validation accuracy: 37.5\n",
            "Iteration: 273\n",
            "Iteration: 274\n",
            "Cost:  0.1755363379980547 Train Accuracy: 38.36222222222222\n",
            "validation cost: 0.1783665818131983 Validation accuracy: 37.64\n",
            "Iteration: 275\n",
            "Iteration: 276\n",
            "Cost:  0.17540694318460573 Train Accuracy: 38.355555555555554\n",
            "validation cost: 0.1782640375950077 Validation accuracy: 37.419999999999995\n",
            "Iteration: 277\n",
            "Iteration: 278\n",
            "Cost:  0.1752896679640975 Train Accuracy: 38.42444444444445\n",
            "validation cost: 0.17816332179781336 Validation accuracy: 37.5\n",
            "Iteration: 279\n",
            "Iteration: 280\n",
            "Cost:  0.17518553048670513 Train Accuracy: 38.41777777777778\n",
            "validation cost: 0.1780908255601408 Validation accuracy: 37.480000000000004\n",
            "Iteration: 281\n",
            "Iteration: 282\n",
            "Cost:  0.17508011056541734 Train Accuracy: 38.60444444444445\n",
            "validation cost: 0.1779820779579445 Validation accuracy: 37.480000000000004\n",
            "Iteration: 283\n",
            "Iteration: 284\n",
            "Cost:  0.17497188559398766 Train Accuracy: 38.50888888888889\n",
            "validation cost: 0.1778901550997399 Validation accuracy: 37.580000000000005\n",
            "Iteration: 285\n",
            "Iteration: 286\n",
            "Cost:  0.1748642657617249 Train Accuracy: 38.6\n",
            "validation cost: 0.17779355121147503 Validation accuracy: 37.82\n",
            "Iteration: 287\n",
            "Iteration: 288\n",
            "Cost:  0.17476857422906145 Train Accuracy: 38.58222222222222\n",
            "validation cost: 0.17772441227297553 Validation accuracy: 37.7\n",
            "Iteration: 289\n",
            "Iteration: 290\n",
            "Cost:  0.1746579179025108 Train Accuracy: 38.62\n",
            "validation cost: 0.17762138503295297 Validation accuracy: 37.74\n",
            "Iteration: 291\n",
            "Iteration: 292\n",
            "Cost:  0.17455612249195968 Train Accuracy: 38.693333333333335\n",
            "validation cost: 0.17751880995444136 Validation accuracy: 37.86\n",
            "Iteration: 293\n",
            "Iteration: 294\n",
            "Cost:  0.17445719208201566 Train Accuracy: 38.708888888888886\n",
            "validation cost: 0.1774210495985481 Validation accuracy: 37.9\n",
            "Iteration: 295\n",
            "Iteration: 296\n",
            "Cost:  0.17436310086496598 Train Accuracy: 38.67777777777778\n",
            "validation cost: 0.17735026260672324 Validation accuracy: 37.82\n",
            "Iteration: 297\n",
            "Iteration: 298\n",
            "Cost:  0.17427910495780544 Train Accuracy: 38.75333333333334\n",
            "validation cost: 0.17729049103644975 Validation accuracy: 37.92\n",
            "Iteration: 299\n",
            "Iteration: 300\n",
            "Cost:  0.17416515828568618 Train Accuracy: 38.81111111111111\n",
            "validation cost: 0.17716734851934685 Validation accuracy: 37.74\n",
            "Iteration: 301\n",
            "Iteration: 302\n",
            "Cost:  0.1740630227074631 Train Accuracy: 38.79555555555555\n",
            "validation cost: 0.17708530840813608 Validation accuracy: 37.76\n",
            "Iteration: 303\n",
            "Iteration: 304\n",
            "Cost:  0.1739646321862356 Train Accuracy: 38.864444444444445\n",
            "validation cost: 0.17699938402910556 Validation accuracy: 37.82\n",
            "Iteration: 305\n",
            "Iteration: 306\n",
            "Cost:  0.17387598841302548 Train Accuracy: 38.88888888888889\n",
            "validation cost: 0.17693141528353956 Validation accuracy: 38.1\n",
            "Iteration: 307\n",
            "Iteration: 308\n",
            "Cost:  0.17378227123226372 Train Accuracy: 39.03333333333333\n",
            "validation cost: 0.1768378044585093 Validation accuracy: 38.06\n",
            "Iteration: 309\n",
            "Iteration: 310\n",
            "Cost:  0.1736844390067019 Train Accuracy: 38.98888888888889\n",
            "validation cost: 0.17675462916975568 Validation accuracy: 37.980000000000004\n",
            "Iteration: 311\n",
            "Iteration: 312\n",
            "Cost:  0.17359120626369462 Train Accuracy: 39.026666666666664\n",
            "validation cost: 0.17666838602364532 Validation accuracy: 38.04\n",
            "Iteration: 313\n",
            "Iteration: 314\n",
            "Cost:  0.17348520968460762 Train Accuracy: 39.08444444444444\n",
            "validation cost: 0.1765655608951875 Validation accuracy: 38.06\n",
            "Iteration: 315\n",
            "Iteration: 316\n",
            "Cost:  0.1734046078708082 Train Accuracy: 39.12\n",
            "validation cost: 0.17649488649863687 Validation accuracy: 37.96\n",
            "Iteration: 317\n",
            "Iteration: 318\n",
            "Cost:  0.17330529723217952 Train Accuracy: 39.11777777777778\n",
            "validation cost: 0.17641847248807016 Validation accuracy: 38.2\n",
            "Iteration: 319\n",
            "Iteration: 320\n",
            "Cost:  0.17321165578873268 Train Accuracy: 39.166666666666664\n",
            "validation cost: 0.17634140966821243 Validation accuracy: 38.24\n",
            "Iteration: 321\n",
            "Iteration: 322\n",
            "Cost:  0.17314338308342173 Train Accuracy: 39.266666666666666\n",
            "validation cost: 0.1762668788637141 Validation accuracy: 38.1\n",
            "Iteration: 323\n",
            "Iteration: 324\n",
            "Cost:  0.1730277603346303 Train Accuracy: 39.300000000000004\n",
            "validation cost: 0.17617625334134712 Validation accuracy: 38.14\n",
            "Iteration: 325\n",
            "Iteration: 326\n",
            "Cost:  0.1729385309088003 Train Accuracy: 39.31777777777778\n",
            "validation cost: 0.1761084012831529 Validation accuracy: 38.14\n",
            "Iteration: 327\n",
            "Iteration: 328\n",
            "Cost:  0.17285382178310965 Train Accuracy: 39.41111111111111\n",
            "validation cost: 0.17601903902766927 Validation accuracy: 38.2\n",
            "Iteration: 329\n",
            "Iteration: 330\n",
            "Cost:  0.172755657308609 Train Accuracy: 39.404444444444444\n",
            "validation cost: 0.17594678266725575 Validation accuracy: 38.26\n",
            "Iteration: 331\n",
            "Iteration: 332\n",
            "Cost:  0.17267604228195635 Train Accuracy: 39.42666666666666\n",
            "validation cost: 0.17587294784218266 Validation accuracy: 38.4\n",
            "Iteration: 333\n",
            "Iteration: 334\n",
            "Cost:  0.17259348003604325 Train Accuracy: 39.41555555555556\n",
            "validation cost: 0.17581037393899826 Validation accuracy: 38.14\n",
            "Iteration: 335\n",
            "Iteration: 336\n",
            "Cost:  0.17249568912269211 Train Accuracy: 39.48444444444444\n",
            "validation cost: 0.17571159646557352 Validation accuracy: 38.26\n",
            "Iteration: 337\n",
            "Iteration: 338\n",
            "Cost:  0.17241952321813148 Train Accuracy: 39.486666666666665\n",
            "validation cost: 0.17564611935607746 Validation accuracy: 38.1\n",
            "Iteration: 339\n",
            "Iteration: 340\n",
            "Cost:  0.17232371989830716 Train Accuracy: 39.63777777777778\n",
            "validation cost: 0.175568770230068 Validation accuracy: 38.48\n",
            "Iteration: 341\n",
            "Iteration: 342\n",
            "Cost:  0.17223623166430854 Train Accuracy: 39.59777777777778\n",
            "validation cost: 0.1755074482331755 Validation accuracy: 38.42\n",
            "Iteration: 343\n",
            "Iteration: 344\n",
            "Cost:  0.17215806077800663 Train Accuracy: 39.628888888888895\n",
            "validation cost: 0.17541166136978106 Validation accuracy: 38.32\n",
            "Iteration: 345\n",
            "Iteration: 346\n",
            "Cost:  0.17209249935791265 Train Accuracy: 39.626666666666665\n",
            "validation cost: 0.1753753656281628 Validation accuracy: 38.18\n",
            "Iteration: 347\n",
            "Iteration: 348\n",
            "Cost:  0.17198846160696102 Train Accuracy: 39.757777777777775\n",
            "validation cost: 0.17525371525062247 Validation accuracy: 38.56\n",
            "Iteration: 349\n",
            "Iteration: 350\n",
            "Cost:  0.17190407361419616 Train Accuracy: 39.739999999999995\n",
            "validation cost: 0.1752120263182881 Validation accuracy: 38.56\n",
            "Iteration: 351\n",
            "Iteration: 352\n",
            "Cost:  0.1718120271346146 Train Accuracy: 39.79333333333333\n",
            "validation cost: 0.17512629562894597 Validation accuracy: 38.440000000000005\n",
            "Iteration: 353\n",
            "Iteration: 354\n",
            "Cost:  0.1717358963245286 Train Accuracy: 39.739999999999995\n",
            "validation cost: 0.1750651254081468 Validation accuracy: 38.66\n",
            "Iteration: 355\n",
            "Iteration: 356\n",
            "Cost:  0.17166017250280116 Train Accuracy: 39.784444444444446\n",
            "validation cost: 0.17499590052995792 Validation accuracy: 38.519999999999996\n",
            "Iteration: 357\n",
            "Iteration: 358\n",
            "Cost:  0.17157547009025598 Train Accuracy: 39.87111111111111\n",
            "validation cost: 0.17492168285717788 Validation accuracy: 38.5\n",
            "Iteration: 359\n",
            "Iteration: 360\n",
            "Cost:  0.1714846807126491 Train Accuracy: 39.84666666666667\n",
            "validation cost: 0.17484451169624826 Validation accuracy: 38.7\n",
            "Iteration: 361\n",
            "Iteration: 362\n",
            "Cost:  0.1714128818188824 Train Accuracy: 39.906666666666666\n",
            "validation cost: 0.17478200371999916 Validation accuracy: 38.68\n",
            "Iteration: 363\n",
            "Iteration: 364\n",
            "Cost:  0.17133696550978567 Train Accuracy: 39.93555555555556\n",
            "validation cost: 0.17471732264177356 Validation accuracy: 38.68\n",
            "Iteration: 365\n",
            "Iteration: 366\n",
            "Cost:  0.1712436609076033 Train Accuracy: 39.90222222222222\n",
            "validation cost: 0.17464222592591636 Validation accuracy: 38.800000000000004\n",
            "Iteration: 367\n",
            "Iteration: 368\n",
            "Cost:  0.17116460195049354 Train Accuracy: 39.99777777777778\n",
            "validation cost: 0.17455368353753659 Validation accuracy: 38.78\n",
            "Iteration: 369\n",
            "Iteration: 370\n",
            "Cost:  0.1710943153563931 Train Accuracy: 39.95777777777778\n",
            "validation cost: 0.17452274523118744 Validation accuracy: 38.76\n",
            "Iteration: 371\n",
            "Iteration: 372\n",
            "Cost:  0.17100653577663738 Train Accuracy: 40.07333333333333\n",
            "validation cost: 0.17441446695962928 Validation accuracy: 38.800000000000004\n",
            "Iteration: 373\n",
            "Iteration: 374\n",
            "Cost:  0.1709427451155586 Train Accuracy: 40.03333333333333\n",
            "validation cost: 0.17438812717042554 Validation accuracy: 38.86\n",
            "Iteration: 375\n",
            "Iteration: 376\n",
            "Cost:  0.1708580012212606 Train Accuracy: 40.03777777777778\n",
            "validation cost: 0.17431014473109532 Validation accuracy: 38.800000000000004\n",
            "Iteration: 377\n",
            "Iteration: 378\n",
            "Cost:  0.17077746020531023 Train Accuracy: 40.135555555555555\n",
            "validation cost: 0.17422143077342087 Validation accuracy: 38.84\n",
            "Iteration: 379\n",
            "Iteration: 380\n",
            "Cost:  0.1706999734958108 Train Accuracy: 40.08444444444444\n",
            "validation cost: 0.17416918819429036 Validation accuracy: 38.84\n",
            "Iteration: 381\n",
            "Iteration: 382\n",
            "Cost:  0.17063020479277277 Train Accuracy: 40.24888888888889\n",
            "validation cost: 0.1741031734201372 Validation accuracy: 38.9\n",
            "Iteration: 383\n",
            "Iteration: 384\n",
            "Cost:  0.17054291921173162 Train Accuracy: 40.215555555555554\n",
            "validation cost: 0.17402839350143118 Validation accuracy: 38.96\n",
            "Iteration: 385\n",
            "Iteration: 386\n",
            "Cost:  0.1704682822011167 Train Accuracy: 40.23111111111111\n",
            "validation cost: 0.17396937352927017 Validation accuracy: 38.96\n",
            "Iteration: 387\n",
            "Iteration: 388\n",
            "Cost:  0.1703923718735927 Train Accuracy: 40.242222222222225\n",
            "validation cost: 0.1739110814521963 Validation accuracy: 39.019999999999996\n",
            "Iteration: 389\n",
            "Iteration: 390\n",
            "Cost:  0.17032420233401022 Train Accuracy: 40.30888888888889\n",
            "validation cost: 0.17384288504283527 Validation accuracy: 39.019999999999996\n",
            "Iteration: 391\n",
            "Iteration: 392\n",
            "Cost:  0.17024105887203692 Train Accuracy: 40.364444444444445\n",
            "validation cost: 0.17376561092688425 Validation accuracy: 38.98\n",
            "Iteration: 393\n",
            "Iteration: 394\n",
            "Cost:  0.1701659404719478 Train Accuracy: 40.40222222222222\n",
            "validation cost: 0.17372085061678727 Validation accuracy: 39.18\n",
            "Iteration: 395\n",
            "Iteration: 396\n",
            "Cost:  0.1701253747755419 Train Accuracy: 40.38888888888889\n",
            "validation cost: 0.17368417706261452 Validation accuracy: 39.2\n",
            "Iteration: 397\n",
            "Iteration: 398\n",
            "Cost:  0.1700143514485543 Train Accuracy: 40.431111111111115\n",
            "validation cost: 0.17358688487856608 Validation accuracy: 39.22\n",
            "Iteration: 399\n",
            "Iteration: 400\n",
            "Cost:  0.16994479044332197 Train Accuracy: 40.39111111111111\n",
            "validation cost: 0.17354440638638657 Validation accuracy: 39.32\n",
            "Iteration: 401\n",
            "Iteration: 402\n",
            "Cost:  0.1698878411091148 Train Accuracy: 40.47555555555555\n",
            "validation cost: 0.17348266585261576 Validation accuracy: 39.24\n",
            "Iteration: 403\n",
            "Iteration: 404\n",
            "Cost:  0.16979865287935197 Train Accuracy: 40.53333333333333\n",
            "validation cost: 0.17340757958862277 Validation accuracy: 39.36\n",
            "Iteration: 405\n",
            "Iteration: 406\n",
            "Cost:  0.1697351693903551 Train Accuracy: 40.57777777777778\n",
            "validation cost: 0.17336642101133967 Validation accuracy: 39.300000000000004\n",
            "Iteration: 407\n",
            "Iteration: 408\n",
            "Cost:  0.1696639404133122 Train Accuracy: 40.55555555555556\n",
            "validation cost: 0.17328717209442315 Validation accuracy: 39.18\n",
            "Iteration: 409\n",
            "Iteration: 410\n",
            "Cost:  0.1695866429247762 Train Accuracy: 40.47777777777778\n",
            "validation cost: 0.17324625814009872 Validation accuracy: 39.300000000000004\n",
            "Iteration: 411\n",
            "Iteration: 412\n",
            "Cost:  0.16951701499829822 Train Accuracy: 40.635555555555555\n",
            "validation cost: 0.17318721084920347 Validation accuracy: 39.34\n",
            "Iteration: 413\n",
            "Iteration: 414\n",
            "Cost:  0.16945148341414631 Train Accuracy: 40.56666666666667\n",
            "validation cost: 0.17312796217929788 Validation accuracy: 39.379999999999995\n",
            "Iteration: 415\n",
            "Iteration: 416\n",
            "Cost:  0.1693767212305906 Train Accuracy: 40.71111111111111\n",
            "validation cost: 0.17304530491085515 Validation accuracy: 39.28\n",
            "Iteration: 417\n",
            "Iteration: 418\n",
            "Cost:  0.16931179387681192 Train Accuracy: 40.70444444444444\n",
            "validation cost: 0.1729987612253103 Validation accuracy: 39.46\n",
            "Iteration: 419\n",
            "Iteration: 420\n",
            "Cost:  0.1692294242689831 Train Accuracy: 40.70666666666667\n",
            "validation cost: 0.17293747124137132 Validation accuracy: 39.4\n",
            "Iteration: 421\n",
            "Iteration: 422\n",
            "Cost:  0.16915971112450073 Train Accuracy: 40.68222222222222\n",
            "validation cost: 0.17288617700665818 Validation accuracy: 39.300000000000004\n",
            "Iteration: 423\n",
            "Iteration: 424\n",
            "Cost:  0.1690939350303945 Train Accuracy: 40.733333333333334\n",
            "validation cost: 0.17283626364561536 Validation accuracy: 39.34\n",
            "Iteration: 425\n",
            "Iteration: 426\n",
            "Cost:  0.1690297736154483 Train Accuracy: 40.80222222222222\n",
            "validation cost: 0.17277669598994985 Validation accuracy: 39.32\n",
            "Iteration: 427\n",
            "Iteration: 428\n",
            "Cost:  0.16895657809948064 Train Accuracy: 40.80444444444444\n",
            "validation cost: 0.17271380146973545 Validation accuracy: 39.46\n",
            "Iteration: 429\n",
            "Iteration: 430\n",
            "Cost:  0.16890017471933136 Train Accuracy: 40.83111111111111\n",
            "validation cost: 0.1726738079915135 Validation accuracy: 39.300000000000004\n",
            "Iteration: 431\n",
            "Iteration: 432\n",
            "Cost:  0.16881635215865426 Train Accuracy: 40.833333333333336\n",
            "validation cost: 0.17260550121587268 Validation accuracy: 39.58\n",
            "Iteration: 433\n",
            "Iteration: 434\n",
            "Cost:  0.16875128512082868 Train Accuracy: 40.89333333333333\n",
            "validation cost: 0.1725600452302652 Validation accuracy: 39.34\n",
            "Iteration: 435\n",
            "Iteration: 436\n",
            "Cost:  0.16868725471614449 Train Accuracy: 40.89111111111111\n",
            "validation cost: 0.17251498590202533 Validation accuracy: 39.48\n",
            "Iteration: 437\n",
            "Iteration: 438\n",
            "Cost:  0.16862876720933995 Train Accuracy: 40.98222222222222\n",
            "validation cost: 0.17246341817460267 Validation accuracy: 39.6\n",
            "Iteration: 439\n",
            "Iteration: 440\n",
            "Cost:  0.16855826401312282 Train Accuracy: 40.95111111111111\n",
            "validation cost: 0.17239412656775543 Validation accuracy: 39.379999999999995\n",
            "Iteration: 441\n",
            "Iteration: 442\n",
            "Cost:  0.16847858079088548 Train Accuracy: 40.98\n",
            "validation cost: 0.17233092707541425 Validation accuracy: 39.44\n",
            "Iteration: 443\n",
            "Iteration: 444\n",
            "Cost:  0.16841832676501844 Train Accuracy: 41.035555555555554\n",
            "validation cost: 0.17228234979280213 Validation accuracy: 39.660000000000004\n",
            "Iteration: 445\n",
            "Iteration: 446\n",
            "Cost:  0.16837753460406193 Train Accuracy: 41.02\n",
            "validation cost: 0.17224701416893518 Validation accuracy: 39.64\n",
            "Iteration: 447\n",
            "Iteration: 448\n",
            "Cost:  0.16830331256128783 Train Accuracy: 41.026666666666664\n",
            "validation cost: 0.172185325137331 Validation accuracy: 39.58\n",
            "Iteration: 449\n",
            "Iteration: 450\n",
            "Cost:  0.16822615119698306 Train Accuracy: 41.12888888888889\n",
            "validation cost: 0.1721088559576979 Validation accuracy: 39.7\n",
            "Iteration: 451\n",
            "Iteration: 452\n",
            "Cost:  0.16816055213742562 Train Accuracy: 41.11333333333334\n",
            "validation cost: 0.17207144971964178 Validation accuracy: 39.64\n",
            "Iteration: 453\n",
            "Iteration: 454\n",
            "Cost:  0.1680983773332109 Train Accuracy: 41.14222222222222\n",
            "validation cost: 0.17202919806312594 Validation accuracy: 39.519999999999996\n",
            "Iteration: 455\n",
            "Iteration: 456\n",
            "Cost:  0.1680475541299855 Train Accuracy: 41.14888888888889\n",
            "validation cost: 0.1719876971861541 Validation accuracy: 39.78\n",
            "Iteration: 457\n",
            "Iteration: 458\n",
            "Cost:  0.16796722534410666 Train Accuracy: 41.22\n",
            "validation cost: 0.17192163346531622 Validation accuracy: 39.76\n",
            "Iteration: 459\n",
            "Iteration: 460\n",
            "Cost:  0.1679100507091664 Train Accuracy: 41.20666666666667\n",
            "validation cost: 0.17185256502365315 Validation accuracy: 39.800000000000004\n",
            "Iteration: 461\n",
            "Iteration: 462\n",
            "Cost:  0.16785061570461005 Train Accuracy: 41.22222222222222\n",
            "validation cost: 0.17181648671950508 Validation accuracy: 39.739999999999995\n",
            "Iteration: 463\n",
            "Iteration: 464\n",
            "Cost:  0.16778003247143694 Train Accuracy: 41.32\n",
            "validation cost: 0.17175084748878536 Validation accuracy: 39.76\n",
            "Iteration: 465\n",
            "Iteration: 466\n",
            "Cost:  0.16772607242109908 Train Accuracy: 41.31111111111111\n",
            "validation cost: 0.17171554800693303 Validation accuracy: 39.68\n",
            "Iteration: 467\n",
            "Iteration: 468\n",
            "Cost:  0.1676788930405779 Train Accuracy: 41.342222222222226\n",
            "validation cost: 0.17165472120821115 Validation accuracy: 39.7\n",
            "Iteration: 469\n",
            "Iteration: 470\n",
            "Cost:  0.16761236807609875 Train Accuracy: 41.346666666666664\n",
            "validation cost: 0.17161179416970715 Validation accuracy: 39.739999999999995\n",
            "Iteration: 471\n",
            "Iteration: 472\n",
            "Cost:  0.16753215267429775 Train Accuracy: 41.406666666666666\n",
            "validation cost: 0.17155818318108618 Validation accuracy: 39.64\n",
            "Iteration: 473\n",
            "Iteration: 474\n",
            "Cost:  0.16747981194893677 Train Accuracy: 41.43333333333333\n",
            "validation cost: 0.17151792165443772 Validation accuracy: 39.78\n",
            "Iteration: 475\n",
            "Iteration: 476\n",
            "Cost:  0.16740844538076852 Train Accuracy: 41.38222222222222\n",
            "validation cost: 0.1714424432769885 Validation accuracy: 39.839999999999996\n",
            "Iteration: 477\n",
            "Iteration: 478\n",
            "Cost:  0.1673552910491313 Train Accuracy: 41.44222222222223\n",
            "validation cost: 0.17141416988626446 Validation accuracy: 40.02\n",
            "Iteration: 479\n",
            "Iteration: 480\n",
            "Cost:  0.1672881959231444 Train Accuracy: 41.47555555555555\n",
            "validation cost: 0.1713579709086253 Validation accuracy: 39.879999999999995\n",
            "Iteration: 481\n",
            "Iteration: 482\n",
            "Cost:  0.16722222144949941 Train Accuracy: 41.51777777777777\n",
            "validation cost: 0.17129919921264877 Validation accuracy: 39.98\n",
            "Iteration: 483\n",
            "Iteration: 484\n",
            "Cost:  0.1671649003744004 Train Accuracy: 41.52222222222222\n",
            "validation cost: 0.1712457640527298 Validation accuracy: 39.879999999999995\n",
            "Iteration: 485\n",
            "Iteration: 486\n",
            "Cost:  0.16710714815449848 Train Accuracy: 41.54888888888889\n",
            "validation cost: 0.17120144296005976 Validation accuracy: 39.82\n",
            "Iteration: 487\n",
            "Iteration: 488\n",
            "Cost:  0.16705310043236535 Train Accuracy: 41.568888888888885\n",
            "validation cost: 0.17117989058272273 Validation accuracy: 39.98\n",
            "Iteration: 489\n",
            "Iteration: 490\n",
            "Cost:  0.16698503847466656 Train Accuracy: 41.69555555555556\n",
            "validation cost: 0.17111673185108642 Validation accuracy: 39.92\n",
            "Iteration: 491\n",
            "Iteration: 492\n",
            "Cost:  0.16693195711781236 Train Accuracy: 41.617777777777775\n",
            "validation cost: 0.17107793070832322 Validation accuracy: 40.0\n",
            "Iteration: 493\n",
            "Iteration: 494\n",
            "Cost:  0.16687006977436145 Train Accuracy: 41.626666666666665\n",
            "validation cost: 0.17102691183066593 Validation accuracy: 39.98\n",
            "Iteration: 495\n",
            "Iteration: 496\n",
            "Cost:  0.16681269221569697 Train Accuracy: 41.699999999999996\n",
            "validation cost: 0.17096532182056198 Validation accuracy: 39.900000000000006\n",
            "Iteration: 497\n",
            "Iteration: 498\n",
            "Cost:  0.1667572858661523 Train Accuracy: 41.68\n",
            "validation cost: 0.17094792578923407 Validation accuracy: 39.86\n",
            "Iteration: 499\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "mlp_l2.fit_btch(lr=0.01, nitr= 500, alpha=0.1, beta=0, tol=5, epsilon=1e-5)\n",
        "t2 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRTeSbG2pNF3",
        "outputId": "09aff408-7d8a-483f-b74d-38509c8a827a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40.47, 0.1694321672497076)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_l2.evaluate_acc(x_test_vector, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdJwfsnbcH8t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyxS0J3UcJgP"
      },
      "outputs": [],
      "source": [
        "mlp_l2_perf = {'test_perf': mlp_l2.evaluate_acc(x_test_vector, test_y), 'train_time': t2-t1,\n",
        "            'train_cost': mlp_l2.costs, 'val_cost': mlp_l2.val_costs}\n",
        "with open('mlp_l2.pickle', 'wb') as h:\n",
        "    pickle.dump(mlp_l2_perf, h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHSFIJL6cJgR"
      },
      "outputs": [],
      "source": [
        "#del file\n",
        "file = drive.CreateFile()\n",
        "file.SetContentFile('mlp_l2.pickle')\n",
        "file.Upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "r0i1oNHsqu27",
        "outputId": "a49abfcc-26a3-4ee2-c125-904b0c752446"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5b498594f0>]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(mlp_l2.val_costs)\n",
        "plt.plot(mlp_l2.costs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-egoEyypOcP"
      },
      "outputs": [],
      "source": [
        "# Explore using grid search\n",
        "# Here, we manually implement the grid search as our model also stores the validation loss\n",
        "#Note that as the model training using numpy only is crawlingly slow, we limit our search space to\n",
        "# separate small sets of l1 and l2 regularization\n",
        "l1_list = [0.01, 0.1, 0.4, 0.8, 1]\n",
        "lr = 0.02\n",
        "nitr = 300 #Epochs for training model\n",
        "tol = 5 #Tolerance epochs\n",
        "epsilon = 1e-5 #Tolerance threshold for early stopping\n",
        "\n",
        "slcted_l1 = []\n",
        "finl1_val_cost = []\n",
        "for ii in range(20):\n",
        "    tmp_l1 = l1_list[np.random.randint]\n",
        "    slcted_l1.append(tmp_l1)\n",
        "\n",
        "    mlp_grid = MLP(activation_func = tanh, activation_deriv= tanh_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 256, 256, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)\n",
        "    mlp_grid.fit_btch(lr=lr, nitr= nitr, alpha=0, beta=tmp_l1, tol=tol, epsilon=epsilon)\n",
        "    finl1_val_cost.append(mlp_grid.val_costs[-1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyNlri83dt-s"
      },
      "outputs": [],
      "source": [
        "mean_csts = []\n",
        "for ii in enumerate(l1_list):\n",
        "    tmp = np.mean(finl1_val_cost[slcted_l1==ii])\n",
        "    mean_csts.append(tmp)\n",
        "slctd_l1 = np.argmin(mean_csts)\n",
        "print(f'selected L1:{l1_list[slctd_l1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY-8VGswtayL"
      },
      "outputs": [],
      "source": [
        "#Perform grid search on l2 space\n",
        "l2_list = [0.01, 0.1, 0.4, 0.8, 1]\n",
        "lr = 0.01\n",
        "nitr = 300 #Epochs for training model\n",
        "tol = 5 #Tolerance epochs\n",
        "epsilon = 1e-4 #Tolerance threshold for early stopping\n",
        "\n",
        "slcted_l2 = []\n",
        "finl2_val_cost = []\n",
        "for ii in range(50):\n",
        "    tmp_l2 = l2_list[np.random.randint]\n",
        "    slcted_l2.append(tmp_l2)\n",
        "\n",
        "    mlp_grid = MLP(activation_func = tanh, activation_deriv= tanh_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 256, 256, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)\n",
        "    mlp_grid.fit_btch(lr=lr, nitr= nitr, alpha=tmp_l2, beta=0, tol=tol, epsilon=epsilon)\n",
        "    finl2_val_cost.append(mlp_grid.val_costs[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqwTbCPkd0wV"
      },
      "outputs": [],
      "source": [
        "mean_csts = []\n",
        "for ii in enumerate(l2_list):\n",
        "    tmp = np.mean(finl2_val_cost[slcted_l2==ii])\n",
        "    mean_csts.append(tmp)\n",
        "slctd_l2 = np.argmin(mean_csts)\n",
        "print(f'selected L2:{l1_list[slctd_l2]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXC42ljpSgMV",
        "outputId": "ea9b7cd2-728f-4954-a8ca-b9c86758ac17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6379.2937388420105"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_lrelu_dic['train_time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nWiGVtqTYVT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlIx5zc3TZN1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6Hr3dsYT6Ks"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUnY-M8HUftf"
      },
      "source": [
        "## Train and observe the performance of MLP models with 3 256 layers and two 512 layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZKlGfVEUfOc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytiaLQQrUpj9"
      },
      "outputs": [],
      "source": [
        "# Activation functions: relu, leaky_relu, tanh\n",
        "# Derivative: tanh_derivative, relu_derivative, leaky_relu_derivative\n",
        "\n",
        "mlp_3 = MLP(activation_func = relu, activation_deriv= relu_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 256, 256, 256, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znBaLz8gUpj_",
        "outputId": "8ec306b9-b667-4509-bcbc-c96d10109419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Cost:  0.26137174618991926 Train Accuracy: 13.168888888888889\n",
            "validation cost: 0.2612198405722894 Validation accuracy: 13.5\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Cost:  0.2399050978540756 Train Accuracy: 16.295555555555556\n",
            "validation cost: 0.23965815435987722 Validation accuracy: 16.56\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Cost:  0.23066195947601786 Train Accuracy: 18.664444444444445\n",
            "validation cost: 0.23041263316142926 Validation accuracy: 19.220000000000002\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Cost:  0.22464899939183092 Train Accuracy: 20.333333333333332\n",
            "validation cost: 0.22442366100769198 Validation accuracy: 20.76\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Cost:  0.2202837610319611 Train Accuracy: 21.50888888888889\n",
            "validation cost: 0.22010733191787324 Validation accuracy: 21.9\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Cost:  0.21685971872001855 Train Accuracy: 22.482222222222223\n",
            "validation cost: 0.21676938649207156 Validation accuracy: 23.06\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Cost:  0.2141091312253045 Train Accuracy: 23.493333333333332\n",
            "validation cost: 0.21410500631247464 Validation accuracy: 23.64\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Cost:  0.21183107862371545 Train Accuracy: 24.22888888888889\n",
            "validation cost: 0.2118592972290327 Validation accuracy: 24.48\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Cost:  0.2099063562001452 Train Accuracy: 24.831111111111113\n",
            "validation cost: 0.20995676466449942 Validation accuracy: 25.080000000000002\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Cost:  0.2082163545193431 Train Accuracy: 25.35777777777778\n",
            "validation cost: 0.20833217211979604 Validation accuracy: 25.4\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Cost:  0.2067167699011663 Train Accuracy: 25.977777777777778\n",
            "validation cost: 0.20687833431868963 Validation accuracy: 25.679999999999996\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Cost:  0.20535645706464475 Train Accuracy: 26.451111111111107\n",
            "validation cost: 0.20557381162902974 Validation accuracy: 26.22\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Cost:  0.20413984254364884 Train Accuracy: 26.842222222222222\n",
            "validation cost: 0.204398836520557 Validation accuracy: 26.44\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Cost:  0.20302101227990493 Train Accuracy: 27.24\n",
            "validation cost: 0.20332319507846222 Validation accuracy: 26.979999999999997\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Cost:  0.20201017817746886 Train Accuracy: 27.611111111111107\n",
            "validation cost: 0.20236367294210864 Validation accuracy: 27.24\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Cost:  0.20106947939777872 Train Accuracy: 27.973333333333333\n",
            "validation cost: 0.2014461909208628 Validation accuracy: 27.52\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Cost:  0.20020737808374287 Train Accuracy: 28.30666666666667\n",
            "validation cost: 0.2006313812931276 Validation accuracy: 27.900000000000002\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Cost:  0.19940039344019356 Train Accuracy: 28.58222222222222\n",
            "validation cost: 0.1998439376872409 Validation accuracy: 28.12\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Cost:  0.19863643061611186 Train Accuracy: 28.92222222222222\n",
            "validation cost: 0.19909639510324537 Validation accuracy: 28.46\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Cost:  0.19792776629684247 Train Accuracy: 29.144444444444446\n",
            "validation cost: 0.19840567563117834 Validation accuracy: 28.999999999999996\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Cost:  0.19726365606850293 Train Accuracy: 29.42666666666667\n",
            "validation cost: 0.1977692578040548 Validation accuracy: 29.220000000000002\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Cost:  0.19663049668741048 Train Accuracy: 29.615555555555556\n",
            "validation cost: 0.19714703502748507 Validation accuracy: 29.520000000000003\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Cost:  0.19604699714516502 Train Accuracy: 29.86888888888889\n",
            "validation cost: 0.19660071200771112 Validation accuracy: 29.959999999999997\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Cost:  0.19547388917012304 Train Accuracy: 30.071111111111108\n",
            "validation cost: 0.1960244584432335 Validation accuracy: 30.06\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Cost:  0.19493289349225987 Train Accuracy: 30.248888888888885\n",
            "validation cost: 0.19552627786011387 Validation accuracy: 30.28\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Cost:  0.19441677654790185 Train Accuracy: 30.42888888888889\n",
            "validation cost: 0.19503240218322374 Validation accuracy: 30.48\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Cost:  0.19391029351660227 Train Accuracy: 30.555555555555557\n",
            "validation cost: 0.19455879425522168 Validation accuracy: 30.880000000000003\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Cost:  0.19344302777179026 Train Accuracy: 30.759999999999998\n",
            "validation cost: 0.19410631740092368 Validation accuracy: 31.14\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Cost:  0.19299787266957708 Train Accuracy: 30.891111111111115\n",
            "validation cost: 0.193691827396245 Validation accuracy: 30.959999999999997\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Cost:  0.19253681510133466 Train Accuracy: 31.07111111111111\n",
            "validation cost: 0.1932701403612706 Validation accuracy: 31.34\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Cost:  0.19210956990923184 Train Accuracy: 31.19111111111111\n",
            "validation cost: 0.1928522005388904 Validation accuracy: 31.540000000000003\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Cost:  0.1917049953842657 Train Accuracy: 31.38222222222222\n",
            "validation cost: 0.19248695545750297 Validation accuracy: 31.619999999999997\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Cost:  0.1913101593587493 Train Accuracy: 31.486666666666668\n",
            "validation cost: 0.19209729097425948 Validation accuracy: 31.580000000000002\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Cost:  0.19093941202277118 Train Accuracy: 31.7\n",
            "validation cost: 0.19174468199519396 Validation accuracy: 31.900000000000002\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Cost:  0.19056395500066092 Train Accuracy: 31.906666666666666\n",
            "validation cost: 0.1913961846886148 Validation accuracy: 31.819999999999997\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Cost:  0.19020917900484516 Train Accuracy: 32.06222222222222\n",
            "validation cost: 0.19104942242793746 Validation accuracy: 32.1\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Cost:  0.1898806878954132 Train Accuracy: 32.16\n",
            "validation cost: 0.19074065598121234 Validation accuracy: 32.22\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Cost:  0.1895381213630634 Train Accuracy: 32.32\n",
            "validation cost: 0.1904233549113225 Validation accuracy: 32.24\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Cost:  0.18921828335053054 Train Accuracy: 32.382222222222225\n",
            "validation cost: 0.19011461971208438 Validation accuracy: 32.46\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Cost:  0.1889028409190268 Train Accuracy: 32.48444444444444\n",
            "validation cost: 0.18982123288902322 Validation accuracy: 32.300000000000004\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Cost:  0.1886043632062369 Train Accuracy: 32.66888888888889\n",
            "validation cost: 0.18954567783006435 Validation accuracy: 32.32\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Cost:  0.18829800089891024 Train Accuracy: 32.806666666666665\n",
            "validation cost: 0.18925011873843112 Validation accuracy: 32.42\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Cost:  0.1879896646763684 Train Accuracy: 32.882222222222225\n",
            "validation cost: 0.18896811202752695 Validation accuracy: 32.46\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Cost:  0.18771170254981864 Train Accuracy: 33.019999999999996\n",
            "validation cost: 0.18870248604127 Validation accuracy: 32.34\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Cost:  0.18743018798035957 Train Accuracy: 33.13333333333333\n",
            "validation cost: 0.18842939359611494 Validation accuracy: 32.5\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Cost:  0.18715920314909978 Train Accuracy: 33.22888888888889\n",
            "validation cost: 0.1881800755671907 Validation accuracy: 32.54\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Cost:  0.18690510878706865 Train Accuracy: 33.32888888888889\n",
            "validation cost: 0.18791615676107198 Validation accuracy: 32.58\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Cost:  0.18665278806600058 Train Accuracy: 33.42444444444445\n",
            "validation cost: 0.18767237910464168 Validation accuracy: 32.519999999999996\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Cost:  0.18639774264100167 Train Accuracy: 33.6\n",
            "validation cost: 0.1874468521760592 Validation accuracy: 32.56\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Cost:  0.18615020936708518 Train Accuracy: 33.68\n",
            "validation cost: 0.18720834150870025 Validation accuracy: 32.62\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Cost:  0.18589379029554662 Train Accuracy: 33.82888888888888\n",
            "validation cost: 0.186961501689051 Validation accuracy: 32.800000000000004\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Cost:  0.1856641947554545 Train Accuracy: 33.89333333333333\n",
            "validation cost: 0.1867521813520405 Validation accuracy: 32.76\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Cost:  0.1854327206942455 Train Accuracy: 33.96\n",
            "validation cost: 0.18653027405420186 Validation accuracy: 33.1\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Cost:  0.18520145272790708 Train Accuracy: 34.10666666666667\n",
            "validation cost: 0.1863128280242684 Validation accuracy: 33.06\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Cost:  0.1849786559122767 Train Accuracy: 34.16222222222222\n",
            "validation cost: 0.18609328851684423 Validation accuracy: 33.22\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Cost:  0.1847531944164494 Train Accuracy: 34.30666666666667\n",
            "validation cost: 0.18589334540760025 Validation accuracy: 33.379999999999995\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Cost:  0.18453444188286527 Train Accuracy: 34.339999999999996\n",
            "validation cost: 0.18568123149371263 Validation accuracy: 33.300000000000004\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Cost:  0.18431707123869476 Train Accuracy: 34.47777777777778\n",
            "validation cost: 0.18546665248462893 Validation accuracy: 33.32\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Cost:  0.18411483445524415 Train Accuracy: 34.52444444444445\n",
            "validation cost: 0.1852821338732137 Validation accuracy: 33.36\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Cost:  0.1839246614893358 Train Accuracy: 34.62888888888889\n",
            "validation cost: 0.18508478246631993 Validation accuracy: 33.4\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Cost:  0.18370561358769752 Train Accuracy: 34.653333333333336\n",
            "validation cost: 0.184896535005853 Validation accuracy: 33.46\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Cost:  0.18351206137535223 Train Accuracy: 34.815555555555555\n",
            "validation cost: 0.18471682544203238 Validation accuracy: 33.48\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Cost:  0.18330956021036782 Train Accuracy: 34.80444444444444\n",
            "validation cost: 0.18452715779566298 Validation accuracy: 33.4\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Cost:  0.18312014139476077 Train Accuracy: 34.86888888888889\n",
            "validation cost: 0.18433745094998016 Validation accuracy: 33.68\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Cost:  0.18293110976109023 Train Accuracy: 35.01111111111111\n",
            "validation cost: 0.18417648027708716 Validation accuracy: 33.64\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Cost:  0.18277140766250435 Train Accuracy: 35.04666666666667\n",
            "validation cost: 0.18398854223777525 Validation accuracy: 33.62\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Cost:  0.18256450528158 Train Accuracy: 35.13111111111111\n",
            "validation cost: 0.1838310364873719 Validation accuracy: 33.78\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Cost:  0.1823827102877998 Train Accuracy: 35.19111111111111\n",
            "validation cost: 0.18365820525517004 Validation accuracy: 34.0\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Cost:  0.1822073273279693 Train Accuracy: 35.23777777777778\n",
            "validation cost: 0.18348215122354372 Validation accuracy: 33.879999999999995\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Cost:  0.1820301339200485 Train Accuracy: 35.36222222222222\n",
            "validation cost: 0.1833058623828047 Validation accuracy: 34.04\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Cost:  0.18187117460977895 Train Accuracy: 35.464444444444446\n",
            "validation cost: 0.1831795622195409 Validation accuracy: 33.96\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Cost:  0.18169799881201612 Train Accuracy: 35.52444444444444\n",
            "validation cost: 0.1829888235407247 Validation accuracy: 34.12\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Cost:  0.18151656584260745 Train Accuracy: 35.568888888888885\n",
            "validation cost: 0.18282366137179473 Validation accuracy: 34.160000000000004\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Cost:  0.18134034245128045 Train Accuracy: 35.62444444444444\n",
            "validation cost: 0.1826618277343708 Validation accuracy: 34.28\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Cost:  0.1811876464959451 Train Accuracy: 35.775555555555556\n",
            "validation cost: 0.1825336411415922 Validation accuracy: 34.42\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Cost:  0.18101895721598385 Train Accuracy: 35.717777777777776\n",
            "validation cost: 0.1823593490176436 Validation accuracy: 34.239999999999995\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Cost:  0.18085140646042466 Train Accuracy: 35.83777777777778\n",
            "validation cost: 0.18221813159642367 Validation accuracy: 34.599999999999994\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Cost:  0.18070311995587404 Train Accuracy: 35.86222222222222\n",
            "validation cost: 0.18209391623804 Validation accuracy: 34.54\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "Cost:  0.18055497173733293 Train Accuracy: 35.94444444444444\n",
            "validation cost: 0.18192754080666884 Validation accuracy: 34.5\n",
            "Iteration: 157\n",
            "Iteration: 158\n",
            "Cost:  0.1803917421132806 Train Accuracy: 36.0\n",
            "validation cost: 0.18179336306346985 Validation accuracy: 34.760000000000005\n",
            "Iteration: 159\n",
            "Iteration: 160\n",
            "Cost:  0.1802397950824854 Train Accuracy: 36.09777777777778\n",
            "validation cost: 0.1816524087829236 Validation accuracy: 34.599999999999994\n",
            "Iteration: 161\n",
            "Iteration: 162\n",
            "Cost:  0.18008079025739515 Train Accuracy: 36.12888888888889\n",
            "validation cost: 0.1815091329379019 Validation accuracy: 34.88\n",
            "Iteration: 163\n",
            "Iteration: 164\n",
            "Cost:  0.1799577341962515 Train Accuracy: 36.193333333333335\n",
            "validation cost: 0.18138191747352103 Validation accuracy: 34.9\n",
            "Iteration: 165\n",
            "Iteration: 166\n",
            "Cost:  0.17981130867624714 Train Accuracy: 36.21333333333333\n",
            "validation cost: 0.18128308228917547 Validation accuracy: 35.04\n",
            "Iteration: 167\n",
            "Iteration: 168\n",
            "Cost:  0.17965443821542473 Train Accuracy: 36.24\n",
            "validation cost: 0.18111681829354398 Validation accuracy: 34.96\n",
            "Iteration: 169\n",
            "Iteration: 170\n",
            "Cost:  0.179501781144045 Train Accuracy: 36.391111111111115\n",
            "validation cost: 0.1809878062351368 Validation accuracy: 35.14\n",
            "Iteration: 171\n",
            "Iteration: 172\n",
            "Cost:  0.1793616965508597 Train Accuracy: 36.38666666666667\n",
            "validation cost: 0.18085788593643431 Validation accuracy: 35.22\n",
            "Iteration: 173\n",
            "Iteration: 174\n",
            "Cost:  0.17922250651534266 Train Accuracy: 36.45777777777778\n",
            "validation cost: 0.18072520972526826 Validation accuracy: 35.22\n",
            "Iteration: 175\n",
            "Iteration: 176\n",
            "Cost:  0.17909482605358676 Train Accuracy: 36.45777777777778\n",
            "validation cost: 0.18062175408649295 Validation accuracy: 35.24\n",
            "Iteration: 177\n",
            "Iteration: 178\n",
            "Cost:  0.17897155743556395 Train Accuracy: 36.50222222222222\n",
            "validation cost: 0.18050063973973993 Validation accuracy: 35.4\n",
            "Iteration: 179\n",
            "Iteration: 180\n",
            "Cost:  0.1788042707831386 Train Accuracy: 36.68888888888889\n",
            "validation cost: 0.18034814947999941 Validation accuracy: 35.4\n",
            "Iteration: 181\n",
            "Iteration: 182\n",
            "Cost:  0.17869295188351703 Train Accuracy: 36.70888888888889\n",
            "validation cost: 0.18026470015043008 Validation accuracy: 35.480000000000004\n",
            "Iteration: 183\n",
            "Iteration: 184\n",
            "Cost:  0.17854664582776605 Train Accuracy: 36.724444444444444\n",
            "validation cost: 0.18012906963714528 Validation accuracy: 35.42\n",
            "Iteration: 185\n",
            "Iteration: 186\n",
            "Cost:  0.17841249106009024 Train Accuracy: 36.78666666666667\n",
            "validation cost: 0.18000022548775557 Validation accuracy: 35.54\n",
            "Iteration: 187\n",
            "Iteration: 188\n",
            "Cost:  0.17827544712735643 Train Accuracy: 36.80444444444444\n",
            "validation cost: 0.17987380145636123 Validation accuracy: 35.56\n",
            "Iteration: 189\n",
            "Iteration: 190\n",
            "Cost:  0.17816319700283237 Train Accuracy: 36.864444444444445\n",
            "validation cost: 0.1797671617012716 Validation accuracy: 35.78\n",
            "Iteration: 191\n",
            "Iteration: 192\n",
            "Cost:  0.17802827382141598 Train Accuracy: 36.84222222222222\n",
            "validation cost: 0.17965440584821568 Validation accuracy: 35.64\n",
            "Iteration: 193\n",
            "Iteration: 194\n",
            "Cost:  0.17789807631861057 Train Accuracy: 36.92444444444444\n",
            "validation cost: 0.17953909575434238 Validation accuracy: 35.72\n",
            "Iteration: 195\n",
            "Iteration: 196\n",
            "Cost:  0.177781813159689 Train Accuracy: 37.01333333333333\n",
            "validation cost: 0.1794270427002584 Validation accuracy: 35.699999999999996\n",
            "Iteration: 197\n",
            "Iteration: 198\n",
            "Cost:  0.17764754532758026 Train Accuracy: 37.08888888888889\n",
            "validation cost: 0.17931979173509058 Validation accuracy: 35.94\n",
            "Iteration: 199\n",
            "Iteration: 200\n",
            "Cost:  0.17752386596644135 Train Accuracy: 37.117777777777775\n",
            "validation cost: 0.17920706017578344 Validation accuracy: 35.94\n",
            "Iteration: 201\n",
            "Iteration: 202\n",
            "Cost:  0.1773994417704987 Train Accuracy: 37.18222222222222\n",
            "validation cost: 0.1790932019657082 Validation accuracy: 36.0\n",
            "Iteration: 203\n",
            "Iteration: 204\n",
            "Cost:  0.17730439236818493 Train Accuracy: 37.21333333333333\n",
            "validation cost: 0.17899422569069529 Validation accuracy: 35.8\n",
            "Iteration: 205\n",
            "Iteration: 206\n",
            "Cost:  0.1771658556208166 Train Accuracy: 37.242222222222225\n",
            "validation cost: 0.17888049198891448 Validation accuracy: 36.16\n",
            "Iteration: 207\n",
            "Iteration: 208\n",
            "Cost:  0.1770585467535523 Train Accuracy: 37.30444444444444\n",
            "validation cost: 0.1787927031392579 Validation accuracy: 36.16\n",
            "Iteration: 209\n",
            "Iteration: 210\n",
            "Cost:  0.17693912935064085 Train Accuracy: 37.333333333333336\n",
            "validation cost: 0.17869959783652023 Validation accuracy: 36.24\n",
            "Iteration: 211\n",
            "Iteration: 212\n",
            "Cost:  0.17681182690540087 Train Accuracy: 37.39555555555555\n",
            "validation cost: 0.1785795331994902 Validation accuracy: 36.199999999999996\n",
            "Iteration: 213\n",
            "Iteration: 214\n",
            "Cost:  0.17671417086103625 Train Accuracy: 37.35333333333333\n",
            "validation cost: 0.17847269373498234 Validation accuracy: 36.18\n",
            "Iteration: 215\n",
            "Iteration: 216\n",
            "Cost:  0.17658447608971717 Train Accuracy: 37.4\n",
            "validation cost: 0.17836414895096472 Validation accuracy: 36.199999999999996\n",
            "Iteration: 217\n",
            "Iteration: 218\n",
            "Cost:  0.17646431347646996 Train Accuracy: 37.48222222222222\n",
            "validation cost: 0.17825881044557446 Validation accuracy: 36.26\n",
            "Iteration: 219\n",
            "Iteration: 220\n",
            "Cost:  0.17637208419341888 Train Accuracy: 37.50222222222222\n",
            "validation cost: 0.1781797804822708 Validation accuracy: 36.32\n",
            "Iteration: 221\n",
            "Iteration: 222\n",
            "Cost:  0.1762484010171034 Train Accuracy: 37.55555555555555\n",
            "validation cost: 0.17807746660654739 Validation accuracy: 36.36\n",
            "Iteration: 223\n",
            "Iteration: 224\n",
            "Cost:  0.17613959959681852 Train Accuracy: 37.53777777777778\n",
            "validation cost: 0.17799116609992882 Validation accuracy: 36.46\n",
            "Iteration: 225\n",
            "Iteration: 226\n",
            "Cost:  0.17602149483516832 Train Accuracy: 37.65555555555555\n",
            "validation cost: 0.1778804008252689 Validation accuracy: 36.64\n",
            "Iteration: 227\n",
            "Iteration: 228\n",
            "Cost:  0.17591636097094235 Train Accuracy: 37.70444444444445\n",
            "validation cost: 0.17778799456507713 Validation accuracy: 36.5\n",
            "Iteration: 229\n",
            "Iteration: 230\n",
            "Cost:  0.17581484131854025 Train Accuracy: 37.73111111111111\n",
            "validation cost: 0.17768697865161862 Validation accuracy: 36.36\n",
            "Iteration: 231\n",
            "Iteration: 232\n",
            "Cost:  0.1756955009557765 Train Accuracy: 37.77111111111111\n",
            "validation cost: 0.1775940176204682 Validation accuracy: 36.44\n",
            "Iteration: 233\n",
            "Iteration: 234\n",
            "Cost:  0.17560100309814694 Train Accuracy: 37.84444444444445\n",
            "validation cost: 0.17752655977676185 Validation accuracy: 36.52\n",
            "Iteration: 235\n",
            "Iteration: 236\n",
            "Cost:  0.1754904620602298 Train Accuracy: 37.955555555555556\n",
            "validation cost: 0.17741556691026716 Validation accuracy: 36.24\n",
            "Iteration: 237\n",
            "Iteration: 238\n",
            "Cost:  0.17538299545073283 Train Accuracy: 37.93333333333334\n",
            "validation cost: 0.1773185223181239 Validation accuracy: 36.36\n",
            "Iteration: 239\n",
            "Iteration: 240\n",
            "Cost:  0.17528185674896787 Train Accuracy: 37.95333333333333\n",
            "validation cost: 0.17725302745106822 Validation accuracy: 36.6\n",
            "Iteration: 241\n",
            "Iteration: 242\n",
            "Cost:  0.175183218403255 Train Accuracy: 38.04666666666667\n",
            "validation cost: 0.17715048931008542 Validation accuracy: 36.44\n",
            "Iteration: 243\n",
            "Iteration: 244\n",
            "Cost:  0.17508060458369903 Train Accuracy: 38.035555555555554\n",
            "validation cost: 0.17705781798945486 Validation accuracy: 36.52\n",
            "Iteration: 245\n",
            "Iteration: 246\n",
            "Cost:  0.17498197098335527 Train Accuracy: 38.04222222222222\n",
            "validation cost: 0.17698927724065616 Validation accuracy: 36.620000000000005\n",
            "Iteration: 247\n",
            "Iteration: 248\n",
            "Cost:  0.17487876007689823 Train Accuracy: 38.13333333333333\n",
            "validation cost: 0.176902825532072 Validation accuracy: 36.58\n",
            "Iteration: 249\n",
            "Iteration: 250\n",
            "Cost:  0.17480070699326786 Train Accuracy: 38.135555555555555\n",
            "validation cost: 0.17683543134344606 Validation accuracy: 36.58\n",
            "Iteration: 251\n",
            "Iteration: 252\n",
            "Cost:  0.17468296759071367 Train Accuracy: 38.20444444444445\n",
            "validation cost: 0.176710065228303 Validation accuracy: 36.8\n",
            "Iteration: 253\n",
            "Iteration: 254\n",
            "Cost:  0.1745939385666708 Train Accuracy: 38.26888888888889\n",
            "validation cost: 0.17665773931320514 Validation accuracy: 36.78\n",
            "Iteration: 255\n",
            "Iteration: 256\n",
            "Cost:  0.1744790250983 Train Accuracy: 38.32666666666667\n",
            "validation cost: 0.1765428470830077 Validation accuracy: 36.7\n",
            "Iteration: 257\n",
            "Iteration: 258\n",
            "Cost:  0.17438858573346863 Train Accuracy: 38.382222222222225\n",
            "validation cost: 0.17647707917096564 Validation accuracy: 36.9\n",
            "Iteration: 259\n",
            "Iteration: 260\n",
            "Cost:  0.17429423464285668 Train Accuracy: 38.38666666666667\n",
            "validation cost: 0.1764035141640328 Validation accuracy: 36.66\n",
            "Iteration: 261\n",
            "Iteration: 262\n",
            "Cost:  0.17420260576180463 Train Accuracy: 38.45333333333333\n",
            "validation cost: 0.17630795059029908 Validation accuracy: 36.82\n",
            "Iteration: 263\n",
            "Iteration: 264\n",
            "Cost:  0.1741073955643751 Train Accuracy: 38.51777777777778\n",
            "validation cost: 0.176216256150918 Validation accuracy: 36.88\n",
            "Iteration: 265\n",
            "Iteration: 266\n",
            "Cost:  0.1740075049175079 Train Accuracy: 38.52444444444444\n",
            "validation cost: 0.1761555060178612 Validation accuracy: 37.0\n",
            "Iteration: 267\n",
            "Iteration: 268\n",
            "Cost:  0.17391170965447533 Train Accuracy: 38.62444444444444\n",
            "validation cost: 0.17605544329044784 Validation accuracy: 37.059999999999995\n",
            "Iteration: 269\n",
            "Iteration: 270\n",
            "Cost:  0.17382845515636808 Train Accuracy: 38.66\n",
            "validation cost: 0.17598208648436256 Validation accuracy: 37.16\n",
            "Iteration: 271\n",
            "Iteration: 272\n",
            "Cost:  0.1737388106735248 Train Accuracy: 38.61777777777778\n",
            "validation cost: 0.1759237802085584 Validation accuracy: 37.12\n",
            "Iteration: 273\n",
            "Iteration: 274\n",
            "Cost:  0.1736362543827586 Train Accuracy: 38.717777777777776\n",
            "validation cost: 0.1758185652234639 Validation accuracy: 37.14\n",
            "Iteration: 275\n",
            "Iteration: 276\n",
            "Cost:  0.17355077163578853 Train Accuracy: 38.693333333333335\n",
            "validation cost: 0.17574726896356777 Validation accuracy: 37.12\n",
            "Iteration: 277\n",
            "Iteration: 278\n",
            "Cost:  0.17345573846004847 Train Accuracy: 38.77333333333333\n",
            "validation cost: 0.17566710828854126 Validation accuracy: 37.16\n",
            "Iteration: 279\n",
            "Iteration: 280\n",
            "Cost:  0.17337213882662303 Train Accuracy: 38.78666666666667\n",
            "validation cost: 0.17560205004770854 Validation accuracy: 37.3\n",
            "Iteration: 281\n",
            "Iteration: 282\n",
            "Cost:  0.17327422401374903 Train Accuracy: 38.85777777777778\n",
            "validation cost: 0.17552495665572468 Validation accuracy: 37.26\n",
            "Iteration: 283\n",
            "Iteration: 284\n",
            "Cost:  0.17319828216709068 Train Accuracy: 38.93111111111111\n",
            "validation cost: 0.17544269436298354 Validation accuracy: 37.24\n",
            "Iteration: 285\n",
            "Iteration: 286\n",
            "Cost:  0.1731167437810565 Train Accuracy: 38.86\n",
            "validation cost: 0.1753853598005824 Validation accuracy: 37.26\n",
            "Iteration: 287\n",
            "Iteration: 288\n",
            "Cost:  0.17304184008680895 Train Accuracy: 38.85777777777778\n",
            "validation cost: 0.1753354489968001 Validation accuracy: 37.32\n",
            "Iteration: 289\n",
            "Iteration: 290\n",
            "Cost:  0.17293545948156339 Train Accuracy: 38.955555555555556\n",
            "validation cost: 0.17523249001604924 Validation accuracy: 37.46\n",
            "Iteration: 291\n",
            "Iteration: 292\n",
            "Cost:  0.17284629839102014 Train Accuracy: 38.96666666666667\n",
            "validation cost: 0.1751461537023174 Validation accuracy: 37.4\n",
            "Iteration: 293\n",
            "Iteration: 294\n",
            "Cost:  0.17275306578349955 Train Accuracy: 39.05777777777778\n",
            "validation cost: 0.17506517118787826 Validation accuracy: 37.419999999999995\n",
            "Iteration: 295\n",
            "Iteration: 296\n",
            "Cost:  0.1726901752686996 Train Accuracy: 39.05555555555556\n",
            "validation cost: 0.1750289285300215 Validation accuracy: 37.64\n",
            "Iteration: 297\n",
            "Iteration: 298\n",
            "Cost:  0.17259372722924143 Train Accuracy: 39.05111111111111\n",
            "validation cost: 0.1749483588514403 Validation accuracy: 37.54\n",
            "Iteration: 299\n",
            "Iteration: 300\n",
            "Cost:  0.1725142454048727 Train Accuracy: 39.09777777777778\n",
            "validation cost: 0.1748695982993773 Validation accuracy: 37.38\n",
            "Iteration: 301\n",
            "Iteration: 302\n",
            "Cost:  0.17241943238988283 Train Accuracy: 39.14\n",
            "validation cost: 0.17478582373809903 Validation accuracy: 37.5\n",
            "Iteration: 303\n",
            "Iteration: 304\n",
            "Cost:  0.17234834616682257 Train Accuracy: 39.13111111111111\n",
            "validation cost: 0.1747380778458771 Validation accuracy: 37.54\n",
            "Iteration: 305\n",
            "Iteration: 306\n",
            "Cost:  0.17226315540303366 Train Accuracy: 39.233333333333334\n",
            "validation cost: 0.17465472277456665 Validation accuracy: 37.580000000000005\n",
            "Iteration: 307\n",
            "Iteration: 308\n",
            "Cost:  0.17218884294112827 Train Accuracy: 39.19111111111111\n",
            "validation cost: 0.17458262263448485 Validation accuracy: 37.66\n",
            "Iteration: 309\n",
            "Iteration: 310\n",
            "Cost:  0.17209696045110928 Train Accuracy: 39.297777777777775\n",
            "validation cost: 0.17450108280785062 Validation accuracy: 37.7\n",
            "Iteration: 311\n",
            "Iteration: 312\n",
            "Cost:  0.17201178725295163 Train Accuracy: 39.27777777777778\n",
            "validation cost: 0.1744246861182859 Validation accuracy: 37.9\n",
            "Iteration: 313\n",
            "Iteration: 314\n",
            "Cost:  0.1719412696841944 Train Accuracy: 39.26888888888889\n",
            "validation cost: 0.17438512099194708 Validation accuracy: 37.84\n",
            "Iteration: 315\n",
            "Iteration: 316\n",
            "Cost:  0.17186649973270196 Train Accuracy: 39.342222222222226\n",
            "validation cost: 0.17429373498793035 Validation accuracy: 38.04\n",
            "Iteration: 317\n",
            "Iteration: 318\n",
            "Cost:  0.17177175981138318 Train Accuracy: 39.30888888888889\n",
            "validation cost: 0.1742414833767771 Validation accuracy: 38.04\n",
            "Iteration: 319\n",
            "Iteration: 320\n",
            "Cost:  0.17169390369593457 Train Accuracy: 39.342222222222226\n",
            "validation cost: 0.17416985809355157 Validation accuracy: 38.019999999999996\n",
            "Iteration: 321\n",
            "Iteration: 322\n",
            "Cost:  0.1716183490176874 Train Accuracy: 39.39333333333334\n",
            "validation cost: 0.1741170824803214 Validation accuracy: 38.0\n",
            "Iteration: 323\n",
            "Iteration: 324\n",
            "Cost:  0.17153856935209227 Train Accuracy: 39.48222222222223\n",
            "validation cost: 0.1740236551462201 Validation accuracy: 38.2\n",
            "Iteration: 325\n",
            "Iteration: 326\n",
            "Cost:  0.17147099231094487 Train Accuracy: 39.45777777777778\n",
            "validation cost: 0.17397659114185252 Validation accuracy: 38.2\n",
            "Iteration: 327\n",
            "Iteration: 328\n",
            "Cost:  0.17138144829041696 Train Accuracy: 39.56\n",
            "validation cost: 0.17390501440125178 Validation accuracy: 38.04\n",
            "Iteration: 329\n",
            "Iteration: 330\n",
            "Cost:  0.171308515581903 Train Accuracy: 39.54222222222222\n",
            "validation cost: 0.1738358549133845 Validation accuracy: 38.12\n",
            "Iteration: 331\n",
            "Iteration: 332\n",
            "Cost:  0.17122537526034506 Train Accuracy: 39.56222222222222\n",
            "validation cost: 0.17376480177669523 Validation accuracy: 38.1\n",
            "Iteration: 333\n",
            "Iteration: 334\n",
            "Cost:  0.1711778837800517 Train Accuracy: 39.553333333333335\n",
            "validation cost: 0.1737346930008034 Validation accuracy: 38.4\n",
            "Iteration: 335\n",
            "Iteration: 336\n",
            "Cost:  0.1710811700174304 Train Accuracy: 39.644444444444446\n",
            "validation cost: 0.17363555742758222 Validation accuracy: 38.42\n",
            "Iteration: 337\n",
            "Iteration: 338\n",
            "Cost:  0.1710103217105952 Train Accuracy: 39.651111111111106\n",
            "validation cost: 0.17361187217349786 Validation accuracy: 38.3\n",
            "Iteration: 339\n",
            "Iteration: 340\n",
            "Cost:  0.17093629662832993 Train Accuracy: 39.571111111111115\n",
            "validation cost: 0.17354047044153914 Validation accuracy: 38.34\n",
            "Iteration: 341\n",
            "Iteration: 342\n",
            "Cost:  0.17084980137659211 Train Accuracy: 39.67777777777778\n",
            "validation cost: 0.17344631654440745 Validation accuracy: 38.24\n",
            "Iteration: 343\n",
            "Iteration: 344\n",
            "Cost:  0.17078035060351313 Train Accuracy: 39.71333333333333\n",
            "validation cost: 0.17340524516674707 Validation accuracy: 38.24\n",
            "Iteration: 345\n",
            "Iteration: 346\n",
            "Cost:  0.17070283878579406 Train Accuracy: 39.78\n",
            "validation cost: 0.1733276704943131 Validation accuracy: 38.34\n",
            "Iteration: 347\n",
            "Iteration: 348\n",
            "Cost:  0.17063141717587899 Train Accuracy: 39.78666666666666\n",
            "validation cost: 0.17326751691203204 Validation accuracy: 38.34\n",
            "Iteration: 349\n",
            "Iteration: 350\n",
            "Cost:  0.17055477116128342 Train Accuracy: 39.77777777777778\n",
            "validation cost: 0.17322162725528406 Validation accuracy: 38.18\n",
            "Iteration: 351\n",
            "Iteration: 352\n",
            "Cost:  0.1704955606575148 Train Accuracy: 39.80222222222222\n",
            "validation cost: 0.17320084339062666 Validation accuracy: 38.440000000000005\n",
            "Iteration: 353\n",
            "Iteration: 354\n",
            "Cost:  0.17041218253416146 Train Accuracy: 39.82\n",
            "validation cost: 0.17310207595527066 Validation accuracy: 38.3\n",
            "Iteration: 355\n",
            "Iteration: 356\n",
            "Cost:  0.17033348101472714 Train Accuracy: 39.89555555555555\n",
            "validation cost: 0.17303287361676759 Validation accuracy: 38.5\n",
            "Iteration: 357\n",
            "Iteration: 358\n",
            "Cost:  0.1702602026900904 Train Accuracy: 39.90888888888889\n",
            "validation cost: 0.17297761175228082 Validation accuracy: 38.32\n",
            "Iteration: 359\n",
            "Iteration: 360\n",
            "Cost:  0.1701905003636471 Train Accuracy: 39.94888888888889\n",
            "validation cost: 0.1729258956246269 Validation accuracy: 38.379999999999995\n",
            "Iteration: 361\n",
            "Iteration: 362\n",
            "Cost:  0.17011390494452994 Train Accuracy: 39.955555555555556\n",
            "validation cost: 0.17284644041428424 Validation accuracy: 38.3\n",
            "Iteration: 363\n",
            "Iteration: 364\n",
            "Cost:  0.1700462468666951 Train Accuracy: 39.99111111111111\n",
            "validation cost: 0.17280159374195203 Validation accuracy: 38.56\n",
            "Iteration: 365\n",
            "Iteration: 366\n",
            "Cost:  0.16997195732211157 Train Accuracy: 40.077777777777776\n",
            "validation cost: 0.17272796206666782 Validation accuracy: 38.42\n",
            "Iteration: 367\n",
            "Iteration: 368\n",
            "Cost:  0.1699010268619184 Train Accuracy: 40.06\n",
            "validation cost: 0.17269123215700155 Validation accuracy: 38.58\n",
            "Iteration: 369\n",
            "Iteration: 370\n",
            "Cost:  0.16983240842474168 Train Accuracy: 40.05555555555556\n",
            "validation cost: 0.17262982417292103 Validation accuracy: 38.54\n",
            "Iteration: 371\n",
            "Iteration: 372\n",
            "Cost:  0.16978050437731754 Train Accuracy: 40.14\n",
            "validation cost: 0.17257560479678766 Validation accuracy: 38.4\n",
            "Iteration: 373\n",
            "Iteration: 374\n",
            "Cost:  0.16968648298796296 Train Accuracy: 40.12222222222222\n",
            "validation cost: 0.17249594831926207 Validation accuracy: 38.5\n",
            "Iteration: 375\n",
            "Iteration: 376\n",
            "Cost:  0.16962122607454266 Train Accuracy: 40.086666666666666\n",
            "validation cost: 0.1724563969731265 Validation accuracy: 38.58\n",
            "Iteration: 377\n",
            "Iteration: 378\n",
            "Cost:  0.16955190870446218 Train Accuracy: 40.14\n",
            "validation cost: 0.17241077304540348 Validation accuracy: 38.4\n",
            "Iteration: 379\n",
            "Iteration: 380\n",
            "Cost:  0.16948052641295533 Train Accuracy: 40.23777777777778\n",
            "validation cost: 0.17234680961920068 Validation accuracy: 38.54\n",
            "Iteration: 381\n",
            "Iteration: 382\n",
            "Cost:  0.169406680600154 Train Accuracy: 40.242222222222225\n",
            "validation cost: 0.17228249958805325 Validation accuracy: 38.62\n",
            "Iteration: 383\n",
            "Iteration: 384\n",
            "Cost:  0.16933896059697642 Train Accuracy: 40.29333333333333\n",
            "validation cost: 0.1722263040062652 Validation accuracy: 38.64\n",
            "Iteration: 385\n",
            "Iteration: 386\n",
            "Cost:  0.16927924453528237 Train Accuracy: 40.242222222222225\n",
            "validation cost: 0.17218351405136811 Validation accuracy: 38.46\n",
            "Iteration: 387\n",
            "Iteration: 388\n",
            "Cost:  0.16920608631300416 Train Accuracy: 40.32222222222222\n",
            "validation cost: 0.17212145451891117 Validation accuracy: 38.58\n",
            "Iteration: 389\n",
            "Iteration: 390\n",
            "Cost:  0.16913987045464812 Train Accuracy: 40.27777777777778\n",
            "validation cost: 0.17207354782651266 Validation accuracy: 38.54\n",
            "Iteration: 391\n",
            "Iteration: 392\n",
            "Cost:  0.16907731385965566 Train Accuracy: 40.33555555555556\n",
            "validation cost: 0.17200964208994798 Validation accuracy: 38.7\n",
            "Iteration: 393\n",
            "Iteration: 394\n",
            "Cost:  0.16900511250594796 Train Accuracy: 40.38666666666666\n",
            "validation cost: 0.17197435477265247 Validation accuracy: 38.62\n",
            "Iteration: 395\n",
            "Iteration: 396\n",
            "Cost:  0.16894337622480246 Train Accuracy: 40.40222222222222\n",
            "validation cost: 0.17191233028503425 Validation accuracy: 38.72\n",
            "Iteration: 397\n",
            "Iteration: 398\n",
            "Cost:  0.16888294732604625 Train Accuracy: 40.43555555555556\n",
            "validation cost: 0.17187131213841667 Validation accuracy: 38.82\n",
            "Iteration: 399\n",
            "Iteration: 400\n",
            "Cost:  0.16880521423340383 Train Accuracy: 40.49333333333333\n",
            "validation cost: 0.17179741065197596 Validation accuracy: 38.82\n",
            "Iteration: 401\n",
            "Iteration: 402\n",
            "Cost:  0.16873958839003045 Train Accuracy: 40.46222222222222\n",
            "validation cost: 0.1717527663680594 Validation accuracy: 38.74\n",
            "Iteration: 403\n",
            "Iteration: 404\n",
            "Cost:  0.16867152209421946 Train Accuracy: 40.52222222222222\n",
            "validation cost: 0.1716830958454278 Validation accuracy: 38.72\n",
            "Iteration: 405\n",
            "Iteration: 406\n",
            "Cost:  0.16860915431616677 Train Accuracy: 40.568888888888885\n",
            "validation cost: 0.17164016083924682 Validation accuracy: 38.76\n",
            "Iteration: 407\n",
            "Iteration: 408\n",
            "Cost:  0.16854598549110406 Train Accuracy: 40.56\n",
            "validation cost: 0.1716001622409694 Validation accuracy: 38.800000000000004\n",
            "Iteration: 409\n",
            "Iteration: 410\n",
            "Cost:  0.16847793249128398 Train Accuracy: 40.58444444444444\n",
            "validation cost: 0.1715586420066329 Validation accuracy: 38.7\n",
            "Iteration: 411\n",
            "Iteration: 412\n",
            "Cost:  0.1684155056810558 Train Accuracy: 40.6\n",
            "validation cost: 0.17150046461465004 Validation accuracy: 38.879999999999995\n",
            "Iteration: 413\n",
            "Iteration: 414\n",
            "Cost:  0.16836061991140894 Train Accuracy: 40.568888888888885\n",
            "validation cost: 0.17147322223400704 Validation accuracy: 38.92\n",
            "Iteration: 415\n",
            "Iteration: 416\n",
            "Cost:  0.16828449575185106 Train Accuracy: 40.644444444444446\n",
            "validation cost: 0.17138641973078844 Validation accuracy: 38.940000000000005\n",
            "Iteration: 417\n",
            "Iteration: 418\n",
            "Cost:  0.16821607795638238 Train Accuracy: 40.66222222222222\n",
            "validation cost: 0.17134508160640743 Validation accuracy: 38.92\n",
            "Iteration: 419\n",
            "Iteration: 420\n",
            "Cost:  0.1681586980992221 Train Accuracy: 40.724444444444444\n",
            "validation cost: 0.17130842815168032 Validation accuracy: 38.879999999999995\n",
            "Iteration: 421\n",
            "Iteration: 422\n",
            "Cost:  0.1681110579028332 Train Accuracy: 40.69111111111111\n",
            "validation cost: 0.17127767061088478 Validation accuracy: 38.96\n",
            "Iteration: 423\n",
            "Iteration: 424\n",
            "Cost:  0.16804098279404886 Train Accuracy: 40.78888888888889\n",
            "validation cost: 0.17119699060392704 Validation accuracy: 38.84\n",
            "Iteration: 425\n",
            "Iteration: 426\n",
            "Cost:  0.1679736535329625 Train Accuracy: 40.82666666666667\n",
            "validation cost: 0.17114928789534078 Validation accuracy: 38.96\n",
            "Iteration: 427\n",
            "Iteration: 428\n",
            "Cost:  0.16790360432202853 Train Accuracy: 40.797777777777775\n",
            "validation cost: 0.1710863781219254 Validation accuracy: 39.160000000000004\n",
            "Iteration: 429\n",
            "Iteration: 430\n",
            "Cost:  0.1678407723689781 Train Accuracy: 40.80666666666667\n",
            "validation cost: 0.1710555245983546 Validation accuracy: 38.96\n",
            "Iteration: 431\n",
            "Iteration: 432\n",
            "Cost:  0.16778514735616723 Train Accuracy: 40.9\n",
            "validation cost: 0.17101346200428805 Validation accuracy: 39.12\n",
            "Iteration: 433\n",
            "Iteration: 434\n",
            "Cost:  0.16771936856626757 Train Accuracy: 40.86\n",
            "validation cost: 0.17094814520895746 Validation accuracy: 38.9\n",
            "Iteration: 435\n",
            "Iteration: 436\n",
            "Cost:  0.1676626672957706 Train Accuracy: 40.94444444444444\n",
            "validation cost: 0.17090807456894633 Validation accuracy: 39.12\n",
            "Iteration: 437\n",
            "Iteration: 438\n",
            "Cost:  0.1676352410466447 Train Accuracy: 40.88888888888889\n",
            "validation cost: 0.17087965122918464 Validation accuracy: 38.800000000000004\n",
            "Iteration: 439\n",
            "Iteration: 440\n",
            "Cost:  0.16753467276734996 Train Accuracy: 40.971111111111114\n",
            "validation cost: 0.17077634010040685 Validation accuracy: 39.08\n",
            "Iteration: 441\n",
            "Iteration: 442\n",
            "Cost:  0.16746457993072045 Train Accuracy: 40.98\n",
            "validation cost: 0.17073649631114582 Validation accuracy: 39.12\n",
            "Iteration: 443\n",
            "Iteration: 444\n",
            "Cost:  0.16740798174235455 Train Accuracy: 40.973333333333336\n",
            "validation cost: 0.1706955046030033 Validation accuracy: 39.14\n",
            "Iteration: 445\n",
            "Iteration: 446\n",
            "Cost:  0.1673654140907897 Train Accuracy: 41.044444444444444\n",
            "validation cost: 0.170645357138643 Validation accuracy: 39.300000000000004\n",
            "Iteration: 447\n",
            "Iteration: 448\n",
            "Cost:  0.1672897070161102 Train Accuracy: 40.988888888888894\n",
            "validation cost: 0.17059418012542307 Validation accuracy: 39.2\n",
            "Iteration: 449\n",
            "Iteration: 450\n",
            "Cost:  0.1672431241816789 Train Accuracy: 41.102222222222224\n",
            "validation cost: 0.1705548292843193 Validation accuracy: 39.28\n",
            "Iteration: 451\n",
            "Iteration: 452\n",
            "Cost:  0.16717948983344746 Train Accuracy: 41.12444444444445\n",
            "validation cost: 0.17052046265081705 Validation accuracy: 39.46\n",
            "Iteration: 453\n",
            "Iteration: 454\n",
            "Cost:  0.16712458007204764 Train Accuracy: 41.14666666666666\n",
            "validation cost: 0.17047168091330095 Validation accuracy: 39.379999999999995\n",
            "Iteration: 455\n",
            "Iteration: 456\n",
            "Cost:  0.1670567411901103 Train Accuracy: 41.215555555555554\n",
            "validation cost: 0.1703976145867072 Validation accuracy: 39.36\n",
            "Iteration: 457\n",
            "Iteration: 458\n",
            "Cost:  0.16699340006684518 Train Accuracy: 41.14666666666666\n",
            "validation cost: 0.17034860595856535 Validation accuracy: 39.42\n",
            "Iteration: 459\n",
            "Iteration: 460\n",
            "Cost:  0.16693976541345368 Train Accuracy: 41.05777777777778\n",
            "validation cost: 0.17030786992505015 Validation accuracy: 39.36\n",
            "Iteration: 461\n",
            "Iteration: 462\n",
            "Cost:  0.16687874746133247 Train Accuracy: 41.208888888888886\n",
            "validation cost: 0.17025176918889776 Validation accuracy: 39.32\n",
            "Iteration: 463\n",
            "Iteration: 464\n",
            "Cost:  0.16682450132274362 Train Accuracy: 41.27777777777778\n",
            "validation cost: 0.17022688612364392 Validation accuracy: 39.54\n",
            "Iteration: 465\n",
            "Iteration: 466\n",
            "Cost:  0.1667651114074653 Train Accuracy: 41.202222222222225\n",
            "validation cost: 0.17017583686567195 Validation accuracy: 39.36\n",
            "Iteration: 467\n",
            "Iteration: 468\n",
            "Cost:  0.1667011866458122 Train Accuracy: 41.224444444444444\n",
            "validation cost: 0.17011575411884788 Validation accuracy: 39.300000000000004\n",
            "Iteration: 469\n",
            "Iteration: 470\n",
            "Cost:  0.16664252107919672 Train Accuracy: 41.27333333333333\n",
            "validation cost: 0.1700679718549109 Validation accuracy: 39.46\n",
            "Iteration: 471\n",
            "Iteration: 472\n",
            "Cost:  0.16659902119742578 Train Accuracy: 41.31333333333333\n",
            "validation cost: 0.17006309504974593 Validation accuracy: 39.34\n",
            "Iteration: 473\n",
            "Iteration: 474\n",
            "Cost:  0.1665262172778694 Train Accuracy: 41.28222222222222\n",
            "validation cost: 0.16996813121200244 Validation accuracy: 39.44\n",
            "Iteration: 475\n",
            "Iteration: 476\n",
            "Cost:  0.16647342037644844 Train Accuracy: 41.36222222222222\n",
            "validation cost: 0.1699279329147158 Validation accuracy: 39.64\n",
            "Iteration: 477\n",
            "Iteration: 478\n",
            "Cost:  0.16641606334869255 Train Accuracy: 41.355555555555554\n",
            "validation cost: 0.1698844482890749 Validation accuracy: 39.48\n",
            "Iteration: 479\n",
            "Iteration: 480\n",
            "Cost:  0.16635789142402313 Train Accuracy: 41.43333333333333\n",
            "validation cost: 0.1698358657515915 Validation accuracy: 39.46\n",
            "Iteration: 481\n",
            "Iteration: 482\n",
            "Cost:  0.1663057386918436 Train Accuracy: 41.397777777777776\n",
            "validation cost: 0.16980275270448128 Validation accuracy: 39.4\n",
            "Iteration: 483\n",
            "Iteration: 484\n",
            "Cost:  0.16624811444928206 Train Accuracy: 41.49777777777778\n",
            "validation cost: 0.1697674934574785 Validation accuracy: 39.660000000000004\n",
            "Iteration: 485\n",
            "Iteration: 486\n",
            "Cost:  0.16619079892254665 Train Accuracy: 41.455555555555556\n",
            "validation cost: 0.16972452146170638 Validation accuracy: 39.660000000000004\n",
            "Iteration: 487\n",
            "Iteration: 488\n",
            "Cost:  0.1661448079682721 Train Accuracy: 41.47555555555555\n",
            "validation cost: 0.16968046681330812 Validation accuracy: 39.519999999999996\n",
            "Iteration: 489\n",
            "Iteration: 490\n",
            "Cost:  0.16607804563653406 Train Accuracy: 41.531111111111116\n",
            "validation cost: 0.16963066020566675 Validation accuracy: 39.48\n",
            "Iteration: 491\n",
            "Iteration: 492\n",
            "Cost:  0.16602072594524442 Train Accuracy: 41.562222222222225\n",
            "validation cost: 0.16956514922942653 Validation accuracy: 39.56\n",
            "Iteration: 493\n",
            "Iteration: 494\n",
            "Cost:  0.16596837974584852 Train Accuracy: 41.60888888888889\n",
            "validation cost: 0.16953805810945408 Validation accuracy: 39.660000000000004\n",
            "Iteration: 495\n",
            "Iteration: 496\n",
            "Cost:  0.16592765543881347 Train Accuracy: 41.56\n",
            "validation cost: 0.16952232413456422 Validation accuracy: 39.46\n",
            "Iteration: 497\n",
            "Iteration: 498\n",
            "Cost:  0.16586518653804894 Train Accuracy: 41.62444444444444\n",
            "validation cost: 0.16947560995830607 Validation accuracy: 39.7\n",
            "Iteration: 499\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "mlp_3.fit_btch(lr=0.01, nitr= 500, alpha=0, beta=0, tol=5, epsilon=1e-5)\n",
        "t2 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9tQq3ZeUpkB"
      },
      "outputs": [],
      "source": [
        "mlp_3_perf = {'test_perf': mlp_3.evaluate_acc(x_test_vector, test_y), 'train_time': t2-t1,\n",
        "            'train_cost': mlp_3.costs, 'val_cost': mlp_3.val_costs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfT8Bvg5UpkD"
      },
      "outputs": [],
      "source": [
        "with open('mlp_3.pickle', 'wb') as h:\n",
        "    pickle.dump(mlp_3_perf, h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obJpOMIQUpkE"
      },
      "outputs": [],
      "source": [
        "# get the folder id where you want to save your file\n",
        "file = drive.CreateFile()\n",
        "file.SetContentFile('mlp_3.pickle')\n",
        "file.Upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dTcHDjLU52u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU_WFmEIU6KP"
      },
      "outputs": [],
      "source": [
        "# Activation functions: relu, leaky_relu, tanh\n",
        "# Derivative: tanh_derivative, relu_derivative, leaky_relu_derivative\n",
        "\n",
        "mlp_512 = MLP(activation_func = relu, activation_deriv= relu_derivative, n=x_train_vector.shape[0], \n",
        "          layer_size = [inp_dim, 512, 512, 10], btch_sz=256, train_set = train_set, \n",
        "          X=x_train_vector, Y=train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiGEQt8_U6KS",
        "outputId": "1e1a50fe-c427-46a6-910d-4ac52afeba15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Cost:  0.297380617657668 Train Accuracy: 12.70888888888889\n",
            "validation cost: 0.29648465550192415 Validation accuracy: 13.28\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Cost:  0.26285287075162567 Train Accuracy: 17.624444444444446\n",
            "validation cost: 0.2622342015834318 Validation accuracy: 18.16\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Cost:  0.24690327690177458 Train Accuracy: 20.44\n",
            "validation cost: 0.24659277812776006 Validation accuracy: 20.64\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Cost:  0.23708724671167164 Train Accuracy: 22.38\n",
            "validation cost: 0.2370201899999708 Validation accuracy: 23.119999999999997\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Cost:  0.2302006495427071 Train Accuracy: 23.795555555555556\n",
            "validation cost: 0.2303721882903865 Validation accuracy: 24.44\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Cost:  0.22503865099290132 Train Accuracy: 24.897777777777776\n",
            "validation cost: 0.22540872012708402 Validation accuracy: 25.5\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Cost:  0.22091608732451762 Train Accuracy: 25.986666666666668\n",
            "validation cost: 0.22147457027297202 Validation accuracy: 26.340000000000003\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Cost:  0.21737301734773135 Train Accuracy: 26.57777777777778\n",
            "validation cost: 0.2181352150156395 Validation accuracy: 26.740000000000002\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Cost:  0.21442850467203828 Train Accuracy: 27.206666666666667\n",
            "validation cost: 0.21537150395324495 Validation accuracy: 27.22\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Cost:  0.21179991429190048 Train Accuracy: 27.775555555555552\n",
            "validation cost: 0.21298209885311042 Validation accuracy: 27.92\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Cost:  0.20946450864723218 Train Accuracy: 28.50888888888889\n",
            "validation cost: 0.21069686693750744 Validation accuracy: 28.84\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Cost:  0.20742411496371393 Train Accuracy: 28.802222222222223\n",
            "validation cost: 0.2087880546552832 Validation accuracy: 28.999999999999996\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Cost:  0.20564475756778525 Train Accuracy: 29.306666666666665\n",
            "validation cost: 0.20714764497570137 Validation accuracy: 29.26\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Cost:  0.20403091995579142 Train Accuracy: 29.74222222222222\n",
            "validation cost: 0.20556046143660256 Validation accuracy: 30.099999999999998\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Cost:  0.2024980327660175 Train Accuracy: 30.288888888888888\n",
            "validation cost: 0.2041702812058156 Validation accuracy: 30.14\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Cost:  0.20107285849625556 Train Accuracy: 30.59777777777778\n",
            "validation cost: 0.20280138957314484 Validation accuracy: 30.64\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Cost:  0.19983335476765754 Train Accuracy: 30.86\n",
            "validation cost: 0.20170095969231336 Validation accuracy: 30.959999999999997\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Cost:  0.1986292981073315 Train Accuracy: 31.253333333333334\n",
            "validation cost: 0.2005420605744711 Validation accuracy: 31.240000000000002\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Cost:  0.19750832696922402 Train Accuracy: 31.61777777777778\n",
            "validation cost: 0.19950347826371315 Validation accuracy: 31.7\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Cost:  0.19653003307402783 Train Accuracy: 31.88888888888889\n",
            "validation cost: 0.198615361726336 Validation accuracy: 31.759999999999998\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Cost:  0.19552533544582493 Train Accuracy: 32.22222222222222\n",
            "validation cost: 0.1977101611772305 Validation accuracy: 31.86\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Cost:  0.19468434696152975 Train Accuracy: 32.37555555555556\n",
            "validation cost: 0.19696527802312142 Validation accuracy: 31.879999999999995\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Cost:  0.1937465904475614 Train Accuracy: 32.711111111111116\n",
            "validation cost: 0.19606801020634732 Validation accuracy: 32.4\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Cost:  0.1929228866245156 Train Accuracy: 32.873333333333335\n",
            "validation cost: 0.19530641054488387 Validation accuracy: 32.54\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Cost:  0.1921883660093874 Train Accuracy: 33.11777777777778\n",
            "validation cost: 0.19464274979769183 Validation accuracy: 32.66\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Cost:  0.19142573647071529 Train Accuracy: 33.40888888888889\n",
            "validation cost: 0.19404274466795043 Validation accuracy: 32.86\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Cost:  0.1906624645816259 Train Accuracy: 33.69111111111111\n",
            "validation cost: 0.1932523993089344 Validation accuracy: 33.06\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Cost:  0.19000555856722703 Train Accuracy: 33.82666666666667\n",
            "validation cost: 0.19264716978294477 Validation accuracy: 33.08\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Cost:  0.18932669138222413 Train Accuracy: 34.004444444444445\n",
            "validation cost: 0.19202198460592684 Validation accuracy: 33.239999999999995\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Cost:  0.18878364706853482 Train Accuracy: 34.23777777777778\n",
            "validation cost: 0.19157551809660217 Validation accuracy: 33.44\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Cost:  0.1880916113544522 Train Accuracy: 34.404444444444444\n",
            "validation cost: 0.1908993393971753 Validation accuracy: 33.64\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Cost:  0.1875541386609087 Train Accuracy: 34.531111111111116\n",
            "validation cost: 0.1904283875755959 Validation accuracy: 33.64\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Cost:  0.1869939850453225 Train Accuracy: 34.70666666666667\n",
            "validation cost: 0.1898496958197338 Validation accuracy: 33.76\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Cost:  0.18645570254387728 Train Accuracy: 34.99777777777778\n",
            "validation cost: 0.18931874763463882 Validation accuracy: 34.1\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Cost:  0.18591598762687198 Train Accuracy: 35.102222222222224\n",
            "validation cost: 0.18882842518085796 Validation accuracy: 34.339999999999996\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Cost:  0.18538734547584032 Train Accuracy: 35.23555555555555\n",
            "validation cost: 0.18836247501550926 Validation accuracy: 34.339999999999996\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Cost:  0.18491620257406333 Train Accuracy: 35.41555555555556\n",
            "validation cost: 0.18790461467678624 Validation accuracy: 34.64\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Cost:  0.18446110801742863 Train Accuracy: 35.586666666666666\n",
            "validation cost: 0.18752734047386607 Validation accuracy: 34.9\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Cost:  0.1840035145837461 Train Accuracy: 35.79333333333333\n",
            "validation cost: 0.1870822248102518 Validation accuracy: 35.0\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Cost:  0.18357385644521665 Train Accuracy: 35.81333333333333\n",
            "validation cost: 0.18671428254612205 Validation accuracy: 34.96\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Cost:  0.18312677642732578 Train Accuracy: 35.98222222222222\n",
            "validation cost: 0.1862987563994201 Validation accuracy: 34.92\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Cost:  0.1827575158567788 Train Accuracy: 36.10444444444445\n",
            "validation cost: 0.18596915137612366 Validation accuracy: 35.22\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Cost:  0.18231890045528176 Train Accuracy: 36.27777777777778\n",
            "validation cost: 0.18551374139657878 Validation accuracy: 35.36\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Cost:  0.18192502782309114 Train Accuracy: 36.446666666666665\n",
            "validation cost: 0.18519282863136016 Validation accuracy: 35.54\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Cost:  0.1815187393063335 Train Accuracy: 36.477777777777774\n",
            "validation cost: 0.18478804254445658 Validation accuracy: 35.6\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Cost:  0.18120749908486708 Train Accuracy: 36.56444444444445\n",
            "validation cost: 0.1845016299225994 Validation accuracy: 35.28\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Cost:  0.18077179585191558 Train Accuracy: 36.78444444444444\n",
            "validation cost: 0.18414144259901816 Validation accuracy: 35.74\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Cost:  0.18041440075118684 Train Accuracy: 37.00222222222222\n",
            "validation cost: 0.1838279112124068 Validation accuracy: 36.14\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Cost:  0.18010757372725875 Train Accuracy: 36.99111111111112\n",
            "validation cost: 0.18360816740930547 Validation accuracy: 35.839999999999996\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Cost:  0.17975047782795556 Train Accuracy: 37.20666666666666\n",
            "validation cost: 0.18320209256120673 Validation accuracy: 36.0\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Cost:  0.17941218128564765 Train Accuracy: 37.30222222222222\n",
            "validation cost: 0.18294618894239387 Validation accuracy: 36.34\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Cost:  0.17907653921289024 Train Accuracy: 37.29555555555555\n",
            "validation cost: 0.18263446138101735 Validation accuracy: 36.04\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Cost:  0.1787545579627482 Train Accuracy: 37.519999999999996\n",
            "validation cost: 0.18232540862271995 Validation accuracy: 36.32\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Cost:  0.1784288436095839 Train Accuracy: 37.67111111111111\n",
            "validation cost: 0.18201602488779095 Validation accuracy: 36.199999999999996\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Cost:  0.17814229855006844 Train Accuracy: 37.668888888888894\n",
            "validation cost: 0.18177390778440267 Validation accuracy: 36.16\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Cost:  0.17783941224611682 Train Accuracy: 37.70222222222222\n",
            "validation cost: 0.18151953924983172 Validation accuracy: 36.6\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Cost:  0.17757915435802102 Train Accuracy: 37.833333333333336\n",
            "validation cost: 0.1813058404515089 Validation accuracy: 36.52\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Cost:  0.1772730015499495 Train Accuracy: 38.004444444444445\n",
            "validation cost: 0.1810500816882092 Validation accuracy: 36.78\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Cost:  0.17696518645127912 Train Accuracy: 38.13777777777778\n",
            "validation cost: 0.18073889537820068 Validation accuracy: 36.58\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Cost:  0.17669155584358487 Train Accuracy: 38.20666666666666\n",
            "validation cost: 0.18048823989284932 Validation accuracy: 36.480000000000004\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Cost:  0.1764370964800639 Train Accuracy: 38.337777777777774\n",
            "validation cost: 0.18024196562187247 Validation accuracy: 36.88\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Cost:  0.17614886973670293 Train Accuracy: 38.42666666666666\n",
            "validation cost: 0.18000902692715626 Validation accuracy: 36.76\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Cost:  0.17592875454813944 Train Accuracy: 38.52888888888889\n",
            "validation cost: 0.1798205688189008 Validation accuracy: 36.74\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Cost:  0.1756379595683134 Train Accuracy: 38.61333333333333\n",
            "validation cost: 0.17959053461189822 Validation accuracy: 37.019999999999996\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Cost:  0.17541703460053992 Train Accuracy: 38.73777777777778\n",
            "validation cost: 0.17938391932142156 Validation accuracy: 36.84\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Cost:  0.17514322833279988 Train Accuracy: 38.806666666666665\n",
            "validation cost: 0.17914825058873976 Validation accuracy: 37.14\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Cost:  0.1749098398485251 Train Accuracy: 38.864444444444445\n",
            "validation cost: 0.17899947210863748 Validation accuracy: 36.919999999999995\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Cost:  0.17464023560396044 Train Accuracy: 39.019999999999996\n",
            "validation cost: 0.1787159108300277 Validation accuracy: 37.059999999999995\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Cost:  0.17446143193003705 Train Accuracy: 39.06222222222222\n",
            "validation cost: 0.1786340289713214 Validation accuracy: 37.16\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Cost:  0.17417907863980944 Train Accuracy: 39.08888888888889\n",
            "validation cost: 0.1783254666452085 Validation accuracy: 37.4\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Cost:  0.17395466544988009 Train Accuracy: 39.26\n",
            "validation cost: 0.17813773758636758 Validation accuracy: 37.1\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Cost:  0.17372355995671604 Train Accuracy: 39.342222222222226\n",
            "validation cost: 0.17793829171577036 Validation accuracy: 37.46\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Cost:  0.17349679681919544 Train Accuracy: 39.40222222222222\n",
            "validation cost: 0.17773433021323598 Validation accuracy: 37.66\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Cost:  0.17329747781182447 Train Accuracy: 39.53111111111111\n",
            "validation cost: 0.1775941352700847 Validation accuracy: 37.46\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Cost:  0.17315610207276935 Train Accuracy: 39.43333333333333\n",
            "validation cost: 0.17746863036064453 Validation accuracy: 37.54\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Cost:  0.1728794433550585 Train Accuracy: 39.635555555555555\n",
            "validation cost: 0.17722747292854002 Validation accuracy: 37.64\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Cost:  0.17270979456101673 Train Accuracy: 39.711111111111116\n",
            "validation cost: 0.17711914736805454 Validation accuracy: 37.74\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Cost:  0.17245063435727573 Train Accuracy: 39.733333333333334\n",
            "validation cost: 0.17686439413395885 Validation accuracy: 37.84\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "Cost:  0.17225774738387684 Train Accuracy: 39.81333333333333\n",
            "validation cost: 0.17671667429737992 Validation accuracy: 37.8\n",
            "Iteration: 157\n",
            "Iteration: 158\n",
            "Cost:  0.17201609168573492 Train Accuracy: 39.92444444444445\n",
            "validation cost: 0.17651322646363482 Validation accuracy: 37.76\n",
            "Iteration: 159\n",
            "Iteration: 160\n",
            "Cost:  0.1718234688492646 Train Accuracy: 39.94\n",
            "validation cost: 0.1763619652039485 Validation accuracy: 37.8\n",
            "Iteration: 161\n",
            "Iteration: 162\n",
            "Cost:  0.17164073551048928 Train Accuracy: 39.97555555555555\n",
            "validation cost: 0.1762105841285927 Validation accuracy: 37.8\n",
            "Iteration: 163\n",
            "Iteration: 164\n",
            "Cost:  0.1714441652547533 Train Accuracy: 40.12444444444444\n",
            "validation cost: 0.1760705837880515 Validation accuracy: 37.88\n",
            "Iteration: 165\n",
            "Iteration: 166\n",
            "Cost:  0.1712404979850334 Train Accuracy: 40.17777777777778\n",
            "validation cost: 0.17590615520348457 Validation accuracy: 37.86\n",
            "Iteration: 167\n",
            "Iteration: 168\n",
            "Cost:  0.17109729495933104 Train Accuracy: 40.32222222222222\n",
            "validation cost: 0.17573462190744638 Validation accuracy: 38.019999999999996\n",
            "Iteration: 169\n",
            "Iteration: 170\n",
            "Cost:  0.17086361963085775 Train Accuracy: 40.36222222222222\n",
            "validation cost: 0.1755848499040604 Validation accuracy: 37.940000000000005\n",
            "Iteration: 171\n",
            "Iteration: 172\n",
            "Cost:  0.17074294243964627 Train Accuracy: 40.404444444444444\n",
            "validation cost: 0.175479573757137 Validation accuracy: 38.36\n",
            "Iteration: 173\n",
            "Iteration: 174\n",
            "Cost:  0.1705070619280502 Train Accuracy: 40.42666666666667\n",
            "validation cost: 0.17527785899110143 Validation accuracy: 38.22\n",
            "Iteration: 175\n",
            "Iteration: 176\n",
            "Cost:  0.17034459958263948 Train Accuracy: 40.46444444444444\n",
            "validation cost: 0.17518093821834632 Validation accuracy: 38.2\n",
            "Iteration: 177\n",
            "Iteration: 178\n",
            "Cost:  0.17015927243201473 Train Accuracy: 40.571111111111115\n",
            "validation cost: 0.17504313290972323 Validation accuracy: 38.080000000000005\n",
            "Iteration: 179\n",
            "Iteration: 180\n",
            "Cost:  0.16996272160749062 Train Accuracy: 40.62888888888889\n",
            "validation cost: 0.17483130936564822 Validation accuracy: 38.06\n",
            "Iteration: 181\n",
            "Iteration: 182\n",
            "Cost:  0.16979241989052304 Train Accuracy: 40.65555555555556\n",
            "validation cost: 0.1747234740225634 Validation accuracy: 38.36\n",
            "Iteration: 183\n",
            "Iteration: 184\n",
            "Cost:  0.16966847042047367 Train Accuracy: 40.824444444444445\n",
            "validation cost: 0.1746488354181506 Validation accuracy: 38.22\n",
            "Iteration: 185\n",
            "Iteration: 186\n",
            "Cost:  0.16950228454149802 Train Accuracy: 40.904444444444444\n",
            "validation cost: 0.1744751568178388 Validation accuracy: 38.279999999999994\n",
            "Iteration: 187\n",
            "Iteration: 188\n",
            "Cost:  0.1693260767891012 Train Accuracy: 40.88444444444445\n",
            "validation cost: 0.17432320291849956 Validation accuracy: 38.1\n",
            "Iteration: 189\n",
            "Iteration: 190\n",
            "Cost:  0.16918838096271058 Train Accuracy: 40.83555555555556\n",
            "validation cost: 0.1742028368868373 Validation accuracy: 38.64\n",
            "Iteration: 191\n",
            "Iteration: 192\n",
            "Cost:  0.16897050788556603 Train Accuracy: 40.96\n",
            "validation cost: 0.1740562552899697 Validation accuracy: 38.54\n",
            "Iteration: 193\n",
            "Iteration: 194\n",
            "Cost:  0.16882266830007464 Train Accuracy: 40.99111111111111\n",
            "validation cost: 0.1739734842372797 Validation accuracy: 38.34\n",
            "Iteration: 195\n",
            "Iteration: 196\n",
            "Cost:  0.16863923393251445 Train Accuracy: 41.13111111111111\n",
            "validation cost: 0.17379098653765745 Validation accuracy: 38.5\n",
            "Iteration: 197\n",
            "Iteration: 198\n",
            "Cost:  0.1684663761607946 Train Accuracy: 41.16888888888889\n",
            "validation cost: 0.17365589056611272 Validation accuracy: 38.56\n",
            "Iteration: 199\n",
            "Iteration: 200\n",
            "Cost:  0.16834640831092004 Train Accuracy: 41.23555555555555\n",
            "validation cost: 0.17352000466635817 Validation accuracy: 38.82\n",
            "Iteration: 201\n",
            "Iteration: 202\n",
            "Cost:  0.1681537886289907 Train Accuracy: 41.32\n",
            "validation cost: 0.17335194212938423 Validation accuracy: 38.6\n",
            "Iteration: 203\n",
            "Iteration: 204\n",
            "Cost:  0.16800254662412756 Train Accuracy: 41.364444444444445\n",
            "validation cost: 0.1732520394872278 Validation accuracy: 38.62\n",
            "Iteration: 205\n",
            "Iteration: 206\n",
            "Cost:  0.16783705972278692 Train Accuracy: 41.45777777777778\n",
            "validation cost: 0.17312824917090966 Validation accuracy: 38.72\n",
            "Iteration: 207\n",
            "Iteration: 208\n",
            "Cost:  0.1677093102704901 Train Accuracy: 41.446666666666665\n",
            "validation cost: 0.1730199148320006 Validation accuracy: 38.84\n",
            "Iteration: 209\n",
            "Iteration: 210\n",
            "Cost:  0.1675903890037933 Train Accuracy: 41.464444444444446\n",
            "validation cost: 0.17290901564212902 Validation accuracy: 38.940000000000005\n",
            "Iteration: 211\n",
            "Iteration: 212\n",
            "Cost:  0.16743683000490542 Train Accuracy: 41.644444444444446\n",
            "validation cost: 0.17280904281940235 Validation accuracy: 38.879999999999995\n",
            "Iteration: 213\n",
            "Iteration: 214\n",
            "Cost:  0.16726122028616028 Train Accuracy: 41.71111111111111\n",
            "validation cost: 0.17267804353319788 Validation accuracy: 38.92\n",
            "Iteration: 215\n",
            "Iteration: 216\n",
            "Cost:  0.16713628393309757 Train Accuracy: 41.61555555555555\n",
            "validation cost: 0.17257709754058528 Validation accuracy: 39.08\n",
            "Iteration: 217\n",
            "Iteration: 218\n",
            "Cost:  0.16701211242176564 Train Accuracy: 41.68222222222222\n",
            "validation cost: 0.1725040187505979 Validation accuracy: 38.86\n",
            "Iteration: 219\n",
            "Iteration: 220\n",
            "Cost:  0.16684962641698434 Train Accuracy: 41.82222222222222\n",
            "validation cost: 0.17236446651713835 Validation accuracy: 39.06\n",
            "Iteration: 221\n",
            "Iteration: 222\n",
            "Cost:  0.16670609747937284 Train Accuracy: 41.86666666666667\n",
            "validation cost: 0.17220829032113408 Validation accuracy: 39.2\n",
            "Iteration: 223\n",
            "Iteration: 224\n",
            "Cost:  0.16654574981517567 Train Accuracy: 41.928888888888885\n",
            "validation cost: 0.17206813601404902 Validation accuracy: 39.300000000000004\n",
            "Iteration: 225\n",
            "Iteration: 226\n",
            "Cost:  0.16643056095913408 Train Accuracy: 42.00666666666667\n",
            "validation cost: 0.17201704688080957 Validation accuracy: 39.2\n",
            "Iteration: 227\n",
            "Iteration: 228\n",
            "Cost:  0.1662584813760923 Train Accuracy: 42.08444444444444\n",
            "validation cost: 0.17187080099614085 Validation accuracy: 39.22\n",
            "Iteration: 229\n",
            "Iteration: 230\n",
            "Cost:  0.16613254014999063 Train Accuracy: 41.98222222222222\n",
            "validation cost: 0.17180778914042702 Validation accuracy: 39.22\n",
            "Iteration: 231\n",
            "Iteration: 232\n",
            "Cost:  0.16604684965582744 Train Accuracy: 42.102222222222224\n",
            "validation cost: 0.17172010839285362 Validation accuracy: 39.56\n",
            "Iteration: 233\n",
            "Iteration: 234\n",
            "Cost:  0.16589259681250665 Train Accuracy: 42.09111111111111\n",
            "validation cost: 0.17161759684948763 Validation accuracy: 39.18\n",
            "Iteration: 235\n",
            "Iteration: 236\n",
            "Cost:  0.1657633147095335 Train Accuracy: 42.215555555555554\n",
            "validation cost: 0.17151236914206713 Validation accuracy: 39.4\n",
            "Iteration: 237\n",
            "Iteration: 238\n",
            "Cost:  0.1656327682182197 Train Accuracy: 42.27777777777778\n",
            "validation cost: 0.17137447471756762 Validation accuracy: 39.519999999999996\n",
            "Iteration: 239\n",
            "Iteration: 240\n",
            "Cost:  0.16545412234059903 Train Accuracy: 42.324444444444445\n",
            "validation cost: 0.17125101158080352 Validation accuracy: 39.46\n",
            "Iteration: 241\n",
            "Iteration: 242\n",
            "Cost:  0.16535438538585925 Train Accuracy: 42.38\n",
            "validation cost: 0.17117939997313922 Validation accuracy: 39.44\n",
            "Iteration: 243\n",
            "Iteration: 244\n",
            "Cost:  0.16521382633998227 Train Accuracy: 42.42\n",
            "validation cost: 0.1710677676487917 Validation accuracy: 39.379999999999995\n",
            "Iteration: 245\n",
            "Iteration: 246\n",
            "Cost:  0.16508965229720327 Train Accuracy: 42.49111111111111\n",
            "validation cost: 0.1709866246840307 Validation accuracy: 39.5\n",
            "Iteration: 247\n",
            "Iteration: 248\n",
            "Cost:  0.1649973896049572 Train Accuracy: 42.49333333333333\n",
            "validation cost: 0.1709029282808091 Validation accuracy: 39.34\n",
            "Iteration: 249\n",
            "Iteration: 250\n",
            "Cost:  0.16483989558914167 Train Accuracy: 42.53111111111111\n",
            "validation cost: 0.17079377436515847 Validation accuracy: 39.58\n",
            "Iteration: 251\n",
            "Iteration: 252\n",
            "Cost:  0.1647114372451004 Train Accuracy: 42.57333333333334\n",
            "validation cost: 0.17065265111676384 Validation accuracy: 39.519999999999996\n",
            "Iteration: 253\n",
            "Iteration: 254\n",
            "Cost:  0.16460858764687317 Train Accuracy: 42.53777777777778\n",
            "validation cost: 0.17060371976224598 Validation accuracy: 39.58\n",
            "Iteration: 255\n",
            "Iteration: 256\n",
            "Cost:  0.1644653638678969 Train Accuracy: 42.675555555555555\n",
            "validation cost: 0.17047759439670168 Validation accuracy: 39.7\n",
            "Iteration: 257\n",
            "Iteration: 258\n",
            "Cost:  0.16439080336008072 Train Accuracy: 42.77777777777778\n",
            "validation cost: 0.17042426954849493 Validation accuracy: 39.660000000000004\n",
            "Iteration: 259\n",
            "Iteration: 260\n",
            "Cost:  0.16421877362696616 Train Accuracy: 42.775555555555556\n",
            "validation cost: 0.17030633899081782 Validation accuracy: 39.82\n",
            "Iteration: 261\n",
            "Iteration: 262\n",
            "Cost:  0.1641269971145551 Train Accuracy: 42.74666666666667\n",
            "validation cost: 0.1702181082383943 Validation accuracy: 39.86\n",
            "Iteration: 263\n",
            "Iteration: 264\n",
            "Cost:  0.16399912543835166 Train Accuracy: 42.873333333333335\n",
            "validation cost: 0.17014338458795927 Validation accuracy: 40.02\n",
            "Iteration: 265\n",
            "Iteration: 266\n",
            "Cost:  0.1638648689584414 Train Accuracy: 42.873333333333335\n",
            "validation cost: 0.17004341280540536 Validation accuracy: 39.76\n",
            "Iteration: 267\n",
            "Iteration: 268\n",
            "Cost:  0.163866695333143 Train Accuracy: 42.87111111111111\n",
            "validation cost: 0.1701054027602188 Validation accuracy: 39.879999999999995\n",
            "Iteration: 269\n",
            "Iteration: 270\n",
            "Cost:  0.1636597030277745 Train Accuracy: 42.891111111111115\n",
            "validation cost: 0.16985761303899774 Validation accuracy: 39.839999999999996\n",
            "Iteration: 271\n",
            "Iteration: 272\n",
            "Cost:  0.16352940290638246 Train Accuracy: 43.07555555555555\n",
            "validation cost: 0.16978316492650752 Validation accuracy: 39.98\n",
            "Iteration: 273\n",
            "Iteration: 274\n",
            "Cost:  0.1634399959414138 Train Accuracy: 43.077777777777776\n",
            "validation cost: 0.16972049181394336 Validation accuracy: 39.94\n",
            "Iteration: 275\n",
            "Iteration: 276\n",
            "Cost:  0.16330135981940827 Train Accuracy: 43.086666666666666\n",
            "validation cost: 0.16961676637229986 Validation accuracy: 39.76\n",
            "Iteration: 277\n",
            "Iteration: 278\n",
            "Cost:  0.16318040802162648 Train Accuracy: 43.111111111111114\n",
            "validation cost: 0.16949828940605988 Validation accuracy: 40.0\n",
            "Iteration: 279\n",
            "Iteration: 280\n",
            "Cost:  0.16307560012341815 Train Accuracy: 43.135555555555555\n",
            "validation cost: 0.1694172431704291 Validation accuracy: 39.94\n",
            "Iteration: 281\n",
            "Iteration: 282\n",
            "Cost:  0.16299148731460103 Train Accuracy: 43.20444444444445\n",
            "validation cost: 0.1693333771065775 Validation accuracy: 40.06\n",
            "Iteration: 283\n",
            "Iteration: 284\n",
            "Cost:  0.16289915401728766 Train Accuracy: 43.27333333333333\n",
            "validation cost: 0.16925741464137659 Validation accuracy: 39.92\n",
            "Iteration: 285\n",
            "Iteration: 286\n",
            "Cost:  0.16277543692821803 Train Accuracy: 43.16888888888889\n",
            "validation cost: 0.16919137875241727 Validation accuracy: 39.879999999999995\n",
            "Iteration: 287\n",
            "Iteration: 288\n",
            "Cost:  0.16263616949999635 Train Accuracy: 43.34888888888889\n",
            "validation cost: 0.1690551869273046 Validation accuracy: 39.94\n",
            "Iteration: 289\n",
            "Iteration: 290\n",
            "Cost:  0.16252628488367027 Train Accuracy: 43.337777777777774\n",
            "validation cost: 0.16901768444472834 Validation accuracy: 40.08\n",
            "Iteration: 291\n",
            "Iteration: 292\n",
            "Cost:  0.16244898398747054 Train Accuracy: 43.382222222222225\n",
            "validation cost: 0.16890005927405047 Validation accuracy: 40.2\n",
            "Iteration: 293\n",
            "Iteration: 294\n",
            "Cost:  0.1623123071767597 Train Accuracy: 43.39333333333333\n",
            "validation cost: 0.1688397371519547 Validation accuracy: 40.02\n",
            "Iteration: 295\n",
            "Iteration: 296\n",
            "Cost:  0.16220183233006666 Train Accuracy: 43.522222222222226\n",
            "validation cost: 0.16874534141638342 Validation accuracy: 40.2\n",
            "Iteration: 297\n",
            "Iteration: 298\n",
            "Cost:  0.16210781692654327 Train Accuracy: 43.54222222222222\n",
            "validation cost: 0.16867925598406197 Validation accuracy: 40.1\n",
            "Iteration: 299\n",
            "Iteration: 300\n",
            "Cost:  0.1620508160735364 Train Accuracy: 43.46888888888889\n",
            "validation cost: 0.1686260425657188 Validation accuracy: 40.1\n",
            "Iteration: 301\n",
            "Iteration: 302\n",
            "Cost:  0.16192214963781396 Train Accuracy: 43.53111111111111\n",
            "validation cost: 0.16854383347184143 Validation accuracy: 40.18\n",
            "Iteration: 303\n",
            "Iteration: 304\n",
            "Cost:  0.1618429097877369 Train Accuracy: 43.70666666666666\n",
            "validation cost: 0.16850668115893774 Validation accuracy: 40.32\n",
            "Iteration: 305\n",
            "Iteration: 306\n",
            "Cost:  0.16170322306874588 Train Accuracy: 43.7\n",
            "validation cost: 0.16833281979564937 Validation accuracy: 40.26\n",
            "Iteration: 307\n",
            "Iteration: 308\n",
            "Cost:  0.16159803686716873 Train Accuracy: 43.73111111111111\n",
            "validation cost: 0.16824559102807657 Validation accuracy: 40.36\n",
            "Iteration: 309\n",
            "Iteration: 310\n",
            "Cost:  0.16150650258485158 Train Accuracy: 43.77777777777778\n",
            "validation cost: 0.16822206698129846 Validation accuracy: 40.26\n",
            "Iteration: 311\n",
            "Iteration: 312\n",
            "Cost:  0.1613944506595945 Train Accuracy: 43.717777777777776\n",
            "validation cost: 0.16809504181349655 Validation accuracy: 40.300000000000004\n",
            "Iteration: 313\n",
            "Iteration: 314\n",
            "Cost:  0.16132888560982084 Train Accuracy: 43.88444444444444\n",
            "validation cost: 0.16811167215472647 Validation accuracy: 40.36\n",
            "Iteration: 315\n",
            "Iteration: 316\n",
            "Cost:  0.16120306134387596 Train Accuracy: 43.91111111111111\n",
            "validation cost: 0.1679889020664984 Validation accuracy: 40.36\n",
            "Iteration: 317\n",
            "Iteration: 318\n",
            "Cost:  0.16110258208167783 Train Accuracy: 43.89555555555555\n",
            "validation cost: 0.16789769646420039 Validation accuracy: 40.26\n",
            "Iteration: 319\n",
            "Iteration: 320\n",
            "Cost:  0.1609925456610378 Train Accuracy: 43.91111111111111\n",
            "validation cost: 0.16780107146491213 Validation accuracy: 40.339999999999996\n",
            "Iteration: 321\n",
            "Iteration: 322\n",
            "Cost:  0.16092567953364667 Train Accuracy: 43.96666666666667\n",
            "validation cost: 0.1677856436711536 Validation accuracy: 40.18\n",
            "Iteration: 323\n",
            "Iteration: 324\n",
            "Cost:  0.16084644110119148 Train Accuracy: 44.035555555555554\n",
            "validation cost: 0.16773527783992032 Validation accuracy: 40.42\n",
            "Iteration: 325\n",
            "Iteration: 326\n",
            "Cost:  0.16073421452224892 Train Accuracy: 44.00222222222222\n",
            "validation cost: 0.1676074440718312 Validation accuracy: 40.400000000000006\n",
            "Iteration: 327\n",
            "Iteration: 328\n",
            "Cost:  0.16061418386362122 Train Accuracy: 44.10444444444445\n",
            "validation cost: 0.16755156308819696 Validation accuracy: 40.36\n",
            "Iteration: 329\n",
            "Iteration: 330\n",
            "Cost:  0.16056951151439694 Train Accuracy: 44.10666666666667\n",
            "validation cost: 0.1675044635645619 Validation accuracy: 40.52\n",
            "Iteration: 331\n",
            "Iteration: 332\n",
            "Cost:  0.16045666564732255 Train Accuracy: 44.20666666666666\n",
            "validation cost: 0.16746831483567087 Validation accuracy: 40.48\n",
            "Iteration: 333\n",
            "Iteration: 334\n",
            "Cost:  0.16035870563024743 Train Accuracy: 44.166666666666664\n",
            "validation cost: 0.16732382774654886 Validation accuracy: 40.44\n",
            "Iteration: 335\n",
            "Iteration: 336\n",
            "Cost:  0.16026851986773274 Train Accuracy: 44.25777777777778\n",
            "validation cost: 0.16729956595434375 Validation accuracy: 40.54\n",
            "Iteration: 337\n",
            "Iteration: 338\n",
            "Cost:  0.16015826559758997 Train Accuracy: 44.306666666666665\n",
            "validation cost: 0.1672096113877933 Validation accuracy: 40.48\n",
            "Iteration: 339\n",
            "Iteration: 340\n",
            "Cost:  0.1600769401575456 Train Accuracy: 44.306666666666665\n",
            "validation cost: 0.1671473328176053 Validation accuracy: 40.56\n",
            "Iteration: 341\n",
            "Iteration: 342\n",
            "Cost:  0.15999603261504658 Train Accuracy: 44.37111111111111\n",
            "validation cost: 0.16709744936653123 Validation accuracy: 40.58\n",
            "Iteration: 343\n",
            "Iteration: 344\n",
            "Cost:  0.15992009387899414 Train Accuracy: 44.32666666666666\n",
            "validation cost: 0.16700811666159676 Validation accuracy: 40.32\n",
            "Iteration: 345\n",
            "Iteration: 346\n",
            "Cost:  0.1598200634442736 Train Accuracy: 44.36\n",
            "validation cost: 0.16692891653796985 Validation accuracy: 40.339999999999996\n",
            "Iteration: 347\n",
            "Iteration: 348\n",
            "Cost:  0.15974137977547898 Train Accuracy: 44.41555555555556\n",
            "validation cost: 0.16683861234314853 Validation accuracy: 40.739999999999995\n",
            "Iteration: 349\n",
            "Iteration: 350\n",
            "Cost:  0.15960022114708997 Train Accuracy: 44.53111111111111\n",
            "validation cost: 0.16674880220265217 Validation accuracy: 40.739999999999995\n",
            "Iteration: 351\n",
            "Iteration: 352\n",
            "Cost:  0.15952409960993105 Train Accuracy: 44.51555555555556\n",
            "validation cost: 0.16670766651388977 Validation accuracy: 40.58\n",
            "Iteration: 353\n",
            "Iteration: 354\n",
            "Cost:  0.15944464401082634 Train Accuracy: 44.50666666666667\n",
            "validation cost: 0.1667012774565648 Validation accuracy: 40.44\n",
            "Iteration: 355\n",
            "Iteration: 356\n",
            "Cost:  0.15936846492624177 Train Accuracy: 44.61333333333333\n",
            "validation cost: 0.16661329835788857 Validation accuracy: 40.88\n",
            "Iteration: 357\n",
            "Iteration: 358\n",
            "Cost:  0.15926286208678916 Train Accuracy: 44.62888888888889\n",
            "validation cost: 0.16654982462488263 Validation accuracy: 40.62\n",
            "Iteration: 359\n",
            "Iteration: 360\n",
            "Cost:  0.15920000560045955 Train Accuracy: 44.68666666666667\n",
            "validation cost: 0.16647235547324504 Validation accuracy: 40.839999999999996\n",
            "Iteration: 361\n",
            "Iteration: 362\n",
            "Cost:  0.1591135763602789 Train Accuracy: 44.74\n",
            "validation cost: 0.1664387699264969 Validation accuracy: 40.6\n",
            "Iteration: 363\n",
            "Iteration: 364\n",
            "Cost:  0.1590005683153945 Train Accuracy: 44.71333333333333\n",
            "validation cost: 0.1663357866195215 Validation accuracy: 40.72\n",
            "Iteration: 365\n",
            "Iteration: 366\n",
            "Cost:  0.15891180866038263 Train Accuracy: 44.693333333333335\n",
            "validation cost: 0.16625532181104566 Validation accuracy: 40.62\n",
            "Iteration: 367\n",
            "Iteration: 368\n",
            "Cost:  0.15885721324278465 Train Accuracy: 44.72666666666667\n",
            "validation cost: 0.16622444223185162 Validation accuracy: 40.82\n",
            "Iteration: 369\n",
            "Iteration: 370\n",
            "Cost:  0.1587778010677695 Train Accuracy: 44.797777777777775\n",
            "validation cost: 0.16618984229590475 Validation accuracy: 40.760000000000005\n",
            "Iteration: 371\n",
            "Iteration: 372\n",
            "Cost:  0.15867482274763117 Train Accuracy: 44.79555555555555\n",
            "validation cost: 0.16607188414336546 Validation accuracy: 40.72\n",
            "Iteration: 373\n",
            "Iteration: 374\n",
            "Cost:  0.15857609216501686 Train Accuracy: 44.84666666666667\n",
            "validation cost: 0.1660285306596991 Validation accuracy: 41.06\n",
            "Iteration: 375\n",
            "Iteration: 376\n",
            "Cost:  0.15851980676847735 Train Accuracy: 44.873333333333335\n",
            "validation cost: 0.1659991336362717 Validation accuracy: 40.9\n",
            "Iteration: 377\n",
            "Iteration: 378\n",
            "Cost:  0.15844865394280333 Train Accuracy: 44.882222222222225\n",
            "validation cost: 0.16593104752797294 Validation accuracy: 40.98\n",
            "Iteration: 379\n",
            "Iteration: 380\n",
            "Cost:  0.15835047112687045 Train Accuracy: 44.971111111111114\n",
            "validation cost: 0.1658977508385014 Validation accuracy: 40.96\n",
            "Iteration: 381\n",
            "Iteration: 382\n",
            "Cost:  0.15829542004654235 Train Accuracy: 44.99333333333333\n",
            "validation cost: 0.16587292681982718 Validation accuracy: 40.82\n",
            "Iteration: 383\n",
            "Iteration: 384\n",
            "Cost:  0.15816404781141985 Train Accuracy: 45.01111111111111\n",
            "validation cost: 0.1656989030367332 Validation accuracy: 40.98\n",
            "Iteration: 385\n",
            "Iteration: 386\n",
            "Cost:  0.1580920789560469 Train Accuracy: 45.06444444444445\n",
            "validation cost: 0.16570036919887318 Validation accuracy: 41.02\n",
            "Iteration: 387\n",
            "Iteration: 388\n",
            "Cost:  0.1580049004513768 Train Accuracy: 45.06444444444445\n",
            "validation cost: 0.1655843606422728 Validation accuracy: 41.02\n",
            "Iteration: 389\n",
            "Iteration: 390\n",
            "Cost:  0.15793686233532198 Train Accuracy: 44.97555555555556\n",
            "validation cost: 0.16558070610490344 Validation accuracy: 41.120000000000005\n",
            "Iteration: 391\n",
            "Iteration: 392\n",
            "Cost:  0.15784835991909107 Train Accuracy: 45.193333333333335\n",
            "validation cost: 0.16550265109110818 Validation accuracy: 41.06\n",
            "Iteration: 393\n",
            "Iteration: 394\n",
            "Cost:  0.1577853714657946 Train Accuracy: 45.16222222222222\n",
            "validation cost: 0.16547116045973465 Validation accuracy: 41.08\n",
            "Iteration: 395\n",
            "Iteration: 396\n",
            "Cost:  0.1577119077117106 Train Accuracy: 45.19555555555556\n",
            "validation cost: 0.16542715357585708 Validation accuracy: 41.04\n",
            "Iteration: 397\n",
            "Iteration: 398\n",
            "Cost:  0.15760714872129925 Train Accuracy: 45.27333333333333\n",
            "validation cost: 0.1653064888647532 Validation accuracy: 41.24\n",
            "Iteration: 399\n",
            "Iteration: 400\n",
            "Cost:  0.15754674371411576 Train Accuracy: 45.248888888888885\n",
            "validation cost: 0.16529414178587 Validation accuracy: 41.02\n",
            "Iteration: 401\n",
            "Iteration: 402\n",
            "Cost:  0.15746351625541707 Train Accuracy: 45.24666666666667\n",
            "validation cost: 0.1652208973875341 Validation accuracy: 41.099999999999994\n",
            "Iteration: 403\n",
            "Iteration: 404\n",
            "Cost:  0.15739328168117206 Train Accuracy: 45.30888888888889\n",
            "validation cost: 0.16514409695324536 Validation accuracy: 41.3\n",
            "Iteration: 405\n",
            "Iteration: 406\n",
            "Cost:  0.157341079972017 Train Accuracy: 45.28\n",
            "validation cost: 0.165183152043636 Validation accuracy: 40.94\n",
            "Iteration: 407\n",
            "Iteration: 408\n",
            "Cost:  0.15723020960730594 Train Accuracy: 45.35777777777778\n",
            "validation cost: 0.16502468559690364 Validation accuracy: 41.160000000000004\n",
            "Iteration: 409\n",
            "Iteration: 410\n",
            "Cost:  0.15718471690348204 Train Accuracy: 45.25333333333334\n",
            "validation cost: 0.16504647077539844 Validation accuracy: 41.160000000000004\n",
            "Iteration: 411\n",
            "Iteration: 412\n",
            "Cost:  0.15710441317878515 Train Accuracy: 45.404444444444444\n",
            "validation cost: 0.1649456202065726 Validation accuracy: 41.3\n",
            "Iteration: 413\n",
            "Iteration: 414\n",
            "Cost:  0.1569829070569646 Train Accuracy: 45.413333333333334\n",
            "validation cost: 0.1648678398344314 Validation accuracy: 41.099999999999994\n",
            "Iteration: 415\n",
            "Iteration: 416\n",
            "Cost:  0.15692258467105155 Train Accuracy: 45.37555555555556\n",
            "validation cost: 0.16480653457449448 Validation accuracy: 41.160000000000004\n",
            "Iteration: 417\n",
            "Iteration: 418\n",
            "Cost:  0.15689093938347443 Train Accuracy: 45.51777777777778\n",
            "validation cost: 0.16478817575817728 Validation accuracy: 41.199999999999996\n",
            "Iteration: 419\n",
            "Iteration: 420\n",
            "Cost:  0.1567899680976278 Train Accuracy: 45.464444444444446\n",
            "validation cost: 0.16475095036005394 Validation accuracy: 41.14\n",
            "Iteration: 421\n",
            "Iteration: 422\n",
            "Cost:  0.156700689383637 Train Accuracy: 45.52888888888889\n",
            "validation cost: 0.16466596089516822 Validation accuracy: 41.32\n",
            "Iteration: 423\n",
            "Iteration: 424\n",
            "Cost:  0.15664847381257285 Train Accuracy: 45.55111111111111\n",
            "validation cost: 0.1645986514791612 Validation accuracy: 41.339999999999996\n",
            "Iteration: 425\n",
            "Iteration: 426\n",
            "Cost:  0.1565621364471141 Train Accuracy: 45.61777777777778\n",
            "validation cost: 0.16457430109099264 Validation accuracy: 41.4\n",
            "Iteration: 427\n",
            "Iteration: 428\n",
            "Cost:  0.15650838402141018 Train Accuracy: 45.64222222222222\n",
            "validation cost: 0.16454691624026782 Validation accuracy: 41.339999999999996\n",
            "Iteration: 429\n",
            "Iteration: 430\n",
            "Cost:  0.15642031098672013 Train Accuracy: 45.608888888888885\n",
            "validation cost: 0.16443379274018582 Validation accuracy: 41.32\n",
            "Iteration: 431\n",
            "Iteration: 432\n",
            "Cost:  0.15633126919793155 Train Accuracy: 45.61555555555555\n",
            "validation cost: 0.1643785563628454 Validation accuracy: 41.46\n",
            "Iteration: 433\n",
            "Iteration: 434\n",
            "Cost:  0.1562616350219525 Train Accuracy: 45.742222222222225\n",
            "validation cost: 0.16432456036634577 Validation accuracy: 41.52\n",
            "Iteration: 435\n",
            "Iteration: 436\n",
            "Cost:  0.15622109645755747 Train Accuracy: 45.67333333333333\n",
            "validation cost: 0.16436451188074058 Validation accuracy: 41.68\n",
            "Iteration: 437\n",
            "Iteration: 438\n",
            "Cost:  0.15613050888747818 Train Accuracy: 45.61555555555555\n",
            "validation cost: 0.16428242990036243 Validation accuracy: 41.339999999999996\n",
            "Iteration: 439\n",
            "Iteration: 440\n",
            "Cost:  0.15607356578323522 Train Accuracy: 45.73111111111111\n",
            "validation cost: 0.16419697996805674 Validation accuracy: 41.5\n",
            "Iteration: 441\n",
            "Iteration: 442\n",
            "Cost:  0.1559741099830293 Train Accuracy: 45.76888888888889\n",
            "validation cost: 0.16412543593022746 Validation accuracy: 41.32\n",
            "Iteration: 443\n",
            "Iteration: 444\n",
            "Cost:  0.156002925764027 Train Accuracy: 45.74444444444444\n",
            "validation cost: 0.16420033235368683 Validation accuracy: 41.660000000000004\n",
            "Iteration: 445\n",
            "Iteration: 446\n",
            "Cost:  0.1558801319563714 Train Accuracy: 45.784444444444446\n",
            "validation cost: 0.16407860637331576 Validation accuracy: 41.54\n",
            "Iteration: 447\n",
            "Iteration: 448\n",
            "Cost:  0.15578606458468913 Train Accuracy: 45.873333333333335\n",
            "validation cost: 0.16397445291708293 Validation accuracy: 41.58\n",
            "Iteration: 449\n",
            "Iteration: 450\n",
            "Cost:  0.15571922729763357 Train Accuracy: 45.931111111111115\n",
            "validation cost: 0.16393395255454954 Validation accuracy: 41.48\n",
            "Iteration: 451\n",
            "Iteration: 452\n",
            "Cost:  0.15563611599467786 Train Accuracy: 45.85333333333333\n",
            "validation cost: 0.16388301299614907 Validation accuracy: 41.6\n",
            "Iteration: 453\n",
            "Iteration: 454\n",
            "Cost:  0.15558412140011632 Train Accuracy: 45.85777777777778\n",
            "validation cost: 0.16386049332485894 Validation accuracy: 41.64\n",
            "Iteration: 455\n",
            "Iteration: 456\n",
            "Cost:  0.15555194238471276 Train Accuracy: 45.84666666666667\n",
            "validation cost: 0.1638178211125431 Validation accuracy: 41.760000000000005\n",
            "Iteration: 457\n",
            "Iteration: 458\n",
            "Cost:  0.155414060736928 Train Accuracy: 46.01111111111111\n",
            "validation cost: 0.16372611879549379 Validation accuracy: 41.64\n",
            "Iteration: 459\n",
            "Iteration: 460\n",
            "Cost:  0.15535475154498912 Train Accuracy: 45.995555555555555\n",
            "validation cost: 0.16367330222598744 Validation accuracy: 41.54\n",
            "Iteration: 461\n",
            "Iteration: 462\n",
            "Cost:  0.15532884557150722 Train Accuracy: 46.02222222222222\n",
            "validation cost: 0.1637105082272186 Validation accuracy: 41.74\n",
            "Iteration: 463\n",
            "Iteration: 464\n",
            "Cost:  0.15521566144148916 Train Accuracy: 46.06444444444445\n",
            "validation cost: 0.16356878671136751 Validation accuracy: 41.58\n",
            "Iteration: 465\n",
            "Iteration: 466\n",
            "Cost:  0.15517345384531608 Train Accuracy: 46.01777777777778\n",
            "validation cost: 0.16356820121675864 Validation accuracy: 41.78\n",
            "Iteration: 467\n",
            "Iteration: 468\n",
            "Cost:  0.15508516149081875 Train Accuracy: 46.135555555555555\n",
            "validation cost: 0.16350600694989534 Validation accuracy: 41.78\n",
            "Iteration: 469\n",
            "Iteration: 470\n",
            "Cost:  0.15500090811187994 Train Accuracy: 46.18222222222222\n",
            "validation cost: 0.1634313328091474 Validation accuracy: 41.92\n",
            "Iteration: 471\n",
            "Iteration: 472\n",
            "Cost:  0.1549457107317894 Train Accuracy: 46.111111111111114\n",
            "validation cost: 0.16337377686156596 Validation accuracy: 41.839999999999996\n",
            "Iteration: 473\n",
            "Iteration: 474\n",
            "Cost:  0.15488519443131077 Train Accuracy: 46.10666666666667\n",
            "validation cost: 0.16336071261233115 Validation accuracy: 41.92\n",
            "Iteration: 475\n",
            "Iteration: 476\n",
            "Cost:  0.15479665434272818 Train Accuracy: 46.22\n",
            "validation cost: 0.16327205017958427 Validation accuracy: 41.86\n",
            "Iteration: 477\n",
            "Iteration: 478\n",
            "Cost:  0.15474977577555035 Train Accuracy: 46.224444444444444\n",
            "validation cost: 0.16325857477351965 Validation accuracy: 41.980000000000004\n",
            "Iteration: 479\n",
            "Iteration: 480\n",
            "Cost:  0.1547061212954358 Train Accuracy: 46.26888888888889\n",
            "validation cost: 0.16316965826501964 Validation accuracy: 41.8\n",
            "Iteration: 481\n",
            "Iteration: 482\n",
            "Cost:  0.1546336062689732 Train Accuracy: 46.28666666666666\n",
            "validation cost: 0.16311940980186912 Validation accuracy: 41.839999999999996\n",
            "Iteration: 483\n",
            "Iteration: 484\n",
            "Cost:  0.1545359512793145 Train Accuracy: 46.28888888888889\n",
            "validation cost: 0.16308849022824706 Validation accuracy: 41.92\n",
            "Iteration: 485\n",
            "Iteration: 486\n",
            "Cost:  0.1544759628704648 Train Accuracy: 46.35333333333334\n",
            "validation cost: 0.16302774564135808 Validation accuracy: 41.86\n",
            "Iteration: 487\n",
            "Iteration: 488\n",
            "Cost:  0.15441222909738908 Train Accuracy: 46.33555555555556\n",
            "validation cost: 0.16300600703470855 Validation accuracy: 41.980000000000004\n",
            "Iteration: 489\n",
            "Iteration: 490\n",
            "Cost:  0.15434907740279144 Train Accuracy: 46.32888888888888\n",
            "validation cost: 0.16292709947474684 Validation accuracy: 41.86\n",
            "Iteration: 491\n",
            "Iteration: 492\n",
            "Cost:  0.15427844541123253 Train Accuracy: 46.39555555555555\n",
            "validation cost: 0.1628925124191145 Validation accuracy: 41.980000000000004\n",
            "Iteration: 493\n",
            "Iteration: 494\n",
            "Cost:  0.154225069503308 Train Accuracy: 46.39111111111111\n",
            "validation cost: 0.16286772660204155 Validation accuracy: 42.18\n",
            "Iteration: 495\n",
            "Iteration: 496\n",
            "Cost:  0.15417457264580092 Train Accuracy: 46.406666666666666\n",
            "validation cost: 0.1627946451532083 Validation accuracy: 42.120000000000005\n",
            "Iteration: 497\n",
            "Iteration: 498\n",
            "Cost:  0.15410372366250777 Train Accuracy: 46.44222222222222\n",
            "validation cost: 0.1627528710308138 Validation accuracy: 41.86\n",
            "Iteration: 499\n"
          ]
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "mlp_512.fit_btch(lr=0.01, nitr= 500, alpha=0, beta=0, tol=5, epsilon=1e-5)\n",
        "t2 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U5NsqG7xU6KT"
      },
      "outputs": [],
      "source": [
        "mlp_512_perf = {'test_perf': mlp_512.evaluate_acc(x_test_vector, test_y), 'train_time': t2-t1,\n",
        "            'train_cost': mlp_512.costs, 'val_cost': mlp_512.val_costs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VoQDt-zpU6KU"
      },
      "outputs": [],
      "source": [
        "with open('mlp_512.pickle', 'wb') as h:\n",
        "    pickle.dump(mlp_512_perf, h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_jrcyQxSU6KV"
      },
      "outputs": [],
      "source": [
        "# get the folder id where you want to save your file\n",
        "file = drive.CreateFile()\n",
        "file.SetContentFile('mlp_512.pickle')\n",
        "file.Upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VNMRV4SOVvN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use pytorch and GPU to create and train two MLP models:\n",
        "\n",
        "\n",
        "*   One with 2 256 layers and no momentum to validate our custome model\n",
        "*   another with 1024 512 layers and momentum\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KSNPs874cBjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(inp_dim, 256),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(256, 256),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(256, 10),\n",
        "    torch.nn.Softmax()\n",
        ")"
      ],
      "metadata": {
        "id": "afMHuhqMqvrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "GZSnmjh8cAJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_torch = TrainSet(x_train_vector, y_train)\n",
        "train_dat = DataLoader(train_set_torch, batch_size=256, shuffle=True)\n"
      ],
      "metadata": {
        "id": "OhwgUUTx-NgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dvc= torch.device('cuda')\n",
        "model.to(dvc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzA4IVJZ-oAh",
        "outputId": "0c3f3ffc-0699-42a9-8a1a-9a3ade115f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=3072, out_features=256, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (5): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "loss_ls = []\n",
        "\n",
        "start_time= time.time()\n",
        "for epoch in range(500):  # loop over the dataset multiple times\n",
        "\n",
        "    print(f'Epoch: {epoch}')\n",
        "\n",
        "    for ind, data in enumerate(train_dat):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        x, y = data        \n",
        "        x = x.to(dvc)\n",
        "        y = y.to(dvc)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model.forward(x.to(torch.float32))\n",
        "        loss_val = loss_fn(outputs, y.reshape(-1))\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "        # print statistics\n",
        "\n",
        "    # set iteration time\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "            \n",
        "    # calculate accuracy\n",
        "    with torch.no_grad():\n",
        "        val_pred = model.forward(torch.tensor(x_val_vector).to(torch.float32).to(dvc))\n",
        "        val_los = loss_fn(val_pred, torch.tensor(y_val.reshape(-1)).to(dvc))\n",
        "        val_pred_clas = torch.argmax(val_pred, axis=1)\n",
        "        val_pred_clas = val_pred_clas.detach().cpu().numpy()\n",
        "\n",
        "        val_ac = 100 * np.mean(val_pred_clas.reshape(-1) == y_val.reshape(-1))\n",
        "    loss_ls.append(val_los.item())\n",
        "    \n",
        "    print(f'Accuracy and loss of the network on validations set: {val_ac, val_los.item()}')\n",
        "    \n"
      ],
      "metadata": {
        "id": "CXwImj0ecAx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f15b93-c84f-4bb6-83a0-a4aaf78fe4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy and loss of the network on validations set: (11.62, 2.301917314529419)\n",
            "Epoch: 1\n",
            "Accuracy and loss of the network on validations set: (13.44, 2.3014914989471436)\n",
            "Epoch: 2\n",
            "Accuracy and loss of the network on validations set: (14.92, 2.3010494709014893)\n",
            "Epoch: 3\n",
            "Accuracy and loss of the network on validations set: (13.62, 2.3005895614624023)\n",
            "Epoch: 4\n",
            "Accuracy and loss of the network on validations set: (11.62, 2.3001134395599365)\n",
            "Epoch: 5\n",
            "Accuracy and loss of the network on validations set: (10.5, 2.299605369567871)\n",
            "Epoch: 6\n",
            "Accuracy and loss of the network on validations set: (10.040000000000001, 2.299044132232666)\n",
            "Epoch: 7\n",
            "Accuracy and loss of the network on validations set: (10.0, 2.29842209815979)\n",
            "Epoch: 8\n",
            "Accuracy and loss of the network on validations set: (9.94, 2.29773211479187)\n",
            "Epoch: 9\n",
            "Accuracy and loss of the network on validations set: (9.94, 2.2969582080841064)\n",
            "Epoch: 10\n",
            "Accuracy and loss of the network on validations set: (10.02, 2.2960898876190186)\n",
            "Epoch: 11\n",
            "Accuracy and loss of the network on validations set: (10.0, 2.295135736465454)\n",
            "Epoch: 12\n",
            "Accuracy and loss of the network on validations set: (9.98, 2.294102430343628)\n",
            "Epoch: 13\n",
            "Accuracy and loss of the network on validations set: (9.98, 2.293022394180298)\n",
            "Epoch: 14\n",
            "Accuracy and loss of the network on validations set: (10.0, 2.2919280529022217)\n",
            "Epoch: 15\n",
            "Accuracy and loss of the network on validations set: (10.02, 2.2908337116241455)\n",
            "Epoch: 16\n",
            "Accuracy and loss of the network on validations set: (10.02, 2.2897307872772217)\n",
            "Epoch: 17\n",
            "Accuracy and loss of the network on validations set: (10.0, 2.2885823249816895)\n",
            "Epoch: 18\n",
            "Accuracy and loss of the network on validations set: (9.98, 2.2873663902282715)\n",
            "Epoch: 19\n",
            "Accuracy and loss of the network on validations set: (10.0, 2.2860474586486816)\n",
            "Epoch: 20\n",
            "Accuracy and loss of the network on validations set: (10.08, 2.284630298614502)\n",
            "Epoch: 21\n",
            "Accuracy and loss of the network on validations set: (10.52, 2.2830896377563477)\n",
            "Epoch: 22\n",
            "Accuracy and loss of the network on validations set: (10.94, 2.2814083099365234)\n",
            "Epoch: 23\n",
            "Accuracy and loss of the network on validations set: (11.82, 2.279583215713501)\n",
            "Epoch: 24\n",
            "Accuracy and loss of the network on validations set: (13.0, 2.2776119709014893)\n",
            "Epoch: 25\n",
            "Accuracy and loss of the network on validations set: (13.76, 2.275512218475342)\n",
            "Epoch: 26\n",
            "Accuracy and loss of the network on validations set: (14.2, 2.2732856273651123)\n",
            "Epoch: 27\n",
            "Accuracy and loss of the network on validations set: (15.06, 2.2708966732025146)\n",
            "Epoch: 28\n",
            "Accuracy and loss of the network on validations set: (16.0, 2.2684051990509033)\n",
            "Epoch: 29\n",
            "Accuracy and loss of the network on validations set: (16.54, 2.265765428543091)\n",
            "Epoch: 30\n",
            "Accuracy and loss of the network on validations set: (16.939999999999998, 2.2630434036254883)\n",
            "Epoch: 31\n",
            "Accuracy and loss of the network on validations set: (17.54, 2.260152816772461)\n",
            "Epoch: 32\n",
            "Accuracy and loss of the network on validations set: (18.459999999999997, 2.2571916580200195)\n",
            "Epoch: 33\n",
            "Accuracy and loss of the network on validations set: (19.259999999999998, 2.254051446914673)\n",
            "Epoch: 34\n",
            "Accuracy and loss of the network on validations set: (19.96, 2.25081729888916)\n",
            "Epoch: 35\n",
            "Accuracy and loss of the network on validations set: (20.54, 2.24749755859375)\n",
            "Epoch: 36\n",
            "Accuracy and loss of the network on validations set: (21.38, 2.243992328643799)\n",
            "Epoch: 37\n",
            "Accuracy and loss of the network on validations set: (21.94, 2.2404959201812744)\n",
            "Epoch: 38\n",
            "Accuracy and loss of the network on validations set: (22.68, 2.2369797229766846)\n",
            "Epoch: 39\n",
            "Accuracy and loss of the network on validations set: (22.62, 2.233647584915161)\n",
            "Epoch: 40\n",
            "Accuracy and loss of the network on validations set: (22.82, 2.2303738594055176)\n",
            "Epoch: 41\n",
            "Accuracy and loss of the network on validations set: (22.86, 2.2272932529449463)\n",
            "Epoch: 42\n",
            "Accuracy and loss of the network on validations set: (23.119999999999997, 2.224461317062378)\n",
            "Epoch: 43\n",
            "Accuracy and loss of the network on validations set: (23.16, 2.221538782119751)\n",
            "Epoch: 44\n",
            "Accuracy and loss of the network on validations set: (23.28, 2.2188613414764404)\n",
            "Epoch: 45\n",
            "Accuracy and loss of the network on validations set: (23.599999999999998, 2.2163829803466797)\n",
            "Epoch: 46\n",
            "Accuracy and loss of the network on validations set: (23.84, 2.2139313220977783)\n",
            "Epoch: 47\n",
            "Accuracy and loss of the network on validations set: (23.919999999999998, 2.2117228507995605)\n",
            "Epoch: 48\n",
            "Accuracy and loss of the network on validations set: (24.26, 2.2095344066619873)\n",
            "Epoch: 49\n",
            "Accuracy and loss of the network on validations set: (24.3, 2.2075142860412598)\n",
            "Epoch: 50\n",
            "Accuracy and loss of the network on validations set: (24.66, 2.2054288387298584)\n",
            "Epoch: 51\n",
            "Accuracy and loss of the network on validations set: (24.84, 2.2035627365112305)\n",
            "Epoch: 52\n",
            "Accuracy and loss of the network on validations set: (25.14, 2.201809883117676)\n",
            "Epoch: 53\n",
            "Accuracy and loss of the network on validations set: (25.419999999999998, 2.2002787590026855)\n",
            "Epoch: 54\n",
            "Accuracy and loss of the network on validations set: (26.179999999999996, 2.1984684467315674)\n",
            "Epoch: 55\n",
            "Accuracy and loss of the network on validations set: (26.36, 2.1969761848449707)\n",
            "Epoch: 56\n",
            "Accuracy and loss of the network on validations set: (26.400000000000002, 2.195693254470825)\n",
            "Epoch: 57\n",
            "Accuracy and loss of the network on validations set: (26.76, 2.1941564083099365)\n",
            "Epoch: 58\n",
            "Accuracy and loss of the network on validations set: (26.779999999999998, 2.1927847862243652)\n",
            "Epoch: 59\n",
            "Accuracy and loss of the network on validations set: (26.86, 2.1914243698120117)\n",
            "Epoch: 60\n",
            "Accuracy and loss of the network on validations set: (26.900000000000002, 2.1902480125427246)\n",
            "Epoch: 61\n",
            "Accuracy and loss of the network on validations set: (27.12, 2.1890885829925537)\n",
            "Epoch: 62\n",
            "Accuracy and loss of the network on validations set: (26.96, 2.18803334236145)\n",
            "Epoch: 63\n",
            "Accuracy and loss of the network on validations set: (27.1, 2.186957836151123)\n",
            "Epoch: 64\n",
            "Accuracy and loss of the network on validations set: (27.38, 2.1859264373779297)\n",
            "Epoch: 65\n",
            "Accuracy and loss of the network on validations set: (27.0, 2.1851816177368164)\n",
            "Epoch: 66\n",
            "Accuracy and loss of the network on validations set: (27.26, 2.1843531131744385)\n",
            "Epoch: 67\n",
            "Accuracy and loss of the network on validations set: (27.279999999999998, 2.1832244396209717)\n",
            "Epoch: 68\n",
            "Accuracy and loss of the network on validations set: (27.54, 2.182483434677124)\n",
            "Epoch: 69\n",
            "Accuracy and loss of the network on validations set: (27.58, 2.1816108226776123)\n",
            "Epoch: 70\n",
            "Accuracy and loss of the network on validations set: (27.52, 2.180647134780884)\n",
            "Epoch: 71\n",
            "Accuracy and loss of the network on validations set: (27.46, 2.1802940368652344)\n",
            "Epoch: 72\n",
            "Accuracy and loss of the network on validations set: (27.62, 2.179198741912842)\n",
            "Epoch: 73\n",
            "Accuracy and loss of the network on validations set: (27.839999999999996, 2.178507089614868)\n",
            "Epoch: 74\n",
            "Accuracy and loss of the network on validations set: (27.76, 2.177927255630493)\n",
            "Epoch: 75\n",
            "Accuracy and loss of the network on validations set: (27.860000000000003, 2.1771092414855957)\n",
            "Epoch: 76\n",
            "Accuracy and loss of the network on validations set: (28.04, 2.1764373779296875)\n",
            "Epoch: 77\n",
            "Accuracy and loss of the network on validations set: (28.1, 2.175795078277588)\n",
            "Epoch: 78\n",
            "Accuracy and loss of the network on validations set: (28.08, 2.1751418113708496)\n",
            "Epoch: 79\n",
            "Accuracy and loss of the network on validations set: (28.02, 2.1745619773864746)\n",
            "Epoch: 80\n",
            "Accuracy and loss of the network on validations set: (28.08, 2.173973321914673)\n",
            "Epoch: 81\n",
            "Accuracy and loss of the network on validations set: (28.499999999999996, 2.1732563972473145)\n",
            "Epoch: 82\n",
            "Accuracy and loss of the network on validations set: (28.439999999999998, 2.172638177871704)\n",
            "Epoch: 83\n",
            "Accuracy and loss of the network on validations set: (28.58, 2.172109842300415)\n",
            "Epoch: 84\n",
            "Accuracy and loss of the network on validations set: (28.62, 2.171471118927002)\n",
            "Epoch: 85\n",
            "Accuracy and loss of the network on validations set: (28.9, 2.1710329055786133)\n",
            "Epoch: 86\n",
            "Accuracy and loss of the network on validations set: (28.499999999999996, 2.1704418659210205)\n",
            "Epoch: 87\n",
            "Accuracy and loss of the network on validations set: (28.599999999999998, 2.170032024383545)\n",
            "Epoch: 88\n",
            "Accuracy and loss of the network on validations set: (28.76, 2.1693849563598633)\n",
            "Epoch: 89\n",
            "Accuracy and loss of the network on validations set: (28.9, 2.169020175933838)\n",
            "Epoch: 90\n",
            "Accuracy and loss of the network on validations set: (28.560000000000002, 2.1683809757232666)\n",
            "Epoch: 91\n",
            "Accuracy and loss of the network on validations set: (28.62, 2.1677651405334473)\n",
            "Epoch: 92\n",
            "Accuracy and loss of the network on validations set: (28.84, 2.1672356128692627)\n",
            "Epoch: 93\n",
            "Accuracy and loss of the network on validations set: (28.78, 2.1667630672454834)\n",
            "Epoch: 94\n",
            "Accuracy and loss of the network on validations set: (28.939999999999998, 2.1663413047790527)\n",
            "Epoch: 95\n",
            "Accuracy and loss of the network on validations set: (29.060000000000002, 2.1657397747039795)\n",
            "Epoch: 96\n",
            "Accuracy and loss of the network on validations set: (28.999999999999996, 2.1654090881347656)\n",
            "Epoch: 97\n",
            "Accuracy and loss of the network on validations set: (29.04, 2.1649434566497803)\n",
            "Epoch: 98\n",
            "Accuracy and loss of the network on validations set: (29.12, 2.1642775535583496)\n",
            "Epoch: 99\n",
            "Accuracy and loss of the network on validations set: (29.18, 2.16389799118042)\n",
            "Epoch: 100\n",
            "Accuracy and loss of the network on validations set: (29.48, 2.1633660793304443)\n",
            "Epoch: 101\n",
            "Accuracy and loss of the network on validations set: (29.42, 2.1627371311187744)\n",
            "Epoch: 102\n",
            "Accuracy and loss of the network on validations set: (29.34, 2.162329912185669)\n",
            "Epoch: 103\n",
            "Accuracy and loss of the network on validations set: (29.54, 2.1617934703826904)\n",
            "Epoch: 104\n",
            "Accuracy and loss of the network on validations set: (29.599999999999998, 2.1615967750549316)\n",
            "Epoch: 105\n",
            "Accuracy and loss of the network on validations set: (29.5, 2.1607584953308105)\n",
            "Epoch: 106\n",
            "Accuracy and loss of the network on validations set: (29.54, 2.1603448390960693)\n",
            "Epoch: 107\n",
            "Accuracy and loss of the network on validations set: (29.580000000000002, 2.159742832183838)\n",
            "Epoch: 108\n",
            "Accuracy and loss of the network on validations set: (29.580000000000002, 2.159221649169922)\n",
            "Epoch: 109\n",
            "Accuracy and loss of the network on validations set: (29.759999999999998, 2.1587741374969482)\n",
            "Epoch: 110\n",
            "Accuracy and loss of the network on validations set: (29.82, 2.1584057807922363)\n",
            "Epoch: 111\n",
            "Accuracy and loss of the network on validations set: (29.64, 2.1577494144439697)\n",
            "Epoch: 112\n",
            "Accuracy and loss of the network on validations set: (29.86, 2.1571853160858154)\n",
            "Epoch: 113\n",
            "Accuracy and loss of the network on validations set: (29.78, 2.1566171646118164)\n",
            "Epoch: 114\n",
            "Accuracy and loss of the network on validations set: (29.82, 2.1560795307159424)\n",
            "Epoch: 115\n",
            "Accuracy and loss of the network on validations set: (29.82, 2.155487537384033)\n",
            "Epoch: 116\n",
            "Accuracy and loss of the network on validations set: (29.959999999999997, 2.1551144123077393)\n",
            "Epoch: 117\n",
            "Accuracy and loss of the network on validations set: (29.880000000000003, 2.154430866241455)\n",
            "Epoch: 118\n",
            "Accuracy and loss of the network on validations set: (29.78, 2.154085636138916)\n",
            "Epoch: 119\n",
            "Accuracy and loss of the network on validations set: (30.06, 2.153634548187256)\n",
            "Epoch: 120\n",
            "Accuracy and loss of the network on validations set: (30.04, 2.152812957763672)\n",
            "Epoch: 121\n",
            "Accuracy and loss of the network on validations set: (29.94, 2.1524879932403564)\n",
            "Epoch: 122\n",
            "Accuracy and loss of the network on validations set: (30.259999999999998, 2.151757001876831)\n",
            "Epoch: 123\n",
            "Accuracy and loss of the network on validations set: (29.880000000000003, 2.1512978076934814)\n",
            "Epoch: 124\n",
            "Accuracy and loss of the network on validations set: (30.159999999999997, 2.150745391845703)\n",
            "Epoch: 125\n",
            "Accuracy and loss of the network on validations set: (30.2, 2.1499884128570557)\n",
            "Epoch: 126\n",
            "Accuracy and loss of the network on validations set: (30.320000000000004, 2.1496047973632812)\n",
            "Epoch: 127\n",
            "Accuracy and loss of the network on validations set: (30.34, 2.1490375995635986)\n",
            "Epoch: 128\n",
            "Accuracy and loss of the network on validations set: (30.48, 2.1482627391815186)\n",
            "Epoch: 129\n",
            "Accuracy and loss of the network on validations set: (30.54, 2.1476645469665527)\n",
            "Epoch: 130\n",
            "Accuracy and loss of the network on validations set: (30.740000000000002, 2.147152900695801)\n",
            "Epoch: 131\n",
            "Accuracy and loss of the network on validations set: (30.54, 2.1465015411376953)\n",
            "Epoch: 132\n",
            "Accuracy and loss of the network on validations set: (30.8, 2.1458489894866943)\n",
            "Epoch: 133\n",
            "Accuracy and loss of the network on validations set: (30.919999999999998, 2.1452794075012207)\n",
            "Epoch: 134\n",
            "Accuracy and loss of the network on validations set: (30.98, 2.1450064182281494)\n",
            "Epoch: 135\n",
            "Accuracy and loss of the network on validations set: (30.94, 2.144056558609009)\n",
            "Epoch: 136\n",
            "Accuracy and loss of the network on validations set: (31.240000000000002, 2.1435840129852295)\n",
            "Epoch: 137\n",
            "Accuracy and loss of the network on validations set: (31.34, 2.142637014389038)\n",
            "Epoch: 138\n",
            "Accuracy and loss of the network on validations set: (31.52, 2.1423983573913574)\n",
            "Epoch: 139\n",
            "Accuracy and loss of the network on validations set: (31.44, 2.1415045261383057)\n",
            "Epoch: 140\n",
            "Accuracy and loss of the network on validations set: (31.759999999999998, 2.1409285068511963)\n",
            "Epoch: 141\n",
            "Accuracy and loss of the network on validations set: (31.72, 2.1402671337127686)\n",
            "Epoch: 142\n",
            "Accuracy and loss of the network on validations set: (31.7, 2.1393842697143555)\n",
            "Epoch: 143\n",
            "Accuracy and loss of the network on validations set: (31.819999999999997, 2.1391289234161377)\n",
            "Epoch: 144\n",
            "Accuracy and loss of the network on validations set: (31.8, 2.137944459915161)\n",
            "Epoch: 145\n",
            "Accuracy and loss of the network on validations set: (31.979999999999997, 2.1371817588806152)\n",
            "Epoch: 146\n",
            "Accuracy and loss of the network on validations set: (32.16, 2.1366372108459473)\n",
            "Epoch: 147\n",
            "Accuracy and loss of the network on validations set: (32.440000000000005, 2.135976552963257)\n",
            "Epoch: 148\n",
            "Accuracy and loss of the network on validations set: (32.22, 2.135157585144043)\n",
            "Epoch: 149\n",
            "Accuracy and loss of the network on validations set: (32.440000000000005, 2.1344549655914307)\n",
            "Epoch: 150\n",
            "Accuracy and loss of the network on validations set: (32.48, 2.1337878704071045)\n",
            "Epoch: 151\n",
            "Accuracy and loss of the network on validations set: (32.56, 2.1332881450653076)\n",
            "Epoch: 152\n",
            "Accuracy and loss of the network on validations set: (32.72, 2.1327812671661377)\n",
            "Epoch: 153\n",
            "Accuracy and loss of the network on validations set: (32.74, 2.1315762996673584)\n",
            "Epoch: 154\n",
            "Accuracy and loss of the network on validations set: (32.86, 2.131051540374756)\n",
            "Epoch: 155\n",
            "Accuracy and loss of the network on validations set: (32.72, 2.130497455596924)\n",
            "Epoch: 156\n",
            "Accuracy and loss of the network on validations set: (32.9, 2.129746198654175)\n",
            "Epoch: 157\n",
            "Accuracy and loss of the network on validations set: (33.06, 2.129166603088379)\n",
            "Epoch: 158\n",
            "Accuracy and loss of the network on validations set: (33.0, 2.1284995079040527)\n",
            "Epoch: 159\n",
            "Accuracy and loss of the network on validations set: (32.92, 2.127790927886963)\n",
            "Epoch: 160\n",
            "Accuracy and loss of the network on validations set: (32.86, 2.127345085144043)\n",
            "Epoch: 161\n",
            "Accuracy and loss of the network on validations set: (33.06, 2.1264946460723877)\n",
            "Epoch: 162\n",
            "Accuracy and loss of the network on validations set: (33.18, 2.1261279582977295)\n",
            "Epoch: 163\n",
            "Accuracy and loss of the network on validations set: (33.14, 2.12540602684021)\n",
            "Epoch: 164\n",
            "Accuracy and loss of the network on validations set: (33.1, 2.1246044635772705)\n",
            "Epoch: 165\n",
            "Accuracy and loss of the network on validations set: (33.44, 2.1243293285369873)\n",
            "Epoch: 166\n",
            "Accuracy and loss of the network on validations set: (33.56, 2.1234190464019775)\n",
            "Epoch: 167\n",
            "Accuracy and loss of the network on validations set: (33.56, 2.1230297088623047)\n",
            "Epoch: 168\n",
            "Accuracy and loss of the network on validations set: (33.72, 2.1225125789642334)\n",
            "Epoch: 169\n",
            "Accuracy and loss of the network on validations set: (33.739999999999995, 2.1220035552978516)\n",
            "Epoch: 170\n",
            "Accuracy and loss of the network on validations set: (33.72, 2.121821641921997)\n",
            "Epoch: 171\n",
            "Accuracy and loss of the network on validations set: (33.86, 2.120757818222046)\n",
            "Epoch: 172\n",
            "Accuracy and loss of the network on validations set: (33.94, 2.120319128036499)\n",
            "Epoch: 173\n",
            "Accuracy and loss of the network on validations set: (33.92, 2.1195921897888184)\n",
            "Epoch: 174\n",
            "Accuracy and loss of the network on validations set: (34.1, 2.119061231613159)\n",
            "Epoch: 175\n",
            "Accuracy and loss of the network on validations set: (34.28, 2.118756055831909)\n",
            "Epoch: 176\n",
            "Accuracy and loss of the network on validations set: (34.36, 2.118225574493408)\n",
            "Epoch: 177\n",
            "Accuracy and loss of the network on validations set: (34.32, 2.118046760559082)\n",
            "Epoch: 178\n",
            "Accuracy and loss of the network on validations set: (34.54, 2.117311477661133)\n",
            "Epoch: 179\n",
            "Accuracy and loss of the network on validations set: (34.08, 2.1168999671936035)\n",
            "Epoch: 180\n",
            "Accuracy and loss of the network on validations set: (34.52, 2.1161751747131348)\n",
            "Epoch: 181\n",
            "Accuracy and loss of the network on validations set: (34.64, 2.11613130569458)\n",
            "Epoch: 182\n",
            "Accuracy and loss of the network on validations set: (34.72, 2.115107774734497)\n",
            "Epoch: 183\n",
            "Accuracy and loss of the network on validations set: (34.260000000000005, 2.1149187088012695)\n",
            "Epoch: 184\n",
            "Accuracy and loss of the network on validations set: (34.46, 2.114274501800537)\n",
            "Epoch: 185\n",
            "Accuracy and loss of the network on validations set: (34.44, 2.1140708923339844)\n",
            "Epoch: 186\n",
            "Accuracy and loss of the network on validations set: (34.660000000000004, 2.1131675243377686)\n",
            "Epoch: 187\n",
            "Accuracy and loss of the network on validations set: (34.58, 2.112997055053711)\n",
            "Epoch: 188\n",
            "Accuracy and loss of the network on validations set: (34.56, 2.1126301288604736)\n",
            "Epoch: 189\n",
            "Accuracy and loss of the network on validations set: (34.74, 2.1122500896453857)\n",
            "Epoch: 190\n",
            "Accuracy and loss of the network on validations set: (34.699999999999996, 2.111509084701538)\n",
            "Epoch: 191\n",
            "Accuracy and loss of the network on validations set: (34.64, 2.111159086227417)\n",
            "Epoch: 192\n",
            "Accuracy and loss of the network on validations set: (34.82, 2.111032485961914)\n",
            "Epoch: 193\n",
            "Accuracy and loss of the network on validations set: (34.78, 2.110476493835449)\n",
            "Epoch: 194\n",
            "Accuracy and loss of the network on validations set: (34.760000000000005, 2.110177755355835)\n",
            "Epoch: 195\n",
            "Accuracy and loss of the network on validations set: (34.839999999999996, 2.1095926761627197)\n",
            "Epoch: 196\n",
            "Accuracy and loss of the network on validations set: (35.02, 2.109131336212158)\n",
            "Epoch: 197\n",
            "Accuracy and loss of the network on validations set: (34.94, 2.108708620071411)\n",
            "Epoch: 198\n",
            "Accuracy and loss of the network on validations set: (35.120000000000005, 2.1083428859710693)\n",
            "Epoch: 199\n",
            "Accuracy and loss of the network on validations set: (34.94, 2.1084232330322266)\n",
            "Epoch: 200\n",
            "Accuracy and loss of the network on validations set: (35.08, 2.107611894607544)\n",
            "Epoch: 201\n",
            "Accuracy and loss of the network on validations set: (35.38, 2.1074461936950684)\n",
            "Epoch: 202\n",
            "Accuracy and loss of the network on validations set: (35.24, 2.1068079471588135)\n",
            "Epoch: 203\n",
            "Accuracy and loss of the network on validations set: (35.160000000000004, 2.1065399646759033)\n",
            "Epoch: 204\n",
            "Accuracy and loss of the network on validations set: (35.22, 2.1060233116149902)\n",
            "Epoch: 205\n",
            "Accuracy and loss of the network on validations set: (35.24, 2.1057376861572266)\n",
            "Epoch: 206\n",
            "Accuracy and loss of the network on validations set: (35.36, 2.105611801147461)\n",
            "Epoch: 207\n",
            "Accuracy and loss of the network on validations set: (35.339999999999996, 2.1051647663116455)\n",
            "Epoch: 208\n",
            "Accuracy and loss of the network on validations set: (35.18, 2.1048927307128906)\n",
            "Epoch: 209\n",
            "Accuracy and loss of the network on validations set: (35.66, 2.1044270992279053)\n",
            "Epoch: 210\n",
            "Accuracy and loss of the network on validations set: (35.480000000000004, 2.1041886806488037)\n",
            "Epoch: 211\n",
            "Accuracy and loss of the network on validations set: (35.42, 2.10384464263916)\n",
            "Epoch: 212\n",
            "Accuracy and loss of the network on validations set: (35.54, 2.103214740753174)\n",
            "Epoch: 213\n",
            "Accuracy and loss of the network on validations set: (35.74, 2.1029446125030518)\n",
            "Epoch: 214\n",
            "Accuracy and loss of the network on validations set: (35.839999999999996, 2.1024434566497803)\n",
            "Epoch: 215\n",
            "Accuracy and loss of the network on validations set: (35.980000000000004, 2.1025004386901855)\n",
            "Epoch: 216\n",
            "Accuracy and loss of the network on validations set: (35.82, 2.1018805503845215)\n",
            "Epoch: 217\n",
            "Accuracy and loss of the network on validations set: (35.6, 2.101515054702759)\n",
            "Epoch: 218\n",
            "Accuracy and loss of the network on validations set: (35.839999999999996, 2.1011030673980713)\n",
            "Epoch: 219\n",
            "Accuracy and loss of the network on validations set: (35.94, 2.1008262634277344)\n",
            "Epoch: 220\n",
            "Accuracy and loss of the network on validations set: (35.8, 2.1002345085144043)\n",
            "Epoch: 221\n",
            "Accuracy and loss of the network on validations set: (35.92, 2.100137710571289)\n",
            "Epoch: 222\n",
            "Accuracy and loss of the network on validations set: (36.02, 2.099916934967041)\n",
            "Epoch: 223\n",
            "Accuracy and loss of the network on validations set: (36.04, 2.099299192428589)\n",
            "Epoch: 224\n",
            "Accuracy and loss of the network on validations set: (36.059999999999995, 2.0990731716156006)\n",
            "Epoch: 225\n",
            "Accuracy and loss of the network on validations set: (36.120000000000005, 2.0987868309020996)\n",
            "Epoch: 226\n",
            "Accuracy and loss of the network on validations set: (36.199999999999996, 2.099114179611206)\n",
            "Epoch: 227\n",
            "Accuracy and loss of the network on validations set: (36.14, 2.0981359481811523)\n",
            "Epoch: 228\n",
            "Accuracy and loss of the network on validations set: (36.28, 2.0978541374206543)\n",
            "Epoch: 229\n",
            "Accuracy and loss of the network on validations set: (36.26, 2.097470760345459)\n",
            "Epoch: 230\n",
            "Accuracy and loss of the network on validations set: (36.36, 2.097160816192627)\n",
            "Epoch: 231\n",
            "Accuracy and loss of the network on validations set: (36.24, 2.097275495529175)\n",
            "Epoch: 232\n",
            "Accuracy and loss of the network on validations set: (36.38, 2.09668231010437)\n",
            "Epoch: 233\n",
            "Accuracy and loss of the network on validations set: (36.36, 2.095947504043579)\n",
            "Epoch: 234\n",
            "Accuracy and loss of the network on validations set: (36.46, 2.0956668853759766)\n",
            "Epoch: 235\n",
            "Accuracy and loss of the network on validations set: (36.480000000000004, 2.0954322814941406)\n",
            "Epoch: 236\n",
            "Accuracy and loss of the network on validations set: (36.54, 2.0951292514801025)\n",
            "Epoch: 237\n",
            "Accuracy and loss of the network on validations set: (36.44, 2.094717264175415)\n",
            "Epoch: 238\n",
            "Accuracy and loss of the network on validations set: (36.46, 2.0944430828094482)\n",
            "Epoch: 239\n",
            "Accuracy and loss of the network on validations set: (36.54, 2.094215154647827)\n",
            "Epoch: 240\n",
            "Accuracy and loss of the network on validations set: (36.7, 2.0939972400665283)\n",
            "Epoch: 241\n",
            "Accuracy and loss of the network on validations set: (36.58, 2.093529224395752)\n",
            "Epoch: 242\n",
            "Accuracy and loss of the network on validations set: (36.78, 2.0934815406799316)\n",
            "Epoch: 243\n",
            "Accuracy and loss of the network on validations set: (36.78, 2.093062162399292)\n",
            "Epoch: 244\n",
            "Accuracy and loss of the network on validations set: (37.04, 2.0927278995513916)\n",
            "Epoch: 245\n",
            "Accuracy and loss of the network on validations set: (36.9, 2.0922927856445312)\n",
            "Epoch: 246\n",
            "Accuracy and loss of the network on validations set: (36.919999999999995, 2.0920791625976562)\n",
            "Epoch: 247\n",
            "Accuracy and loss of the network on validations set: (36.76, 2.0919108390808105)\n",
            "Epoch: 248\n",
            "Accuracy and loss of the network on validations set: (36.919999999999995, 2.0912411212921143)\n",
            "Epoch: 249\n",
            "Accuracy and loss of the network on validations set: (37.12, 2.0911600589752197)\n",
            "Epoch: 250\n",
            "Accuracy and loss of the network on validations set: (36.919999999999995, 2.0907559394836426)\n",
            "Epoch: 251\n",
            "Accuracy and loss of the network on validations set: (37.16, 2.090289354324341)\n",
            "Epoch: 252\n",
            "Accuracy and loss of the network on validations set: (37.059999999999995, 2.0907537937164307)\n",
            "Epoch: 253\n",
            "Accuracy and loss of the network on validations set: (37.480000000000004, 2.0898172855377197)\n",
            "Epoch: 254\n",
            "Accuracy and loss of the network on validations set: (37.12, 2.0895538330078125)\n",
            "Epoch: 255\n",
            "Accuracy and loss of the network on validations set: (37.28, 2.0894691944122314)\n",
            "Epoch: 256\n",
            "Accuracy and loss of the network on validations set: (37.08, 2.0896377563476562)\n",
            "Epoch: 257\n",
            "Accuracy and loss of the network on validations set: (37.38, 2.0888831615448)\n",
            "Epoch: 258\n",
            "Accuracy and loss of the network on validations set: (37.32, 2.088489532470703)\n",
            "Epoch: 259\n",
            "Accuracy and loss of the network on validations set: (37.24, 2.088157892227173)\n",
            "Epoch: 260\n",
            "Accuracy and loss of the network on validations set: (37.38, 2.0880205631256104)\n",
            "Epoch: 261\n",
            "Accuracy and loss of the network on validations set: (37.38, 2.0877063274383545)\n",
            "Epoch: 262\n",
            "Accuracy and loss of the network on validations set: (37.4, 2.087602138519287)\n",
            "Epoch: 263\n",
            "Accuracy and loss of the network on validations set: (37.419999999999995, 2.0872085094451904)\n",
            "Epoch: 264\n",
            "Accuracy and loss of the network on validations set: (37.78, 2.0870680809020996)\n",
            "Epoch: 265\n",
            "Accuracy and loss of the network on validations set: (37.580000000000005, 2.08719539642334)\n",
            "Epoch: 266\n",
            "Accuracy and loss of the network on validations set: (37.76, 2.086792469024658)\n",
            "Epoch: 267\n",
            "Accuracy and loss of the network on validations set: (37.88, 2.086217164993286)\n",
            "Epoch: 268\n",
            "Accuracy and loss of the network on validations set: (37.6, 2.08608341217041)\n",
            "Epoch: 269\n",
            "Accuracy and loss of the network on validations set: (37.68, 2.08567476272583)\n",
            "Epoch: 270\n",
            "Accuracy and loss of the network on validations set: (37.88, 2.085175037384033)\n",
            "Epoch: 271\n",
            "Accuracy and loss of the network on validations set: (38.019999999999996, 2.0849337577819824)\n",
            "Epoch: 272\n",
            "Accuracy and loss of the network on validations set: (38.080000000000005, 2.0847420692443848)\n",
            "Epoch: 273\n",
            "Accuracy and loss of the network on validations set: (38.0, 2.0845413208007812)\n",
            "Epoch: 274\n",
            "Accuracy and loss of the network on validations set: (37.36, 2.085088014602661)\n",
            "Epoch: 275\n",
            "Accuracy and loss of the network on validations set: (37.9, 2.084052085876465)\n",
            "Epoch: 276\n",
            "Accuracy and loss of the network on validations set: (38.019999999999996, 2.0841259956359863)\n",
            "Epoch: 277\n",
            "Accuracy and loss of the network on validations set: (37.480000000000004, 2.0840044021606445)\n",
            "Epoch: 278\n",
            "Accuracy and loss of the network on validations set: (37.84, 2.083503484725952)\n",
            "Epoch: 279\n",
            "Accuracy and loss of the network on validations set: (37.78, 2.0832347869873047)\n",
            "Epoch: 280\n",
            "Accuracy and loss of the network on validations set: (37.72, 2.082780361175537)\n",
            "Epoch: 281\n",
            "Accuracy and loss of the network on validations set: (37.86, 2.082780361175537)\n",
            "Epoch: 282\n",
            "Accuracy and loss of the network on validations set: (38.18, 2.0825119018554688)\n",
            "Epoch: 283\n",
            "Accuracy and loss of the network on validations set: (38.14, 2.0823700428009033)\n",
            "Epoch: 284\n",
            "Accuracy and loss of the network on validations set: (37.72, 2.0819499492645264)\n",
            "Epoch: 285\n",
            "Accuracy and loss of the network on validations set: (38.04, 2.0816073417663574)\n",
            "Epoch: 286\n",
            "Accuracy and loss of the network on validations set: (37.66, 2.0816874504089355)\n",
            "Epoch: 287\n",
            "Accuracy and loss of the network on validations set: (38.04, 2.0813424587249756)\n",
            "Epoch: 288\n",
            "Accuracy and loss of the network on validations set: (37.82, 2.081160068511963)\n",
            "Epoch: 289\n",
            "Accuracy and loss of the network on validations set: (37.56, 2.0810985565185547)\n",
            "Epoch: 290\n",
            "Accuracy and loss of the network on validations set: (38.06, 2.081089735031128)\n",
            "Epoch: 291\n",
            "Accuracy and loss of the network on validations set: (38.22, 2.0805182456970215)\n",
            "Epoch: 292\n",
            "Accuracy and loss of the network on validations set: (37.92, 2.080413341522217)\n",
            "Epoch: 293\n",
            "Accuracy and loss of the network on validations set: (38.14, 2.080395460128784)\n",
            "Epoch: 294\n",
            "Accuracy and loss of the network on validations set: (38.06, 2.0795159339904785)\n",
            "Epoch: 295\n",
            "Accuracy and loss of the network on validations set: (38.1, 2.079333782196045)\n",
            "Epoch: 296\n",
            "Accuracy and loss of the network on validations set: (38.24, 2.079153537750244)\n",
            "Epoch: 297\n",
            "Accuracy and loss of the network on validations set: (38.14, 2.079172372817993)\n",
            "Epoch: 298\n",
            "Accuracy and loss of the network on validations set: (37.96, 2.0788416862487793)\n",
            "Epoch: 299\n",
            "Accuracy and loss of the network on validations set: (37.78, 2.078789234161377)\n",
            "Epoch: 300\n",
            "Accuracy and loss of the network on validations set: (38.24, 2.0784051418304443)\n",
            "Epoch: 301\n",
            "Accuracy and loss of the network on validations set: (37.7, 2.0791971683502197)\n",
            "Epoch: 302\n",
            "Accuracy and loss of the network on validations set: (37.66, 2.079124927520752)\n",
            "Epoch: 303\n",
            "Accuracy and loss of the network on validations set: (38.26, 2.0777628421783447)\n",
            "Epoch: 304\n",
            "Accuracy and loss of the network on validations set: (38.16, 2.077996253967285)\n",
            "Epoch: 305\n",
            "Accuracy and loss of the network on validations set: (38.0, 2.077702045440674)\n",
            "Epoch: 306\n",
            "Accuracy and loss of the network on validations set: (38.36, 2.0772039890289307)\n",
            "Epoch: 307\n",
            "Accuracy and loss of the network on validations set: (38.440000000000005, 2.0769026279449463)\n",
            "Epoch: 308\n",
            "Accuracy and loss of the network on validations set: (38.440000000000005, 2.07676362991333)\n",
            "Epoch: 309\n",
            "Accuracy and loss of the network on validations set: (38.0, 2.0775070190429688)\n",
            "Epoch: 310\n",
            "Accuracy and loss of the network on validations set: (38.34, 2.0770084857940674)\n",
            "Epoch: 311\n",
            "Accuracy and loss of the network on validations set: (38.68, 2.0763611793518066)\n",
            "Epoch: 312\n",
            "Accuracy and loss of the network on validations set: (38.0, 2.076683759689331)\n",
            "Epoch: 313\n",
            "Accuracy and loss of the network on validations set: (38.279999999999994, 2.0764248371124268)\n",
            "Epoch: 314\n",
            "Accuracy and loss of the network on validations set: (38.800000000000004, 2.07568359375)\n",
            "Epoch: 315\n",
            "Accuracy and loss of the network on validations set: (38.24, 2.076676607131958)\n",
            "Epoch: 316\n",
            "Accuracy and loss of the network on validations set: (38.279999999999994, 2.075904130935669)\n",
            "Epoch: 317\n",
            "Accuracy and loss of the network on validations set: (38.46, 2.074946403503418)\n",
            "Epoch: 318\n",
            "Accuracy and loss of the network on validations set: (38.24, 2.075225830078125)\n",
            "Epoch: 319\n",
            "Accuracy and loss of the network on validations set: (38.36, 2.0751850605010986)\n",
            "Epoch: 320\n",
            "Accuracy and loss of the network on validations set: (38.519999999999996, 2.0746610164642334)\n",
            "Epoch: 321\n",
            "Accuracy and loss of the network on validations set: (38.62, 2.0748581886291504)\n",
            "Epoch: 322\n",
            "Accuracy and loss of the network on validations set: (38.5, 2.0743184089660645)\n",
            "Epoch: 323\n",
            "Accuracy and loss of the network on validations set: (38.56, 2.074185371398926)\n",
            "Epoch: 324\n",
            "Accuracy and loss of the network on validations set: (38.5, 2.073868989944458)\n",
            "Epoch: 325\n",
            "Accuracy and loss of the network on validations set: (38.34, 2.0739169120788574)\n",
            "Epoch: 326\n",
            "Accuracy and loss of the network on validations set: (38.46, 2.074394464492798)\n",
            "Epoch: 327\n",
            "Accuracy and loss of the network on validations set: (38.64, 2.0735387802124023)\n",
            "Epoch: 328\n",
            "Accuracy and loss of the network on validations set: (38.48, 2.0732884407043457)\n",
            "Epoch: 329\n",
            "Accuracy and loss of the network on validations set: (38.66, 2.073397636413574)\n",
            "Epoch: 330\n",
            "Accuracy and loss of the network on validations set: (38.54, 2.072890281677246)\n",
            "Epoch: 331\n",
            "Accuracy and loss of the network on validations set: (38.6, 2.072916030883789)\n",
            "Epoch: 332\n",
            "Accuracy and loss of the network on validations set: (38.58, 2.0726218223571777)\n",
            "Epoch: 333\n",
            "Accuracy and loss of the network on validations set: (38.68, 2.072242498397827)\n",
            "Epoch: 334\n",
            "Accuracy and loss of the network on validations set: (38.5, 2.0725367069244385)\n",
            "Epoch: 335\n",
            "Accuracy and loss of the network on validations set: (38.56, 2.071809768676758)\n",
            "Epoch: 336\n",
            "Accuracy and loss of the network on validations set: (38.74, 2.071742296218872)\n",
            "Epoch: 337\n",
            "Accuracy and loss of the network on validations set: (38.58, 2.072686195373535)\n",
            "Epoch: 338\n",
            "Accuracy and loss of the network on validations set: (38.58, 2.072049140930176)\n",
            "Epoch: 339\n",
            "Accuracy and loss of the network on validations set: (38.519999999999996, 2.071769952774048)\n",
            "Epoch: 340\n",
            "Accuracy and loss of the network on validations set: (38.879999999999995, 2.071256399154663)\n",
            "Epoch: 341\n",
            "Accuracy and loss of the network on validations set: (38.7, 2.0713565349578857)\n",
            "Epoch: 342\n",
            "Accuracy and loss of the network on validations set: (38.92, 2.0714666843414307)\n",
            "Epoch: 343\n",
            "Accuracy and loss of the network on validations set: (38.72, 2.0709280967712402)\n",
            "Epoch: 344\n",
            "Accuracy and loss of the network on validations set: (38.7, 2.0706772804260254)\n",
            "Epoch: 345\n",
            "Accuracy and loss of the network on validations set: (38.68, 2.0704314708709717)\n",
            "Epoch: 346\n",
            "Accuracy and loss of the network on validations set: (38.62, 2.0708744525909424)\n",
            "Epoch: 347\n",
            "Accuracy and loss of the network on validations set: (38.78, 2.0705227851867676)\n",
            "Epoch: 348\n",
            "Accuracy and loss of the network on validations set: (38.800000000000004, 2.0701682567596436)\n",
            "Epoch: 349\n",
            "Accuracy and loss of the network on validations set: (38.78, 2.0698156356811523)\n",
            "Epoch: 350\n",
            "Accuracy and loss of the network on validations set: (38.800000000000004, 2.0702741146087646)\n",
            "Epoch: 351\n",
            "Accuracy and loss of the network on validations set: (38.72, 2.069810390472412)\n",
            "Epoch: 352\n",
            "Accuracy and loss of the network on validations set: (38.78, 2.070322275161743)\n",
            "Epoch: 353\n",
            "Accuracy and loss of the network on validations set: (38.879999999999995, 2.0696470737457275)\n",
            "Epoch: 354\n",
            "Accuracy and loss of the network on validations set: (38.92, 2.0687124729156494)\n",
            "Epoch: 355\n",
            "Accuracy and loss of the network on validations set: (38.86, 2.0686087608337402)\n",
            "Epoch: 356\n",
            "Accuracy and loss of the network on validations set: (38.9, 2.068614959716797)\n",
            "Epoch: 357\n",
            "Accuracy and loss of the network on validations set: (38.86, 2.0692977905273438)\n",
            "Epoch: 358\n",
            "Accuracy and loss of the network on validations set: (38.96, 2.0683631896972656)\n",
            "Epoch: 359\n",
            "Accuracy and loss of the network on validations set: (39.04, 2.0680689811706543)\n",
            "Epoch: 360\n",
            "Accuracy and loss of the network on validations set: (39.12, 2.0682742595672607)\n",
            "Epoch: 361\n",
            "Accuracy and loss of the network on validations set: (38.86, 2.068018674850464)\n",
            "Epoch: 362\n",
            "Accuracy and loss of the network on validations set: (39.0, 2.0675816535949707)\n",
            "Epoch: 363\n",
            "Accuracy and loss of the network on validations set: (39.12, 2.0678529739379883)\n",
            "Epoch: 364\n",
            "Accuracy and loss of the network on validations set: (39.2, 2.0679538249969482)\n",
            "Epoch: 365\n",
            "Accuracy and loss of the network on validations set: (39.12, 2.0672571659088135)\n",
            "Epoch: 366\n",
            "Accuracy and loss of the network on validations set: (39.06, 2.066972255706787)\n",
            "Epoch: 367\n",
            "Accuracy and loss of the network on validations set: (39.04, 2.066880464553833)\n",
            "Epoch: 368\n",
            "Accuracy and loss of the network on validations set: (39.22, 2.0672314167022705)\n",
            "Epoch: 369\n",
            "Accuracy and loss of the network on validations set: (39.24, 2.0666277408599854)\n",
            "Epoch: 370\n",
            "Accuracy and loss of the network on validations set: (39.300000000000004, 2.066575288772583)\n",
            "Epoch: 371\n",
            "Accuracy and loss of the network on validations set: (39.160000000000004, 2.066232442855835)\n",
            "Epoch: 372\n",
            "Accuracy and loss of the network on validations set: (39.06, 2.065983295440674)\n",
            "Epoch: 373\n",
            "Accuracy and loss of the network on validations set: (39.2, 2.065927267074585)\n",
            "Epoch: 374\n",
            "Accuracy and loss of the network on validations set: (39.06, 2.0659353733062744)\n",
            "Epoch: 375\n",
            "Accuracy and loss of the network on validations set: (39.1, 2.0662975311279297)\n",
            "Epoch: 376\n",
            "Accuracy and loss of the network on validations set: (39.08, 2.065589666366577)\n",
            "Epoch: 377\n",
            "Accuracy and loss of the network on validations set: (39.18, 2.065277576446533)\n",
            "Epoch: 378\n",
            "Accuracy and loss of the network on validations set: (39.32, 2.0653882026672363)\n",
            "Epoch: 379\n",
            "Accuracy and loss of the network on validations set: (39.24, 2.0652759075164795)\n",
            "Epoch: 380\n",
            "Accuracy and loss of the network on validations set: (39.18, 2.0649452209472656)\n",
            "Epoch: 381\n",
            "Accuracy and loss of the network on validations set: (39.1, 2.064852237701416)\n",
            "Epoch: 382\n",
            "Accuracy and loss of the network on validations set: (39.08, 2.0648367404937744)\n",
            "Epoch: 383\n",
            "Accuracy and loss of the network on validations set: (39.519999999999996, 2.0644805431365967)\n",
            "Epoch: 384\n",
            "Accuracy and loss of the network on validations set: (39.44, 2.0646684169769287)\n",
            "Epoch: 385\n",
            "Accuracy and loss of the network on validations set: (39.36, 2.0637166500091553)\n",
            "Epoch: 386\n",
            "Accuracy and loss of the network on validations set: (39.18, 2.0642948150634766)\n",
            "Epoch: 387\n",
            "Accuracy and loss of the network on validations set: (39.56, 2.0633583068847656)\n",
            "Epoch: 388\n",
            "Accuracy and loss of the network on validations set: (39.54, 2.063709259033203)\n",
            "Epoch: 389\n",
            "Accuracy and loss of the network on validations set: (39.379999999999995, 2.0634284019470215)\n",
            "Epoch: 390\n",
            "Accuracy and loss of the network on validations set: (39.24, 2.06368088722229)\n",
            "Epoch: 391\n",
            "Accuracy and loss of the network on validations set: (39.18, 2.0633654594421387)\n",
            "Epoch: 392\n",
            "Accuracy and loss of the network on validations set: (39.44, 2.0628857612609863)\n",
            "Epoch: 393\n",
            "Accuracy and loss of the network on validations set: (39.519999999999996, 2.0628929138183594)\n",
            "Epoch: 394\n",
            "Accuracy and loss of the network on validations set: (39.300000000000004, 2.0635321140289307)\n",
            "Epoch: 395\n",
            "Accuracy and loss of the network on validations set: (39.54, 2.0627365112304688)\n",
            "Epoch: 396\n",
            "Accuracy and loss of the network on validations set: (39.739999999999995, 2.0618085861206055)\n",
            "Epoch: 397\n",
            "Accuracy and loss of the network on validations set: (39.660000000000004, 2.062037944793701)\n",
            "Epoch: 398\n",
            "Accuracy and loss of the network on validations set: (39.58, 2.061598062515259)\n",
            "Epoch: 399\n",
            "Accuracy and loss of the network on validations set: (39.76, 2.0616960525512695)\n",
            "Epoch: 400\n",
            "Accuracy and loss of the network on validations set: (39.6, 2.0619938373565674)\n",
            "Epoch: 401\n",
            "Accuracy and loss of the network on validations set: (39.64, 2.0616462230682373)\n",
            "Epoch: 402\n",
            "Accuracy and loss of the network on validations set: (39.44, 2.062154769897461)\n",
            "Epoch: 403\n",
            "Accuracy and loss of the network on validations set: (39.48, 2.062004804611206)\n",
            "Epoch: 404\n",
            "Accuracy and loss of the network on validations set: (39.6, 2.06136417388916)\n",
            "Epoch: 405\n",
            "Accuracy and loss of the network on validations set: (39.68, 2.0609729290008545)\n",
            "Epoch: 406\n",
            "Accuracy and loss of the network on validations set: (39.78, 2.0606400966644287)\n",
            "Epoch: 407\n",
            "Accuracy and loss of the network on validations set: (39.64, 2.060265064239502)\n",
            "Epoch: 408\n",
            "Accuracy and loss of the network on validations set: (39.44, 2.0609114170074463)\n",
            "Epoch: 409\n",
            "Accuracy and loss of the network on validations set: (39.42, 2.060683012008667)\n",
            "Epoch: 410\n",
            "Accuracy and loss of the network on validations set: (39.58, 2.060089349746704)\n",
            "Epoch: 411\n",
            "Accuracy and loss of the network on validations set: (39.82, 2.059861421585083)\n",
            "Epoch: 412\n",
            "Accuracy and loss of the network on validations set: (39.800000000000004, 2.0596671104431152)\n",
            "Epoch: 413\n",
            "Accuracy and loss of the network on validations set: (39.7, 2.0597152709960938)\n",
            "Epoch: 414\n",
            "Accuracy and loss of the network on validations set: (39.98, 2.0590853691101074)\n",
            "Epoch: 415\n",
            "Accuracy and loss of the network on validations set: (40.0, 2.059169292449951)\n",
            "Epoch: 416\n",
            "Accuracy and loss of the network on validations set: (39.92, 2.058598756790161)\n",
            "Epoch: 417\n",
            "Accuracy and loss of the network on validations set: (39.839999999999996, 2.0587167739868164)\n",
            "Epoch: 418\n",
            "Accuracy and loss of the network on validations set: (39.7, 2.0584516525268555)\n",
            "Epoch: 419\n",
            "Accuracy and loss of the network on validations set: (40.08, 2.057969093322754)\n",
            "Epoch: 420\n",
            "Accuracy and loss of the network on validations set: (39.879999999999995, 2.0584867000579834)\n",
            "Epoch: 421\n",
            "Accuracy and loss of the network on validations set: (40.1, 2.058015823364258)\n",
            "Epoch: 422\n",
            "Accuracy and loss of the network on validations set: (40.18, 2.057755947113037)\n",
            "Epoch: 423\n",
            "Accuracy and loss of the network on validations set: (40.12, 2.057424306869507)\n",
            "Epoch: 424\n",
            "Accuracy and loss of the network on validations set: (40.0, 2.057668447494507)\n",
            "Epoch: 425\n",
            "Accuracy and loss of the network on validations set: (39.96, 2.057594060897827)\n",
            "Epoch: 426\n",
            "Accuracy and loss of the network on validations set: (40.160000000000004, 2.0573534965515137)\n",
            "Epoch: 427\n",
            "Accuracy and loss of the network on validations set: (40.0, 2.0576939582824707)\n",
            "Epoch: 428\n",
            "Accuracy and loss of the network on validations set: (40.04, 2.057255744934082)\n",
            "Epoch: 429\n",
            "Accuracy and loss of the network on validations set: (39.86, 2.056978225708008)\n",
            "Epoch: 430\n",
            "Accuracy and loss of the network on validations set: (40.160000000000004, 2.0563290119171143)\n",
            "Epoch: 431\n",
            "Accuracy and loss of the network on validations set: (39.879999999999995, 2.056335926055908)\n",
            "Epoch: 432\n",
            "Accuracy and loss of the network on validations set: (40.14, 2.0567092895507812)\n",
            "Epoch: 433\n",
            "Accuracy and loss of the network on validations set: (40.26, 2.0558407306671143)\n",
            "Epoch: 434\n",
            "Accuracy and loss of the network on validations set: (40.160000000000004, 2.055896759033203)\n",
            "Epoch: 435\n",
            "Accuracy and loss of the network on validations set: (40.22, 2.055309295654297)\n",
            "Epoch: 436\n",
            "Accuracy and loss of the network on validations set: (40.160000000000004, 2.0552475452423096)\n",
            "Epoch: 437\n",
            "Accuracy and loss of the network on validations set: (40.160000000000004, 2.054919481277466)\n",
            "Epoch: 438\n",
            "Accuracy and loss of the network on validations set: (40.14, 2.054612398147583)\n",
            "Epoch: 439\n",
            "Accuracy and loss of the network on validations set: (40.2, 2.0552468299865723)\n",
            "Epoch: 440\n",
            "Accuracy and loss of the network on validations set: (40.28, 2.0558440685272217)\n",
            "Epoch: 441\n",
            "Accuracy and loss of the network on validations set: (40.12, 2.055198907852173)\n",
            "Epoch: 442\n",
            "Accuracy and loss of the network on validations set: (40.339999999999996, 2.054156541824341)\n",
            "Epoch: 443\n",
            "Accuracy and loss of the network on validations set: (40.18, 2.0546319484710693)\n",
            "Epoch: 444\n",
            "Accuracy and loss of the network on validations set: (40.44, 2.054029703140259)\n",
            "Epoch: 445\n",
            "Accuracy and loss of the network on validations set: (40.44, 2.0537736415863037)\n",
            "Epoch: 446\n",
            "Accuracy and loss of the network on validations set: (40.2, 2.0541038513183594)\n",
            "Epoch: 447\n",
            "Accuracy and loss of the network on validations set: (40.300000000000004, 2.053208589553833)\n",
            "Epoch: 448\n",
            "Accuracy and loss of the network on validations set: (40.28, 2.0538535118103027)\n",
            "Epoch: 449\n",
            "Accuracy and loss of the network on validations set: (40.1, 2.055098056793213)\n",
            "Epoch: 450\n",
            "Accuracy and loss of the network on validations set: (40.2, 2.053311347961426)\n",
            "Epoch: 451\n",
            "Accuracy and loss of the network on validations set: (40.52, 2.0531809329986572)\n",
            "Epoch: 452\n",
            "Accuracy and loss of the network on validations set: (40.339999999999996, 2.0535058975219727)\n",
            "Epoch: 453\n",
            "Accuracy and loss of the network on validations set: (40.22, 2.052304983139038)\n",
            "Epoch: 454\n",
            "Accuracy and loss of the network on validations set: (40.52, 2.052264451980591)\n",
            "Epoch: 455\n",
            "Accuracy and loss of the network on validations set: (40.42, 2.052112579345703)\n",
            "Epoch: 456\n",
            "Accuracy and loss of the network on validations set: (40.300000000000004, 2.0518345832824707)\n",
            "Epoch: 457\n",
            "Accuracy and loss of the network on validations set: (40.22, 2.052421808242798)\n",
            "Epoch: 458\n",
            "Accuracy and loss of the network on validations set: (40.5, 2.053194046020508)\n",
            "Epoch: 459\n",
            "Accuracy and loss of the network on validations set: (40.62, 2.051865339279175)\n",
            "Epoch: 460\n",
            "Accuracy and loss of the network on validations set: (40.54, 2.051778793334961)\n",
            "Epoch: 461\n",
            "Accuracy and loss of the network on validations set: (40.68, 2.05092453956604)\n",
            "Epoch: 462\n",
            "Accuracy and loss of the network on validations set: (40.64, 2.051286220550537)\n",
            "Epoch: 463\n",
            "Accuracy and loss of the network on validations set: (40.62, 2.0508594512939453)\n",
            "Epoch: 464\n",
            "Accuracy and loss of the network on validations set: (40.32, 2.05176043510437)\n",
            "Epoch: 465\n",
            "Accuracy and loss of the network on validations set: (40.68, 2.0508313179016113)\n",
            "Epoch: 466\n",
            "Accuracy and loss of the network on validations set: (40.88, 2.050271987915039)\n",
            "Epoch: 467\n",
            "Accuracy and loss of the network on validations set: (40.5, 2.050757884979248)\n",
            "Epoch: 468\n",
            "Accuracy and loss of the network on validations set: (40.44, 2.0508930683135986)\n",
            "Epoch: 469\n",
            "Accuracy and loss of the network on validations set: (40.5, 2.0500071048736572)\n",
            "Epoch: 470\n",
            "Accuracy and loss of the network on validations set: (40.839999999999996, 2.049741506576538)\n",
            "Epoch: 471\n",
            "Accuracy and loss of the network on validations set: (40.760000000000005, 2.049921751022339)\n",
            "Epoch: 472\n",
            "Accuracy and loss of the network on validations set: (40.839999999999996, 2.049485445022583)\n",
            "Epoch: 473\n",
            "Accuracy and loss of the network on validations set: (40.64, 2.049276113510132)\n",
            "Epoch: 474\n",
            "Accuracy and loss of the network on validations set: (40.739999999999995, 2.0497443675994873)\n",
            "Epoch: 475\n",
            "Accuracy and loss of the network on validations set: (40.699999999999996, 2.0491421222686768)\n",
            "Epoch: 476\n",
            "Accuracy and loss of the network on validations set: (40.660000000000004, 2.0490286350250244)\n",
            "Epoch: 477\n",
            "Accuracy and loss of the network on validations set: (40.56, 2.0499067306518555)\n",
            "Epoch: 478\n",
            "Accuracy and loss of the network on validations set: (40.94, 2.0485289096832275)\n",
            "Epoch: 479\n",
            "Accuracy and loss of the network on validations set: (40.739999999999995, 2.048386573791504)\n",
            "Epoch: 480\n",
            "Accuracy and loss of the network on validations set: (40.739999999999995, 2.049553871154785)\n",
            "Epoch: 481\n",
            "Accuracy and loss of the network on validations set: (40.98, 2.048194646835327)\n",
            "Epoch: 482\n",
            "Accuracy and loss of the network on validations set: (40.86, 2.048063039779663)\n",
            "Epoch: 483\n",
            "Accuracy and loss of the network on validations set: (40.54, 2.048689126968384)\n",
            "Epoch: 484\n",
            "Accuracy and loss of the network on validations set: (41.06, 2.047807455062866)\n",
            "Epoch: 485\n",
            "Accuracy and loss of the network on validations set: (40.92, 2.047320604324341)\n",
            "Epoch: 486\n",
            "Accuracy and loss of the network on validations set: (41.120000000000005, 2.0473110675811768)\n",
            "Epoch: 487\n",
            "Accuracy and loss of the network on validations set: (40.660000000000004, 2.048862934112549)\n",
            "Epoch: 488\n",
            "Accuracy and loss of the network on validations set: (41.099999999999994, 2.046976089477539)\n",
            "Epoch: 489\n",
            "Accuracy and loss of the network on validations set: (40.94, 2.046854257583618)\n",
            "Epoch: 490\n",
            "Accuracy and loss of the network on validations set: (41.199999999999996, 2.0463099479675293)\n",
            "Epoch: 491\n",
            "Accuracy and loss of the network on validations set: (40.760000000000005, 2.0475246906280518)\n",
            "Epoch: 492\n",
            "Accuracy and loss of the network on validations set: (40.9, 2.0464823246002197)\n",
            "Epoch: 493\n",
            "Accuracy and loss of the network on validations set: (41.18, 2.046192169189453)\n",
            "Epoch: 494\n",
            "Accuracy and loss of the network on validations set: (40.88, 2.0464818477630615)\n",
            "Epoch: 495\n",
            "Accuracy and loss of the network on validations set: (40.98, 2.0464212894439697)\n",
            "Epoch: 496\n",
            "Accuracy and loss of the network on validations set: (41.22, 2.0460190773010254)\n",
            "Epoch: 497\n",
            "Accuracy and loss of the network on validations set: (41.14, 2.0456037521362305)\n",
            "Epoch: 498\n",
            "Accuracy and loss of the network on validations set: (41.36, 2.045389175415039)\n",
            "Epoch: 499\n",
            "Accuracy and loss of the network on validations set: (40.94, 2.0466294288635254)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    tst_pred = model.forward(torch.tensor(x_test_vector).to(torch.float32).to(dvc))\n",
        "    tst_los = loss_fn(tst_pred, torch.tensor(y_test.reshape(-1)).to(dvc))\n",
        "    tst_pred_clas = torch.argmax(tst_pred, axis=1)\n",
        "    tst_pred_clas = tst_pred_clas.detach().cpu().numpy()\n",
        "\n",
        "    tst_ac = 100 * np.mean(tst_pred_clas.reshape(-1) == y_test.reshape(-1))\n",
        "\n",
        "    \n",
        "    print(f'Accuracy and loss of the network on test set: {tst_ac, tst_los.item()}. Fairly close to our results ')"
      ],
      "metadata": {
        "id": "pFq5tuQHm9kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PMHxHccr5twP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1024 512\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(inp_dim, 1024),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 512),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(512, 10),\n",
        "    torch.nn.Softmax()\n",
        ")"
      ],
      "metadata": {
        "id": "pI5RDV0y5vOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Hb5hYbZz5vOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_torch = TrainSet(x_train_vector, y_train)\n",
        "train_dat = DataLoader(train_set_torch, batch_size=256, shuffle=True)\n"
      ],
      "metadata": {
        "id": "XGfnrYjW5vOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dvc= torch.device('cuda')\n",
        "model.to(dvc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37cdfd3e-4d35-4c7b-e00b-d6959ddeae1e",
        "id": "HI3B3BYh5vOp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=3072, out_features=1024, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (5): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_ls = []\n",
        "\n",
        "for epoch in range(200):  # loop over the dataset multiple times\n",
        "\n",
        "    print(f'Epoch: {epoch}')\n",
        "\n",
        "    for ind, data in enumerate(train_dat):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        x, y = data        \n",
        "        x = x.to(dvc)\n",
        "        y = y.to(dvc)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model.forward(x.to(torch.float32))\n",
        "        loss_val = loss_fn(outputs, y.reshape(-1))\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "        # print statistics\n",
        "\n",
        "    # set iteration time\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "            \n",
        "    # calculate accuracy\n",
        "    with torch.no_grad():\n",
        "        val_pred = model.forward(torch.tensor(x_val_vector).to(torch.float32).to(dvc))\n",
        "        val_los = loss_fn(val_pred, torch.tensor(y_val.reshape(-1)).to(dvc))\n",
        "        val_pred_clas = torch.argmax(val_pred, axis=1)\n",
        "        val_pred_clas = val_pred_clas.detach().cpu().numpy()\n",
        "\n",
        "        val_ac = 100 * np.mean(val_pred_clas.reshape(-1) == y_val.reshape(-1))\n",
        "    loss_ls.append(val_los.item())\n",
        "    \n",
        "    print(f'Accuracy and loss of the network on validations set: {val_ac, val_los.item()}')\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331c63b1-f9a4-40c2-d8fd-e5e7cdd03066",
        "id": "KRDvHbWr5vOq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Accuracy and loss of the network on validations set: (10.38, 2.2967255115509033)\n",
            "Epoch: 1\n",
            "Accuracy and loss of the network on validations set: (11.44, 2.2829294204711914)\n",
            "Epoch: 2\n",
            "Accuracy and loss of the network on validations set: (18.7, 2.258939266204834)\n",
            "Epoch: 3\n",
            "Accuracy and loss of the network on validations set: (22.939999999999998, 2.2289934158325195)\n",
            "Epoch: 4\n",
            "Accuracy and loss of the network on validations set: (24.44, 2.204228401184082)\n",
            "Epoch: 5\n",
            "Accuracy and loss of the network on validations set: (26.919999999999998, 2.1892287731170654)\n",
            "Epoch: 6\n",
            "Accuracy and loss of the network on validations set: (27.560000000000002, 2.1796281337738037)\n",
            "Epoch: 7\n",
            "Accuracy and loss of the network on validations set: (28.68, 2.1721079349517822)\n",
            "Epoch: 8\n",
            "Accuracy and loss of the network on validations set: (29.12, 2.1671595573425293)\n",
            "Epoch: 9\n",
            "Accuracy and loss of the network on validations set: (29.4, 2.160322427749634)\n",
            "Epoch: 10\n",
            "Accuracy and loss of the network on validations set: (29.82, 2.1557579040527344)\n",
            "Epoch: 11\n",
            "Accuracy and loss of the network on validations set: (30.42, 2.1498513221740723)\n",
            "Epoch: 12\n",
            "Accuracy and loss of the network on validations set: (31.0, 2.1446139812469482)\n",
            "Epoch: 13\n",
            "Accuracy and loss of the network on validations set: (31.0, 2.1407833099365234)\n",
            "Epoch: 14\n",
            "Accuracy and loss of the network on validations set: (31.96, 2.1355550289154053)\n",
            "Epoch: 15\n",
            "Accuracy and loss of the network on validations set: (32.36, 2.131376028060913)\n",
            "Epoch: 16\n",
            "Accuracy and loss of the network on validations set: (33.5, 2.123422861099243)\n",
            "Epoch: 17\n",
            "Accuracy and loss of the network on validations set: (34.239999999999995, 2.1158933639526367)\n",
            "Epoch: 18\n",
            "Accuracy and loss of the network on validations set: (34.68, 2.110745429992676)\n",
            "Epoch: 19\n",
            "Accuracy and loss of the network on validations set: (35.120000000000005, 2.1066207885742188)\n",
            "Epoch: 20\n",
            "Accuracy and loss of the network on validations set: (35.52, 2.1033225059509277)\n",
            "Epoch: 21\n",
            "Accuracy and loss of the network on validations set: (36.14, 2.0980794429779053)\n",
            "Epoch: 22\n",
            "Accuracy and loss of the network on validations set: (36.26, 2.0968050956726074)\n",
            "Epoch: 23\n",
            "Accuracy and loss of the network on validations set: (36.58, 2.0939888954162598)\n",
            "Epoch: 24\n",
            "Accuracy and loss of the network on validations set: (36.84, 2.090134382247925)\n",
            "Epoch: 25\n",
            "Accuracy and loss of the network on validations set: (37.08, 2.086946964263916)\n",
            "Epoch: 26\n",
            "Accuracy and loss of the network on validations set: (37.18, 2.0883829593658447)\n",
            "Epoch: 27\n",
            "Accuracy and loss of the network on validations set: (38.279999999999994, 2.0806407928466797)\n",
            "Epoch: 28\n",
            "Accuracy and loss of the network on validations set: (37.72, 2.0810558795928955)\n",
            "Epoch: 29\n",
            "Accuracy and loss of the network on validations set: (38.519999999999996, 2.0771327018737793)\n",
            "Epoch: 30\n",
            "Accuracy and loss of the network on validations set: (38.0, 2.075469732284546)\n",
            "Epoch: 31\n",
            "Accuracy and loss of the network on validations set: (39.019999999999996, 2.0710411071777344)\n",
            "Epoch: 32\n",
            "Accuracy and loss of the network on validations set: (38.379999999999995, 2.0711259841918945)\n",
            "Epoch: 33\n",
            "Accuracy and loss of the network on validations set: (39.0, 2.0703394412994385)\n",
            "Epoch: 34\n",
            "Accuracy and loss of the network on validations set: (39.36, 2.0649144649505615)\n",
            "Epoch: 35\n",
            "Accuracy and loss of the network on validations set: (39.78, 2.0631496906280518)\n",
            "Epoch: 36\n",
            "Accuracy and loss of the network on validations set: (39.64, 2.0619351863861084)\n",
            "Epoch: 37\n",
            "Accuracy and loss of the network on validations set: (39.58, 2.0606491565704346)\n",
            "Epoch: 38\n",
            "Accuracy and loss of the network on validations set: (40.14, 2.058236837387085)\n",
            "Epoch: 39\n",
            "Accuracy and loss of the network on validations set: (39.879999999999995, 2.0619421005249023)\n",
            "Epoch: 40\n",
            "Accuracy and loss of the network on validations set: (40.06, 2.0595126152038574)\n",
            "Epoch: 41\n",
            "Accuracy and loss of the network on validations set: (39.879999999999995, 2.0553479194641113)\n",
            "Epoch: 42\n",
            "Accuracy and loss of the network on validations set: (40.22, 2.054384708404541)\n",
            "Epoch: 43\n",
            "Accuracy and loss of the network on validations set: (40.86, 2.0516016483306885)\n",
            "Epoch: 44\n",
            "Accuracy and loss of the network on validations set: (40.64, 2.0507752895355225)\n",
            "Epoch: 45\n",
            "Accuracy and loss of the network on validations set: (40.54, 2.0517020225524902)\n",
            "Epoch: 46\n",
            "Accuracy and loss of the network on validations set: (40.54, 2.051919937133789)\n",
            "Epoch: 47\n",
            "Accuracy and loss of the network on validations set: (40.02, 2.049694061279297)\n",
            "Epoch: 48\n",
            "Accuracy and loss of the network on validations set: (41.099999999999994, 2.0436508655548096)\n",
            "Epoch: 49\n",
            "Accuracy and loss of the network on validations set: (41.06, 2.0435118675231934)\n",
            "Epoch: 50\n",
            "Accuracy and loss of the network on validations set: (41.48, 2.0438971519470215)\n",
            "Epoch: 51\n",
            "Accuracy and loss of the network on validations set: (41.3, 2.0443625450134277)\n",
            "Epoch: 52\n",
            "Accuracy and loss of the network on validations set: (41.18, 2.044156551361084)\n",
            "Epoch: 53\n",
            "Accuracy and loss of the network on validations set: (41.64, 2.0379040241241455)\n",
            "Epoch: 54\n",
            "Accuracy and loss of the network on validations set: (41.88, 2.037024736404419)\n",
            "Epoch: 55\n",
            "Accuracy and loss of the network on validations set: (41.839999999999996, 2.036738395690918)\n",
            "Epoch: 56\n",
            "Accuracy and loss of the network on validations set: (41.46, 2.0392134189605713)\n",
            "Epoch: 57\n",
            "Accuracy and loss of the network on validations set: (41.86, 2.0362346172332764)\n",
            "Epoch: 58\n",
            "Accuracy and loss of the network on validations set: (41.980000000000004, 2.0342280864715576)\n",
            "Epoch: 59\n",
            "Accuracy and loss of the network on validations set: (42.620000000000005, 2.030392646789551)\n",
            "Epoch: 60\n",
            "Accuracy and loss of the network on validations set: (42.28, 2.0336225032806396)\n",
            "Epoch: 61\n",
            "Accuracy and loss of the network on validations set: (42.559999999999995, 2.031939744949341)\n",
            "Epoch: 62\n",
            "Accuracy and loss of the network on validations set: (42.76, 2.0320913791656494)\n",
            "Epoch: 63\n",
            "Accuracy and loss of the network on validations set: (42.52, 2.030682325363159)\n",
            "Epoch: 64\n",
            "Accuracy and loss of the network on validations set: (42.76, 2.0267388820648193)\n",
            "Epoch: 65\n",
            "Accuracy and loss of the network on validations set: (42.980000000000004, 2.025970220565796)\n",
            "Epoch: 66\n",
            "Accuracy and loss of the network on validations set: (42.64, 2.027766704559326)\n",
            "Epoch: 67\n",
            "Accuracy and loss of the network on validations set: (42.54, 2.0312600135803223)\n",
            "Epoch: 68\n",
            "Accuracy and loss of the network on validations set: (43.480000000000004, 2.022102117538452)\n",
            "Epoch: 69\n",
            "Accuracy and loss of the network on validations set: (43.519999999999996, 2.0196268558502197)\n",
            "Epoch: 70\n",
            "Accuracy and loss of the network on validations set: (43.519999999999996, 2.0182015895843506)\n",
            "Epoch: 71\n",
            "Accuracy and loss of the network on validations set: (43.44, 2.0203123092651367)\n",
            "Epoch: 72\n",
            "Accuracy and loss of the network on validations set: (43.88, 2.0158867835998535)\n",
            "Epoch: 73\n",
            "Accuracy and loss of the network on validations set: (44.0, 2.0180366039276123)\n",
            "Epoch: 74\n",
            "Accuracy and loss of the network on validations set: (44.18, 2.0135421752929688)\n",
            "Epoch: 75\n",
            "Accuracy and loss of the network on validations set: (44.080000000000005, 2.016129493713379)\n",
            "Epoch: 76\n",
            "Accuracy and loss of the network on validations set: (44.22, 2.0157318115234375)\n",
            "Epoch: 77\n",
            "Accuracy and loss of the network on validations set: (44.3, 2.010044813156128)\n",
            "Epoch: 78\n",
            "Accuracy and loss of the network on validations set: (44.6, 2.0113115310668945)\n",
            "Epoch: 79\n",
            "Accuracy and loss of the network on validations set: (44.82, 2.009880781173706)\n",
            "Epoch: 80\n",
            "Accuracy and loss of the network on validations set: (44.58, 2.0097880363464355)\n",
            "Epoch: 81\n",
            "Accuracy and loss of the network on validations set: (44.940000000000005, 2.008910894393921)\n",
            "Epoch: 82\n",
            "Accuracy and loss of the network on validations set: (45.32, 2.0030648708343506)\n",
            "Epoch: 83\n",
            "Accuracy and loss of the network on validations set: (45.379999999999995, 2.004581928253174)\n",
            "Epoch: 84\n",
            "Accuracy and loss of the network on validations set: (44.92, 2.005347967147827)\n",
            "Epoch: 85\n",
            "Accuracy and loss of the network on validations set: (45.46, 2.0013887882232666)\n",
            "Epoch: 86\n",
            "Accuracy and loss of the network on validations set: (45.4, 2.0019469261169434)\n",
            "Epoch: 87\n",
            "Accuracy and loss of the network on validations set: (45.72, 1.999557614326477)\n",
            "Epoch: 88\n",
            "Accuracy and loss of the network on validations set: (45.839999999999996, 1.9976876974105835)\n",
            "Epoch: 89\n",
            "Accuracy and loss of the network on validations set: (46.28, 1.9948344230651855)\n",
            "Epoch: 90\n",
            "Accuracy and loss of the network on validations set: (46.5, 1.9956620931625366)\n",
            "Epoch: 91\n",
            "Accuracy and loss of the network on validations set: (46.08, 1.9953224658966064)\n",
            "Epoch: 92\n",
            "Accuracy and loss of the network on validations set: (45.800000000000004, 1.9975433349609375)\n",
            "Epoch: 93\n",
            "Accuracy and loss of the network on validations set: (45.800000000000004, 1.9972082376480103)\n",
            "Epoch: 94\n",
            "Accuracy and loss of the network on validations set: (47.0, 1.9905437231063843)\n",
            "Epoch: 95\n",
            "Accuracy and loss of the network on validations set: (46.62, 1.9937351942062378)\n",
            "Epoch: 96\n",
            "Accuracy and loss of the network on validations set: (46.379999999999995, 1.9931775331497192)\n",
            "Epoch: 97\n",
            "Accuracy and loss of the network on validations set: (46.62, 1.9914933443069458)\n",
            "Epoch: 98\n",
            "Accuracy and loss of the network on validations set: (46.68, 1.9893556833267212)\n",
            "Epoch: 99\n",
            "Accuracy and loss of the network on validations set: (46.2, 1.9939494132995605)\n",
            "Epoch: 100\n",
            "Accuracy and loss of the network on validations set: (47.04, 1.9859815835952759)\n",
            "Epoch: 101\n",
            "Accuracy and loss of the network on validations set: (47.339999999999996, 1.9842396974563599)\n",
            "Epoch: 102\n",
            "Accuracy and loss of the network on validations set: (46.96, 1.9857712984085083)\n",
            "Epoch: 103\n",
            "Accuracy and loss of the network on validations set: (47.64, 1.9836955070495605)\n",
            "Epoch: 104\n",
            "Accuracy and loss of the network on validations set: (47.199999999999996, 1.9875127077102661)\n",
            "Epoch: 105\n",
            "Accuracy and loss of the network on validations set: (48.0, 1.9798476696014404)\n",
            "Epoch: 106\n",
            "Accuracy and loss of the network on validations set: (47.5, 1.9824004173278809)\n",
            "Epoch: 107\n",
            "Accuracy and loss of the network on validations set: (46.86, 1.9887462854385376)\n",
            "Epoch: 108\n",
            "Accuracy and loss of the network on validations set: (47.82, 1.9834203720092773)\n",
            "Epoch: 109\n",
            "Accuracy and loss of the network on validations set: (47.9, 1.9806896448135376)\n",
            "Epoch: 110\n",
            "Accuracy and loss of the network on validations set: (47.68, 1.9816603660583496)\n",
            "Epoch: 111\n",
            "Accuracy and loss of the network on validations set: (47.8, 1.9786312580108643)\n",
            "Epoch: 112\n",
            "Accuracy and loss of the network on validations set: (47.760000000000005, 1.981002688407898)\n",
            "Epoch: 113\n",
            "Accuracy and loss of the network on validations set: (47.92, 1.9792823791503906)\n",
            "Epoch: 114\n",
            "Accuracy and loss of the network on validations set: (48.58, 1.976190447807312)\n",
            "Epoch: 115\n",
            "Accuracy and loss of the network on validations set: (48.699999999999996, 1.9737564325332642)\n",
            "Epoch: 116\n",
            "Accuracy and loss of the network on validations set: (48.6, 1.973198413848877)\n",
            "Epoch: 117\n",
            "Accuracy and loss of the network on validations set: (48.5, 1.9738656282424927)\n",
            "Epoch: 118\n",
            "Accuracy and loss of the network on validations set: (48.5, 1.9733424186706543)\n",
            "Epoch: 119\n",
            "Accuracy and loss of the network on validations set: (48.9, 1.9699593782424927)\n",
            "Epoch: 120\n",
            "Accuracy and loss of the network on validations set: (48.1, 1.9762179851531982)\n",
            "Epoch: 121\n",
            "Accuracy and loss of the network on validations set: (49.0, 1.9703418016433716)\n",
            "Epoch: 122\n",
            "Accuracy and loss of the network on validations set: (49.46, 1.9678466320037842)\n",
            "Epoch: 123\n",
            "Accuracy and loss of the network on validations set: (48.68, 1.96968674659729)\n",
            "Epoch: 124\n",
            "Accuracy and loss of the network on validations set: (48.96, 1.9690130949020386)\n",
            "Epoch: 125\n",
            "Accuracy and loss of the network on validations set: (49.220000000000006, 1.9673224687576294)\n",
            "Epoch: 126\n",
            "Accuracy and loss of the network on validations set: (48.36, 1.9763439893722534)\n",
            "Epoch: 127\n",
            "Accuracy and loss of the network on validations set: (49.2, 1.9690651893615723)\n",
            "Epoch: 128\n",
            "Accuracy and loss of the network on validations set: (49.3, 1.9659843444824219)\n",
            "Epoch: 129\n",
            "Accuracy and loss of the network on validations set: (48.24, 1.972564697265625)\n",
            "Epoch: 130\n",
            "Accuracy and loss of the network on validations set: (49.32, 1.968264102935791)\n",
            "Epoch: 131\n",
            "Accuracy and loss of the network on validations set: (49.76, 1.9631280899047852)\n",
            "Epoch: 132\n",
            "Accuracy and loss of the network on validations set: (49.58, 1.9640822410583496)\n",
            "Epoch: 133\n",
            "Accuracy and loss of the network on validations set: (49.68, 1.9650214910507202)\n",
            "Epoch: 134\n",
            "Accuracy and loss of the network on validations set: (49.32, 1.964025616645813)\n",
            "Epoch: 135\n",
            "Accuracy and loss of the network on validations set: (49.519999999999996, 1.964349627494812)\n",
            "Epoch: 136\n",
            "Accuracy and loss of the network on validations set: (49.4, 1.9634511470794678)\n",
            "Epoch: 137\n",
            "Accuracy and loss of the network on validations set: (49.9, 1.9619505405426025)\n",
            "Epoch: 138\n",
            "Accuracy and loss of the network on validations set: (49.120000000000005, 1.9668400287628174)\n",
            "Epoch: 139\n",
            "Accuracy and loss of the network on validations set: (49.120000000000005, 1.9654890298843384)\n",
            "Epoch: 140\n",
            "Accuracy and loss of the network on validations set: (49.6, 1.9627190828323364)\n",
            "Epoch: 141\n",
            "Accuracy and loss of the network on validations set: (49.559999999999995, 1.9626669883728027)\n",
            "Epoch: 142\n",
            "Accuracy and loss of the network on validations set: (49.66, 1.9615662097930908)\n",
            "Epoch: 143\n",
            "Accuracy and loss of the network on validations set: (49.24, 1.9658533334732056)\n",
            "Epoch: 144\n",
            "Accuracy and loss of the network on validations set: (50.03999999999999, 1.9602457284927368)\n",
            "Epoch: 145\n",
            "Accuracy and loss of the network on validations set: (49.78, 1.9608503580093384)\n",
            "Epoch: 146\n",
            "Accuracy and loss of the network on validations set: (49.58, 1.9621012210845947)\n",
            "Epoch: 147\n",
            "Accuracy and loss of the network on validations set: (49.64, 1.963580846786499)\n",
            "Epoch: 148\n",
            "Accuracy and loss of the network on validations set: (50.0, 1.9587228298187256)\n",
            "Epoch: 149\n",
            "Accuracy and loss of the network on validations set: (49.72, 1.9587681293487549)\n",
            "Epoch: 150\n",
            "Accuracy and loss of the network on validations set: (50.03999999999999, 1.9583550691604614)\n",
            "Epoch: 151\n",
            "Accuracy and loss of the network on validations set: (50.18, 1.9557420015335083)\n",
            "Epoch: 152\n",
            "Accuracy and loss of the network on validations set: (49.4, 1.9613884687423706)\n",
            "Epoch: 153\n",
            "Accuracy and loss of the network on validations set: (49.26, 1.9645191431045532)\n",
            "Epoch: 154\n",
            "Accuracy and loss of the network on validations set: (50.44, 1.9546550512313843)\n",
            "Epoch: 155\n",
            "Accuracy and loss of the network on validations set: (50.839999999999996, 1.9516913890838623)\n",
            "Epoch: 156\n",
            "Accuracy and loss of the network on validations set: (50.13999999999999, 1.9553097486495972)\n",
            "Epoch: 157\n",
            "Accuracy and loss of the network on validations set: (50.54, 1.9536927938461304)\n",
            "Epoch: 158\n",
            "Accuracy and loss of the network on validations set: (49.96, 1.9615693092346191)\n",
            "Epoch: 159\n",
            "Accuracy and loss of the network on validations set: (49.36, 1.9647611379623413)\n",
            "Epoch: 160\n",
            "Accuracy and loss of the network on validations set: (49.9, 1.9555143117904663)\n",
            "Epoch: 161\n",
            "Accuracy and loss of the network on validations set: (50.44, 1.953769326210022)\n",
            "Epoch: 162\n",
            "Accuracy and loss of the network on validations set: (50.28, 1.956316351890564)\n",
            "Epoch: 163\n",
            "Accuracy and loss of the network on validations set: (50.03999999999999, 1.9602396488189697)\n",
            "Epoch: 164\n",
            "Accuracy and loss of the network on validations set: (50.839999999999996, 1.9521435499191284)\n",
            "Epoch: 165\n",
            "Accuracy and loss of the network on validations set: (50.42, 1.9511195421218872)\n",
            "Epoch: 166\n",
            "Accuracy and loss of the network on validations set: (50.68, 1.9508837461471558)\n",
            "Epoch: 167\n",
            "Accuracy and loss of the network on validations set: (50.42, 1.9555584192276)\n",
            "Epoch: 168\n",
            "Accuracy and loss of the network on validations set: (50.44, 1.9533801078796387)\n",
            "Epoch: 169\n",
            "Accuracy and loss of the network on validations set: (49.58, 1.9588890075683594)\n",
            "Epoch: 170\n",
            "Accuracy and loss of the network on validations set: (49.78, 1.96133553981781)\n",
            "Epoch: 171\n",
            "Accuracy and loss of the network on validations set: (49.96, 1.95821213722229)\n",
            "Epoch: 172\n",
            "Accuracy and loss of the network on validations set: (50.480000000000004, 1.9523123502731323)\n",
            "Epoch: 173\n",
            "Accuracy and loss of the network on validations set: (50.96000000000001, 1.9494895935058594)\n",
            "Epoch: 174\n",
            "Accuracy and loss of the network on validations set: (50.7, 1.9528177976608276)\n",
            "Epoch: 175\n",
            "Accuracy and loss of the network on validations set: (50.339999999999996, 1.9544944763183594)\n",
            "Epoch: 176\n",
            "Accuracy and loss of the network on validations set: (50.63999999999999, 1.9510574340820312)\n",
            "Epoch: 177\n",
            "Accuracy and loss of the network on validations set: (50.839999999999996, 1.9546347856521606)\n",
            "Epoch: 178\n",
            "Accuracy and loss of the network on validations set: (50.9, 1.9487035274505615)\n",
            "Epoch: 179\n",
            "Accuracy and loss of the network on validations set: (51.019999999999996, 1.9487993717193604)\n",
            "Epoch: 180\n",
            "Accuracy and loss of the network on validations set: (50.7, 1.9493955373764038)\n",
            "Epoch: 181\n",
            "Accuracy and loss of the network on validations set: (51.019999999999996, 1.9478915929794312)\n",
            "Epoch: 182\n",
            "Accuracy and loss of the network on validations set: (51.1, 1.9472169876098633)\n",
            "Epoch: 183\n",
            "Accuracy and loss of the network on validations set: (50.82, 1.9491374492645264)\n",
            "Epoch: 184\n",
            "Accuracy and loss of the network on validations set: (51.080000000000005, 1.9470499753952026)\n",
            "Epoch: 185\n",
            "Accuracy and loss of the network on validations set: (51.28, 1.9460794925689697)\n",
            "Epoch: 186\n",
            "Accuracy and loss of the network on validations set: (49.6, 1.9591606855392456)\n",
            "Epoch: 187\n",
            "Accuracy and loss of the network on validations set: (51.22, 1.946412444114685)\n",
            "Epoch: 188\n",
            "Accuracy and loss of the network on validations set: (50.760000000000005, 1.9502631425857544)\n",
            "Epoch: 189\n",
            "Accuracy and loss of the network on validations set: (51.160000000000004, 1.9455056190490723)\n",
            "Epoch: 190\n",
            "Accuracy and loss of the network on validations set: (50.9, 1.9486316442489624)\n",
            "Epoch: 191\n",
            "Accuracy and loss of the network on validations set: (51.339999999999996, 1.9455190896987915)\n",
            "Epoch: 192\n",
            "Accuracy and loss of the network on validations set: (50.0, 1.9560669660568237)\n",
            "Epoch: 193\n",
            "Accuracy and loss of the network on validations set: (50.86000000000001, 1.9493166208267212)\n",
            "Epoch: 194\n",
            "Accuracy and loss of the network on validations set: (51.019999999999996, 1.9462023973464966)\n",
            "Epoch: 195\n",
            "Accuracy and loss of the network on validations set: (50.4, 1.951796531677246)\n",
            "Epoch: 196\n",
            "Accuracy and loss of the network on validations set: (51.559999999999995, 1.9452931880950928)\n",
            "Epoch: 197\n",
            "Accuracy and loss of the network on validations set: (51.42, 1.944196343421936)\n",
            "Epoch: 198\n",
            "Accuracy and loss of the network on validations set: (50.339999999999996, 1.9536175727844238)\n",
            "Epoch: 199\n",
            "Accuracy and loss of the network on validations set: (50.839999999999996, 1.9502240419387817)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    tst_pred = model.forward(torch.tensor(x_test_vector).to(torch.float32).to(dvc))\n",
        "    tst_los = loss_fn(tst_pred, torch.tensor(y_test.reshape(-1)).to(dvc))\n",
        "    tst_pred_clas = torch.argmax(tst_pred, axis=1)\n",
        "    tst_pred_clas = tst_pred_clas.detach().cpu().numpy()\n",
        "\n",
        "    tst_ac = 100 * np.mean(tst_pred_clas.reshape(-1) == y_test.reshape(-1))\n",
        "\n",
        "    \n",
        "    print(f'Accuracy and loss of the network on test set: {tst_ac, tst_los.item()}. Fairly close to our results ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWgtwkZy5vOr",
        "outputId": "b7f915d7-604e-4cd1-bdc1-e0b217eae76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy and loss of the network on test set: (51.15, 1.9462952613830566). Fairly close to our results \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qzkh9dHJAqw"
      },
      "source": [
        "## Plotting using the saved performances. No need to run on a new platform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a3opmtaKJ_x"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive as drv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB5nRM6sJ7Wa",
        "outputId": "aadd22f2-5234-409f-fb88-39786e3f35a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount drive\n",
        "drv.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkGu4VgwJAAi"
      },
      "outputs": [],
      "source": [
        "\n",
        "dir = '/content/drive/MyDrive/'\n",
        "with open(dir+'mlp_1.pickle', 'rb') as h:\n",
        "    mlp_1_dic = pickle.load(h)\n",
        "\n",
        "with open(dir+'mlp_2.pickle', 'rb') as h:\n",
        "    mlp_2_dic = pickle.load(h)\n",
        "with open(dir+'mlp_ful.pickle', 'rb') as h:\n",
        "    mlp_ful_dic = pickle.load(h)\n",
        "with open(dir+'mlp_l1.pickle', 'rb') as h:\n",
        "    mlp_l1_dic = pickle.load(h)\n",
        "with open(dir+'mlp_l2.pickle', 'rb') as h:\n",
        "    mlp_l2_dic = pickle.load(h)\n",
        "with open(dir+'mlp_lrelu.pickle', 'rb') as h:\n",
        "    mlp_lrelu_dic = pickle.load(h)\n",
        "with open(dir+'mlp_noh.pickle', 'rb') as h:\n",
        "    mlp_noh_dic = pickle.load(h)\n",
        "with open(dir+'mlp_tanh.pickle', 'rb') as h:\n",
        "    mlp_tanh_dic = pickle.load(h)\n",
        "with open(dir+'mlp_3.pickle', 'rb') as h:\n",
        "    mlp_3_dic = pickle.load(h)\n",
        "with open(dir+'mlp_512.pickle', 'rb') as h:\n",
        "    mlp_512_dic = pickle.load(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "JoKdy8zmKWvx",
        "outputId": "c2cd4391-f629-4108-f240-9296c938c3f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(mlp_ful_dic['train_cost'], label='relu')\n",
        "plt.plot(mlp_lrelu_dic['train_cost'], label='leaky relu')\n",
        "plt.plot(mlp_tanh_dic['train_cost'], label='tanh')\n",
        "plt.legend(frameon=False)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "#plt.savefig('fig1.png', format='png', dpi=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "DbgwhwjKLs5R",
        "outputId": "0cd1790f-0ff6-4f60-ee0d-adcce5c36e4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(mlp_ful_dic['val_cost'], label='relu')\n",
        "plt.plot(mlp_lrelu_dic['val_cost'], label='leaky relu')\n",
        "plt.plot(mlp_tanh_dic['val_cost'], label='tanh')\n",
        "plt.legend(frameon=False)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "#plt.savefig('fig1.png', format='png', dpi=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For test performance, the result is reported as (accuracy, loss)"
      ],
      "metadata": {
        "id": "346OpPADcUV0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVE-q7VYSCcf",
        "outputId": "34a4a5e4-de76-4d89-e11b-fe6a3d9c2966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final performance of model with relu activation: (39.160000000000004, 0.17175061848872528)\n",
            "Final performance of model with leaky relu activation: (39.82, 0.17175530266298739)\n",
            "Final performance of model with relu activation: (39.83, 0.1724528572309131)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Final test performance of model with relu activation: {mlp_ful_dic['test_perf']}\")\n",
        "print(f\"Final test performance of model with leaky relu activation: {mlp_lrelu_dic['test_perf']}\")\n",
        "print(f\"Final test performance of model with relu activation: {mlp_tanh_dic['test_perf']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf7Iun2fS3Yk",
        "outputId": "0479c917-9be0-42c3-a256-08f8e18977a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time of model with relu activation: 7398.999198436737\n",
            "Training time of model with leaky relu activation: 6379.2937388420105\n",
            "Training time of model with relu activation: 11145.086985826492\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training time of model with relu activation: {mlp_2_dic['train_time']}s\")\n",
        "print(f\"Training time of model with leaky relu activation: {mlp_lrelu_dic['train_time']}s\")\n",
        "print(f\"Training time of model with relu activation: {mlp_tanh_dic['train_time']}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "7KP4yma3MUWK",
        "outputId": "56a92e82-c003-4abd-9732-44ba77e73f86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training loss')"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(mlp_ful_dic['train_cost'], label='2 hidden')\n",
        "plt.plot(mlp_1_dic['train_cost'], label='1 hidden')\n",
        "plt.plot(mlp_noh_dic['train_cost'], label='No hidden')\n",
        "plt.legend(frameon=False)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss')\n",
        "#plt.savefig('fig1.png', format='png', dpi=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "MJZo9eQkMzKT",
        "outputId": "023fdeb2-4e5e-47fa-c417-f77358b9ab1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Validation loss')"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(mlp_ful_dic['val_cost'], label='2 hidden')\n",
        "plt.plot(mlp_1_dic['val_cost'], label='1 hidden')\n",
        "plt.plot(mlp_noh_dic['val_cost'], label='No hidden')\n",
        "plt.legend(frameon=False)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Validation loss')\n",
        "#plt.savefig('fig1.png', format='png', dpi=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjE7gCwBTYqX",
        "outputId": "756c38ae-791e-46f9-b7a7-bff1a25ff64b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final test performance of model with 2 hidden layers: (39.160000000000004, 0.17175061848872528)\n",
            "Final test performance of model with 1 hidden layer: (36.480000000000004, 0.1851969758531202)\n",
            "Final test performance of model with no hidden layer: (20.119999999999997, 0.33889570300388094)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Final test performance of model with 2 hidden layers: {mlp_ful_dic['test_perf']}\")\n",
        "print(f\"Final test performance of model with 1 hidden layer: {mlp_1_dic['test_perf']}\")\n",
        "print(f\"Final test performance of model with no hidden layer: {mlp_noh_dic['test_perf']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEuHfc75TYqa"
      },
      "outputs": [],
      "source": [
        "print(f\"Training time of model with 2 hidden layers: {mlp_2_dic['train_time']}s\")\n",
        "print(f\"Training time of model with 1 hidden layer: {mlp_1_dic['train_time']}s\")\n",
        "print(f\"Training time of model with no hidden layer: {mlp_noh_dic['train_time']}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "H-NPKHEfNAxz",
        "outputId": "753a1e45-f8e5-45cc-825f-60075e2022d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training loss')"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(mlp_ful_dic['train_cost'], label='No reg')\n",
        "plt.plot(mlp_l1_dic['train_cost'], label='L1')\n",
        "plt.plot(mlp_l2_dic['train_cost'], label='L2')\n",
        "plt.legend(frameon=False)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss')\n",
        "#plt.savefig('fig1.png', format='png', dpi=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "G1v5gVuvNJLd",
        "outputId": "29aec57e-bd97-4336-efae-3bb1b50820fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training loss')"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(mlp_ful_dic['val_cost'], label='No reg')\n",
        "plt.plot(mlp_l1_dic['val_cost'], label='L1')\n",
        "plt.plot(mlp_l2_dic['val_cost'], label='L2')\n",
        "plt.legend(frameon=False)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss')\n",
        "#plt.savefig('fig1.png', format='png', dpi=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzB0pSwzT6av",
        "outputId": "4ede21fa-3b1b-4040-a0cd-c695d519bb26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final test performance of model with no regularization: (39.160000000000004, 0.17175061848872528)\n",
            "Final test performance of model with L1 regularization: (40.22, 0.16949206481186058)\n",
            "Final test performance of model with L2 regularization: (40.47, 0.1694321672497076)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Final test performance of model with no regularization: {mlp_ful_dic['test_perf']}s\")\n",
        "print(f\"Final test performance of model with L1 regularization: {mlp_l1_dic['test_perf']}s\")\n",
        "print(f\"Final test performance of model with L2 regularization: {mlp_l2_dic['test_perf']}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK-1CAzNT6ay",
        "outputId": "346b242c-5f7e-4e97-befa-ac3f9d43a34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time of model with no regulariation: 7398.999198436737\n",
            "Training time of model with L1 regularization: 6880.1857097148895\n",
            "Training time of model with L2 regularization: 7218.637221813202\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training time of model with no regulariation: {mlp_2_dic['train_time']}s\")\n",
        "print(f\"Training time of model with L1 regularization: {mlp_l1_dic['train_time']}s\")\n",
        "print(f\"Training time of model with L2 regularization: {mlp_l2_dic['train_time']}s\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WS-NfDIWW1NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "3ac7be31-539b-448a-b417-0f9c29a2baed",
        "id": "5P-YzZkEW1cJ"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training loss')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(mlp_ful_dic['val_cost'], label='2 256 hidden layers')\n",
        "plt.plot(mlp_3_dic['val_cost'], label='3 256 hidden layers')\n",
        "plt.plot(mlp_512_dic['val_cost'], label='2 512 hidden layes')\n",
        "plt.legend(frameon=False)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss')\n",
        "#plt.savefig('fig1.png', format='png', dpi=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b58bdfb-0830-44f7-cb3b-a2346f61d778",
        "id": "ncrm_al7W1cM"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test performance of model with 2 256 hidden layers: (39.160000000000004, 0.17175061848872528)\n",
            "Test performance of model with 3 256 hidden layers: (40.37, 0.16833193947218475)\n",
            "Test performance of model with 2 512 hidden layers: (42.67, 0.16204763471677303)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test performance of model with 2 256 hidden layers: {mlp_ful_dic['test_perf']}\")\n",
        "print(f\"Test performance of model with 3 256 hidden layers: {mlp_3_dic['test_perf']}\")\n",
        "print(f\"Test performance of model with 2 512 hidden layers: {mlp_512_dic['test_perf']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef761645-15ea-4149-f331-cde15ab201d4",
        "id": "yk_LvGLyW1cN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time of model with 2 256 hidden layers: 7398.999198436737 s\n",
            "Training time of model with 3 256 hidden layers: 8206.493489027023 s\n",
            "Training time of model with 2 512 hidden layers: 14890.447857379913 s\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training time of model with 2 256 hidden layers: {mlp_2_dic['train_time']}s\")\n",
        "print(f\"Training time of model with 3 256 hidden layers: {mlp_3_dic['train_time']}s\")\n",
        "print(f\"Training time of model with 2 512 hidden layers: {mlp_512_dic['train_time']}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awsKUCeKnxDf"
      },
      "source": [
        "## PyTorch: Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "yEUvLYlPteBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the the CIFAR-10 dataset normalize the data\n",
        "test_train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.225, 0.225, 0.225])\n",
        "])\n",
        "\n",
        "# Now load the appropriate training and test datasets\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=test_train_transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_train_transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSjHqXTrs9yS",
        "outputId": "59605921-bbba-4faf-ad28-3e5504a294a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MyCNN class with convolutional neural network architecture"
      ],
      "metadata": {
        "id": "9RFNz0FTtfyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCNN, self).__init__()\n",
        "\n",
        "        # Conv layers\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3,3), stride=1, padding=1)\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(32*8*8, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.50)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "trh_6ZKXtgK4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "shZuof07tpRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize CNN\n",
        "cnn = MyCNN().to(dvc)\n",
        "\n",
        "# Define the loss function, optimizer, and loss list for later plotting\n",
        "lossfunct = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(cnn.parameters(), lr=0.005, momentum=0.9)\n",
        "loss_list = []\n",
        "\n",
        "# Train the model on 40 epochs\n",
        "for epoch in range(40):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # Get the inputs and labels\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(dvc)\n",
        "        labels = labels.to(dvc)\n",
        "\n",
        "        # Initialize the parameter gradients to 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward, backward, and optimize\n",
        "        outputs = cnn(inputs)\n",
        "        loss = lossfunct(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather running loss\n",
        "        running_loss += loss.item()\n",
        "        max_i=i\n",
        "\n",
        "    current_loss = running_loss / max_i\n",
        "    loss_list.append(current_loss)\n",
        "    running_loss = 0.0 \n",
        "\n",
        "    # Calculate training accuracy after each epoch\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for data in train_loader:\n",
        "            # Get the inputs and labels again\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(dvc)\n",
        "            labels = labels.to(dvc)\n",
        "            outputs = cnn(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    current_accuracy = 100 * correct / total\n",
        "\n",
        "    print('[' + str(epoch + 1) + '] loss: ' + str(round(current_loss, 3)) + ', accuracy: ' + str(current_accuracy))\n",
        "\n",
        "print('Done training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_W2rba5ts6r",
        "outputId": "fc212080-2398-4db7-aabf-e72d0ea0ce82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 1.798, accuracy: 47.014\n",
            "[2] loss: 1.431, accuracy: 48.866\n",
            "[3] loss: 1.324, accuracy: 53.774\n",
            "[4] loss: 1.257, accuracy: 57.55\n",
            "[5] loss: 1.2, accuracy: 57.664\n",
            "[6] loss: 1.153, accuracy: 60.294\n",
            "[7] loss: 1.123, accuracy: 59.716\n",
            "[8] loss: 1.102, accuracy: 61.988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the loss of the train set over each epoch"
      ],
      "metadata": {
        "id": "awprFbYkt813"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_list)\n",
        "plt.title(\"CNN\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Running Loss\")"
      ],
      "metadata": {
        "id": "KqxY8vZUt-Y3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "e6f82406-20fe-44cb-9e77-f5a0806bfef5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Running Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gather the test accuracy"
      ],
      "metadata": {
        "id": "mtzaHRb1uGaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(dvc)\n",
        "        labels = labels.to(dvc)\n",
        "        outputs = cnn(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test accuracy: ' + str(100 * correct / total))"
      ],
      "metadata": {
        "id": "EF0qtleZuG4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb72578-3798-4526-a10b-c8a728ee7bfc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 68.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f9X-xkve1b-"
      },
      "source": [
        "## Resnet18: *Pre-Trained model*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ssphPZjfC2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "f3370f3b329c4c1ab82116fb019f29cf",
            "71bbcdb28213409090cd6ddc57945be0",
            "949f987062fa40dc98cdd92a39634185",
            "039b569f646746719360bc974b27acb5",
            "11e3f1c9515c4247a570cf2c81a9c648",
            "35abf9a73110495383a44d49d861c6aa",
            "2cbd75ed2f1145968a5c24565ed7fee8",
            "906b4cf27268483ea0e3760d063279a6",
            "bd5d714b2c6d4886ae2e564355b77e52",
            "a45404c6634a4a59bf3fbddf92f14ece",
            "2f747138e9524ccf9965f4a0e10d388b"
          ]
        },
        "outputId": "84f51ce0-2384-4f84-f784-c0182389fec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3370f3b329c4c1ab82116fb019f29cf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "resnet = models.resnet18(pretrained=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "37bc61f0b88640e58d424373e189e59c",
            "46d46c94aae74ddd826a5d62ef9d4ddd",
            "4ffd75853dd64c22935314d3485ad654",
            "f94a71f7ddba49ec81d859207a3c9fea",
            "1e7a9c5d8488404c9bb411bc3fb2ebb6",
            "5ee15194a4df49ceba255485ebae6230",
            "f5df19d7c85a401695bf36f27eba142c",
            "3a5254a1a9c24e5183c0ce9817d50cf3",
            "1d2b027509e6446589a007b367f1f863",
            "d19ab5c2663448beb3ef869ff4aaadb7",
            "ec68b4c1344b4832b602ad48c51406fe"
          ]
        },
        "id": "7e50FWG49Yqo",
        "outputId": "60cf9a74-83be-413b-9f7e-c9235d437083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37bc61f0b88640e58d424373e189e59c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnUpE7xafGCE"
      },
      "outputs": [],
      "source": [
        "#Freezing convolutional layers\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Remove fully connected layers\n",
        "num_features = resnet.fc.in_features\n",
        "resnet.fc = nn.Identity()\n",
        "# Define new fully connected layers\n",
        "new_fc = nn.Sequential(\n",
        "    nn.Linear(num_features,512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 10)\n",
        "    #nn.ReLU(),\n",
        "    #nn.Linear(128, 10)\n",
        ")\n",
        "resnet.fc = new_fc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dvc= torch.device('cuda')\n",
        "resnet.to(dvc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjiYG82ZxpOb",
        "outputId": "a4f70051-581e-4280-c6b8-2f17dccd7031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMXjdDxO9stF"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet.parameters(), lr=0.005, momentum=0.9)\n",
        "\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list_gpu=[]\n",
        "acc_list_gpu=[]\n",
        "start_time_pytorch = time.time()\n",
        "for epoch in range(50):  # loop over the dataset multiple times\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs= inputs.to(dvc)\n",
        "        labels= labels.to(dvc)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = resnet(inputs)\n",
        "        loss_val= loss(outputs, labels)\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "        # print statistics\n",
        "        running_loss += loss_val.item()\n",
        "        max_i=i\n",
        "    # set iteration time\n",
        "    iter_time = time.time()-start_time_pytorch\n",
        "    print(f'[{epoch + 1}] loss: {running_loss/max_i:.3f} time: {iter_time:.2f} seconds')\n",
        "    loss_list_gpu.append(running_loss/max_i)\n",
        "\n",
        "            \n",
        "    # calculate accuracy\n",
        "    with torch.no_grad():\n",
        "        for data in trainloader:\n",
        "            inputs, labels = data\n",
        "            inputs= inputs.to(dvc)\n",
        "            labels= labels.to(dvc)\n",
        "            outputs = resnet(inputs)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            \n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    acc_list_gpu.append(accuracy)\n",
        "    print(f'Accuracy of the network on the training images: {accuracy:.2f}%')\n",
        "\n",
        "\n",
        "# set iteration time time\n",
        "end_time = time.time()\n",
        "# calculate total running time\n",
        "total_time = end_time - start_time_pytorch\n",
        "\n",
        "print(f'Finished Training. Total running time: {total_time:.2f} seconds')"
      ],
      "metadata": {
        "id": "dwdh-IStxlHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c76cfa7-35a4-40d3-e400-c1f86aa519db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 1.848 time: 18.49 seconds\n",
            "Accuracy of the network on the training images: 44.32%\n",
            "[2] loss: 1.598 time: 44.16 seconds\n",
            "Accuracy of the network on the training images: 46.86%\n",
            "[3] loss: 1.539 time: 69.82 seconds\n",
            "Accuracy of the network on the training images: 47.67%\n",
            "[4] loss: 1.504 time: 97.56 seconds\n",
            "Accuracy of the network on the training images: 49.23%\n",
            "[5] loss: 1.477 time: 123.84 seconds\n",
            "Accuracy of the network on the training images: 49.63%\n",
            "[6] loss: 1.451 time: 150.13 seconds\n",
            "Accuracy of the network on the training images: 50.72%\n",
            "[7] loss: 1.426 time: 176.27 seconds\n",
            "Accuracy of the network on the training images: 51.75%\n",
            "[8] loss: 1.399 time: 203.03 seconds\n",
            "Accuracy of the network on the training images: 52.67%\n",
            "[9] loss: 1.379 time: 228.99 seconds\n",
            "Accuracy of the network on the training images: 53.32%\n",
            "[10] loss: 1.354 time: 254.66 seconds\n",
            "Accuracy of the network on the training images: 54.08%\n",
            "[11] loss: 1.336 time: 280.08 seconds\n",
            "Accuracy of the network on the training images: 54.81%\n",
            "[12] loss: 1.311 time: 305.31 seconds\n",
            "Accuracy of the network on the training images: 55.98%\n",
            "[13] loss: 1.293 time: 331.11 seconds\n",
            "Accuracy of the network on the training images: 56.39%\n",
            "[14] loss: 1.271 time: 358.50 seconds\n",
            "Accuracy of the network on the training images: 57.13%\n",
            "[15] loss: 1.248 time: 388.32 seconds\n",
            "Accuracy of the network on the training images: 58.32%\n",
            "[16] loss: 1.231 time: 419.40 seconds\n",
            "Accuracy of the network on the training images: 58.87%\n",
            "[17] loss: 1.214 time: 448.66 seconds\n",
            "Accuracy of the network on the training images: 59.00%\n",
            "[18] loss: 1.194 time: 477.44 seconds\n",
            "Accuracy of the network on the training images: 60.51%\n",
            "[19] loss: 1.178 time: 506.60 seconds\n",
            "Accuracy of the network on the training images: 61.16%\n",
            "[20] loss: 1.157 time: 536.64 seconds\n",
            "Accuracy of the network on the training images: 61.30%\n",
            "[21] loss: 1.138 time: 564.98 seconds\n",
            "Accuracy of the network on the training images: 62.40%\n",
            "[22] loss: 1.113 time: 593.78 seconds\n",
            "Accuracy of the network on the training images: 63.32%\n",
            "[23] loss: 1.103 time: 621.87 seconds\n",
            "Accuracy of the network on the training images: 63.82%\n",
            "[24] loss: 1.077 time: 651.16 seconds\n",
            "Accuracy of the network on the training images: 64.76%\n",
            "[25] loss: 1.066 time: 679.04 seconds\n",
            "Accuracy of the network on the training images: 65.05%\n",
            "[26] loss: 1.043 time: 707.05 seconds\n",
            "Accuracy of the network on the training images: 66.25%\n",
            "[27] loss: 1.029 time: 735.16 seconds\n",
            "Accuracy of the network on the training images: 66.11%\n",
            "[28] loss: 1.014 time: 764.24 seconds\n",
            "Accuracy of the network on the training images: 66.41%\n",
            "[29] loss: 0.991 time: 793.20 seconds\n",
            "Accuracy of the network on the training images: 68.05%\n",
            "[30] loss: 0.974 time: 821.31 seconds\n",
            "Accuracy of the network on the training images: 67.61%\n",
            "[31] loss: 0.963 time: 848.95 seconds\n",
            "Accuracy of the network on the training images: 68.11%\n",
            "[32] loss: 0.945 time: 876.67 seconds\n",
            "Accuracy of the network on the training images: 69.37%\n",
            "[33] loss: 0.933 time: 902.97 seconds\n",
            "Accuracy of the network on the training images: 69.69%\n",
            "[34] loss: 0.921 time: 928.70 seconds\n",
            "Accuracy of the network on the training images: 70.45%\n",
            "[35] loss: 0.903 time: 954.81 seconds\n",
            "Accuracy of the network on the training images: 70.45%\n",
            "[36] loss: 0.889 time: 980.74 seconds\n",
            "Accuracy of the network on the training images: 72.30%\n",
            "[37] loss: 0.874 time: 1006.16 seconds\n",
            "Accuracy of the network on the training images: 71.02%\n",
            "[38] loss: 0.862 time: 1031.78 seconds\n",
            "Accuracy of the network on the training images: 72.76%\n",
            "[39] loss: 0.844 time: 1057.24 seconds\n",
            "Accuracy of the network on the training images: 72.69%\n",
            "[40] loss: 0.830 time: 1082.92 seconds\n",
            "Accuracy of the network on the training images: 73.11%\n",
            "[41] loss: 0.818 time: 1108.34 seconds\n",
            "Accuracy of the network on the training images: 74.15%\n",
            "[42] loss: 0.806 time: 1134.32 seconds\n",
            "Accuracy of the network on the training images: 73.59%\n",
            "[43] loss: 0.799 time: 1159.53 seconds\n",
            "Accuracy of the network on the training images: 74.75%\n",
            "[44] loss: 0.783 time: 1185.02 seconds\n",
            "Accuracy of the network on the training images: 75.31%\n",
            "[45] loss: 0.775 time: 1210.45 seconds\n",
            "Accuracy of the network on the training images: 75.60%\n",
            "[46] loss: 0.763 time: 1235.92 seconds\n",
            "Accuracy of the network on the training images: 74.78%\n",
            "[47] loss: 0.752 time: 1262.35 seconds\n",
            "Accuracy of the network on the training images: 76.33%\n",
            "[48] loss: 0.742 time: 1288.02 seconds\n",
            "Accuracy of the network on the training images: 77.11%\n",
            "[49] loss: 0.730 time: 1313.20 seconds\n",
            "Accuracy of the network on the training images: 76.72%\n",
            "[50] loss: 0.725 time: 1338.53 seconds\n",
            "Accuracy of the network on the training images: 77.26%\n",
            "Finished Training. Total running time: 1351.14 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(loss_list_gpu)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "ax = plt.gca()\n",
        "ax.spines[['right', 'top']].set_visible(False)\n",
        "plt.savefig('resnet.png', dpi=150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "OmELRU2cGKX-",
        "outputId": "6a0be02f-2f95-4d49-ff3a-86e8f5413fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate accuracy\n",
        "correct_tst = 0\n",
        "total_tst = 0\n",
        "resnet.eval()\n",
        "for data in testloader:\n",
        "    inputs, labels = data\n",
        "    inputs= inputs.to(dvc)\n",
        "    labels= labels.to(dvc)\n",
        "    outputs = resnet(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total_tst += labels.size(0)\n",
        "    correct_tst += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy_tst = 100 * correct_tst / total_tst\n",
        "print(f'Resnet test accuracy: {accuracy_tst}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820962dd-e6c0-4799-ba87-80c9353c8046",
        "id": "5faH2UinJo-r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resnet test accuracy: 48.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate accuracy\n",
        "correct_tst = 0\n",
        "total_tst = 0\n",
        "resnet.eval()\n",
        "for data in trainloader:\n",
        "    inputs, labels = data\n",
        "    inputs= inputs.to(dvc)\n",
        "    labels= labels.to(dvc)\n",
        "    outputs = resnet(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total_tst += labels.size(0)\n",
        "    correct_tst += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy_tst = 100 * correct_tst / total_tst\n",
        "print(f'Resnet train accuracy: {accuracy_tst}')"
      ],
      "metadata": {
        "id": "Lj7sOMQOKqnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d47d5fe-576c-4820-ad32-3b84596637a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resnet train accuracy: 83.034\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f3370f3b329c4c1ab82116fb019f29cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71bbcdb28213409090cd6ddc57945be0",
              "IPY_MODEL_949f987062fa40dc98cdd92a39634185",
              "IPY_MODEL_039b569f646746719360bc974b27acb5"
            ],
            "layout": "IPY_MODEL_11e3f1c9515c4247a570cf2c81a9c648"
          }
        },
        "71bbcdb28213409090cd6ddc57945be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35abf9a73110495383a44d49d861c6aa",
            "placeholder": "",
            "style": "IPY_MODEL_2cbd75ed2f1145968a5c24565ed7fee8",
            "value": "100%"
          }
        },
        "949f987062fa40dc98cdd92a39634185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_906b4cf27268483ea0e3760d063279a6",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd5d714b2c6d4886ae2e564355b77e52",
            "value": 46830571
          }
        },
        "039b569f646746719360bc974b27acb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45404c6634a4a59bf3fbddf92f14ece",
            "placeholder": "",
            "style": "IPY_MODEL_2f747138e9524ccf9965f4a0e10d388b",
            "value": " 44.7M/44.7M [00:01&lt;00:00, 25.0MB/s]"
          }
        },
        "11e3f1c9515c4247a570cf2c81a9c648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35abf9a73110495383a44d49d861c6aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cbd75ed2f1145968a5c24565ed7fee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "906b4cf27268483ea0e3760d063279a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd5d714b2c6d4886ae2e564355b77e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a45404c6634a4a59bf3fbddf92f14ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f747138e9524ccf9965f4a0e10d388b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37bc61f0b88640e58d424373e189e59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46d46c94aae74ddd826a5d62ef9d4ddd",
              "IPY_MODEL_4ffd75853dd64c22935314d3485ad654",
              "IPY_MODEL_f94a71f7ddba49ec81d859207a3c9fea"
            ],
            "layout": "IPY_MODEL_1e7a9c5d8488404c9bb411bc3fb2ebb6"
          }
        },
        "46d46c94aae74ddd826a5d62ef9d4ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ee15194a4df49ceba255485ebae6230",
            "placeholder": "",
            "style": "IPY_MODEL_f5df19d7c85a401695bf36f27eba142c",
            "value": "100%"
          }
        },
        "4ffd75853dd64c22935314d3485ad654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a5254a1a9c24e5183c0ce9817d50cf3",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d2b027509e6446589a007b367f1f863",
            "value": 170498071
          }
        },
        "f94a71f7ddba49ec81d859207a3c9fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d19ab5c2663448beb3ef869ff4aaadb7",
            "placeholder": "",
            "style": "IPY_MODEL_ec68b4c1344b4832b602ad48c51406fe",
            "value": " 170498071/170498071 [00:13&lt;00:00, 14405251.53it/s]"
          }
        },
        "1e7a9c5d8488404c9bb411bc3fb2ebb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ee15194a4df49ceba255485ebae6230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5df19d7c85a401695bf36f27eba142c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a5254a1a9c24e5183c0ce9817d50cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d2b027509e6446589a007b367f1f863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d19ab5c2663448beb3ef869ff4aaadb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec68b4c1344b4832b602ad48c51406fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}